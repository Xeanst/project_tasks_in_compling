{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Анализ тональности к именованным сущностям в новостных текстах\n",
    "\n",
    "[Репозиторий на GitHub](https://github.com/dialogue-evaluation/RuSentNE-evaluation)\n",
    "\n",
    "[Страница на CodaLab](https://codalab.lisn.upsaclay.fr/competitions/9538)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим обучающую, валидационную и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -q https://raw.githubusercontent.com/dialogue-evaluation/RuSentNE-evaluation/main/train_data.csv\n",
    "!wget -q https://raw.githubusercontent.com/dialogue-evaluation/RuSentNE-evaluation/main/validation_data_labeled.csv\n",
    "!wget -q https://raw.githubusercontent.com/dialogue-evaluation/RuSentNE-evaluation/main/final_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv('train_data.csv', sep='\\t')\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.read_csv('validation_data_labeled.csv', sep='\\t')\n",
    "print(validation.shape)\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('final_data.csv', sep='\\t')\n",
    "print(test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разметка присутствует в обучающей и валидационной выборке. Разметка для тестовых данных отсутствует в загруженном файле. Оценка качестве на тестовой выборке возможна только через платформу CodaLab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анализ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируем данные обучающей выборки.\n",
    "\n",
    "Определим минимальную, максимальную и среднюю длину текста. Отобразим распределение на графике."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(x.split()) for x in train['sentence']]\n",
    "\n",
    "max_l, min_l, mean_l = max(lens), min(lens), sum(lens)/len(lens)\n",
    "\n",
    "print(f'Минимальная длина текста: {min_l}')\n",
    "print(f'Максимальная длина текста: {max_l}')\n",
    "print(f'Средняя длина текста: {mean_l:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "len_counts = Counter(lens)\n",
    "plt.figure(figsize = (6,3))\n",
    "plt.bar(len_counts.keys(), len_counts.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем самый длинный текст."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(train)):\n",
    "    if len(train['sentence'][i].split()) == max_l:\n",
    "        print(f\"Предложение:\\n{train['sentence'][i]}\")\n",
    "        print(f\"Сущность:\\n{train['entity'][i]}\")\n",
    "        print(f\"Тональность:\\n{train['label'][i]}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение классов тональности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.xlabel('Класс')\n",
    "plt.ylabel('Количество примеров')\n",
    "plt.title('Распределение примеров по классам')\n",
    "plt.bar(1, train[train['label'] == 1].shape, label='POS', color='lightgreen')\n",
    "plt.bar(0, train[train['label'] == 0].shape, label='NEUT', color='lightblue')\n",
    "plt.bar(-1, train[train['label'] == -1].shape, label='NEG', color='lightpink')\n",
    "plt.xticks(ticks=[1, 0, -1], labels=['1', '0', '-1'])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим статистику по типам сущностей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.xlabel('Сущность')\n",
    "plt.ylabel('Количество примеров')\n",
    "plt.title('Распределение типов сущностей')\n",
    "plt.bar('Люди', train[train['entity_tag'] == 'PERSON'].shape)\n",
    "plt.bar('Профессии', train[train['entity_tag'] == 'PROFESSION'].shape)\n",
    "plt.bar('Организации', train[train['entity_tag'] == 'ORGANIZATION'].shape)\n",
    "plt.bar('Страны', train[train['entity_tag'] == 'COUNTRY'].shape)\n",
    "plt.bar('Национальности', train[train['entity_tag'] == 'NATIONALITY'].shape)\n",
    "plt.xticks(ticks=['Люди', 'Профессии', 'Организации', 'Страны', 'Национальности'])\n",
    "plt.tick_params(labelrotation=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим самые частые сущности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['entity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе осуществим тонкую настройку модели [RuBERT base conversational](https://huggingface.co/DeepPavlov/rubert-base-cased-conversational)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создание вопросов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем решать задачу классификации пары предложений. На вход подаются два предложения, разделенные токеном [SEP]:\n",
    "1. Вопрос «Как относятся к X?» где Х – сущность в дательном падеже;\n",
    "2. Текст предложения.\n",
    "\n",
    "Следовательно, необходимо каждое предложение сопроводить вопросом. Для постановки сущности в дательный падеж воспользуемся библиотекой [pymorphy3](https://github.com/no-plagiarism/pymorphy3). Документация аналогична предыдущей версии библиотеки [pymorphy2](https://pymorphy2.readthedocs.io/en/stable/user/guide.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pymorphy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymorphy3\n",
    "morph = pymorphy3.MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью метода `morph.parse()` получаем все возможные морфологические разборы слова и берем первый вариант."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = morph.parse(train['entity'][0])\n",
    "word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " С помощью метода `.inflect()` ставим слово в нужный падеж."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dative = word[0].inflect({'datv'})\n",
    "dative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " С помощью метода `.restore_capitalization()` сохраняем исходный регистр.  Применяем это к каждому слову, входящему в название сущности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question(df):\n",
    "  sentences = []\n",
    "  for entity in df['entity'].values:\n",
    "    try:\n",
    "      dative_list = [pymorphy3.shapes.restore_capitalization(morph.parse(x)[0].inflect({'datv'}).word, x) for x in entity.split()]\n",
    "      final_form = ' '.join(dative_list)\n",
    "    except AttributeError:\n",
    "      final_form = entity\n",
    "    sentences.append(f'Как относятся к {final_form}?')\n",
    "  return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавим вопросы для объектов обучающей, валидационной и тестовой выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['question'] = question(train)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['question'] = question(validation)\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['question'] = question(test)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предобработка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходно метки датасета выглядят так: -1 - отрицательная тональность, 0 - нейтральная, 1 - положительная.\n",
    "\n",
    "При обучении нейросети мы выбираем предсказанный класс как позицию наибольшего значения (наибольшей вероятности). Следовательно, необходимо избавиться от отрицательных значений в метках класса.\n",
    "\n",
    "Применим преобразование к обучающей и валидационной выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {-1: 0, 0: 1, 1: 2}\n",
    "train['raw_label'] = train[\"label\"]\n",
    "train['label'] = train[\"raw_label\"].map(label_dict)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation['raw_label'] = validation[\"label\"]\n",
    "validation['label'] = validation[\"raw_label\"].map(label_dict)\n",
    "validation.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуем набор данных в датасет Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q datasets transformers evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "dataset_dict = DatasetDict({\"train\": Dataset.from_pandas(train),\n",
    "                            \"validation\": Dataset.from_pandas(validation),\n",
    "                            \"test\": Dataset.from_pandas(test)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы получили объект класса `DatasetDict`, который включает обучающую выборку, валидационную выборку и тестовую выборку."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы предобработать датасет, нам необходимо конвертировать текст в числа, которые может обработать модель. Это делается с помощью токенизатора."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"DeepPavlov/rubert-base-cased-conversational\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы хранить данные в формате датасета, мы будем использовать методы `Dataset.map()`. Метод `map()` применяет некоторую функцию к каждому элементу датасета.\n",
    "\n",
    "Давайте определим функцию, которая токенизирует наши входные данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"question\"], example[\"sentence\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = dataset_dict.map(tokenize_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`input_ids` содержит индексы, соответствующие токенам по словарю.\n",
    "\n",
    "Маски внимания (`attention_mask`) — это тензоры той же формы, что и тензор входных идентификаторов, заполненные 0 и 1: 1 означает, что соответствующие токены должны “привлекать внимание”, а 0 означает, что соответствующие токены не должны “привлекать внимание” (т.е. должны игнорироваться слоями внимания модели).\n",
    "\n",
    "`token_type_ids` указывает модели, какая часть входных данных является первым предложением, а какая вторым."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'input_ids\\n{tokenized_dataset[\"train\"][0][\"input_ids\"]}')\n",
    "print(f'attention_mask\\n{tokenized_dataset[\"train\"][0][\"attention_mask\"]}')\n",
    "print(f'token_type_ids\\n{tokenized_dataset[\"train\"][0][\"token_type_ids\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, отвечающая за объединение элементов внутри батча, называется `collate_function`. Это аргумент, который вы можете передать при создании `DataLoader`. По умолчанию это функция, которая просто преобразует объекты в тензоры PyTorch и объединяет их. В нашем случае это невозможно, поскольку входные данные, которые у нас есть, не будут иметь одинакового размера.\n",
    "\n",
    "Функция `collate_function` будет осуществлять корректный паддинг элементов выборки, которые мы хотим объединить в батч. Библиотека Transformers предоставляет эту функцию через класс `DataCollatorWithPadding`. При создании экземпляра требуется указать токенизатор: чтобы знать, какой токен использовать для паддинга и слева или справа нужно дополнять данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы хотим использовать GPU в случае, если у нас будет такая возможность (на CPU процесс может занять несколько часов вместо пары минут). Чтобы добиться этого, мы определим переменную `device` и «прикрепим» к видеокарте нашу модель и данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перейдем к тонкой настройке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека Transformers предоставляет класс `Trainer`, который помогает произвести тонкую настройку любой предобученной модели на вашем датасете. После предобработки данных, сделанных в прошлом разделе, вам останется сделать несколько шагов для определения `Trainer`.\n",
    "\n",
    "Первый шаг перед определением `Trainer` — задание класса `TrainingArguments`, который будет содержать все гиперпараметры для `Trainer` (для процессов обучения и валидации). Единственный аргумент, который обязательно нужно задать, — это каталог, в котором будет сохранена обученная модель. Для всего остального можно оставить значения по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "training_args = TrainingArguments(output_dir='./results',\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  report_to=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Второй шаг – задание модели. Мы будем использовать класс `AutoModelForSequenceClassification` с тремя классами:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После того как мы загрузили модель, мы можем определить `Trainer` и передать туда нужные объекты: `model`, `training_args`, обучающую и валидационную выборки, `data_collator` и `tokenizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для тонкой настройки модели на нашем датасете нужно вызвать метод `train()` у `Trainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы получить предсказания, мы можем использовать встроенную функцию `Trainer.predict()`. В качестве выходов модели получаем различные данные, нам нужны именно предсказания и истинные метки. Чтобы определить предсказанный класс, будем брать позицию максимального значения (`argmax`) по строке (`axis=-1`). Также осуществим обратное преобразование меток. Объединим все этапы в функцию `predict_labels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_labels(dataset):\n",
    "    output = trainer.predict(dataset)\n",
    "    logits, labels = output[:2]\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    reverse_label_dict = {v:k for k, v in label_dict.items()}\n",
    "    return [reverse_label_dict[x] for x in predictions]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запишем предсказания на валидационной выборке и добавим их в датасет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_predictions = predict_labels(tokenized_dataset[\"validation\"])\n",
    "print(len(validation_predictions))\n",
    "validation_predictions[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset[\"validation\"] = tokenized_dataset[\"validation\"].add_column(\"predictions\", validation_predictions)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем значение макро F1-меры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "def compute_metrics(preds, labels):\n",
    "    metric = evaluate.load(\"f1\")\n",
    "    return metric.compute(predictions=preds, references=labels, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(tokenized_dataset[\"validation\"][\"predictions\"], tokenized_dataset[\"validation\"][\"raw_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако в соревновании рейтинг строится по макро F1-мере, посчитанной только для положительного и отрицательного класса. Уберем нейтральный класс и посчитаем метрику."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_validation = tokenized_dataset[\"validation\"].filter(lambda example: example[\"raw_label\"]!=0)\n",
    "filtered_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_metrics(filtered_validation[\"predictions\"], filtered_validation[\"raw_label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Осуществим предсказания на тестовой выборке и запишем их в файл."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = predict_labels(tokenized_dataset[\"test\"])\n",
    "print(len(test_predictions))\n",
    "test_predictions[1925:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(test_predictions).to_csv('RuSentNE_predictions_Trainer.zip', compression={'method': 'zip', 'archive_name': 'RuSentNE_predictions_Trainer.csv'}, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итоговый zip-архив, содержащий внутри себя csv-файл, может быть отправлен на платформу CodaLab для получения метрики на тестовой выборке."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
