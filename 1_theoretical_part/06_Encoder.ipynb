{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">–ú–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–Ω–∫–æ–¥–µ—Ä–∞ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —ç–Ω–∫–æ–¥–µ—Ä–∞ –∏ –¥–µ–∫–æ–¥–µ—Ä–∞. –û–Ω–∞ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –≤ –∑–∞–¥–∞—á–∞—Ö –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞ –∏ –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á–∞—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π, –≥–¥–µ –≤—Ö–æ–¥–Ω–∞—è –∏ –≤—ã—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–æ–≥—É—Ç –∏–º–µ—Ç—å —Ä–∞–∑–Ω—É—é –¥–ª–∏–Ω—É (sequence-to-sequence)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-content/L06/out/transformer_architecture.png\" width=\"450\"></center>\n",
    "\n",
    "<center><em>–ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞</em></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/1706.03762\">Attention Is All You Need</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–Ω–∞–∫–æ –±–ª–æ–∫–∏ —ç–Ω–∫–æ–¥–µ—Ä–∞ –∏ –¥–µ–∫–æ–¥–µ—Ä–∞ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "- –ú–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ–∫–æ–¥–µ—Ä–∞ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ (Generative Pre-trained Transformers, GPT)\n",
    "- –ú–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–Ω–∫–æ–¥–µ—Ä–∞ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –¥–ª—è –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á: –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–¥–Ω–æ–≥–æ –∏–ª–∏ –ø–∞—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —Ç–µ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏, –ø–æ–∏—Å–∫–∞ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å (Bidirectional Encoder Representations from Transformers, BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–µ–≥–æ–¥–Ω—è –º—ã –ø–æ–¥—Ä–æ–±–Ω–æ —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏ BERT –∏ –µ—ë –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á. BERT –≤–æ–∑–Ω–∏–∫ –∫–∞–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –Ω–µ–¥–æ—á–µ—Ç–æ–≤ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –º–æ–¥–µ–ª–µ–π, –ø–æ—ç—Ç–æ–º—É —Ä–∞—Å—Å–∫–∞–∑ –ø—Ä–æ –Ω–µ–≥–æ –º—ã –Ω–∞—á–Ω–µ–º –Ω–µ–º–Ω–æ–≥–æ –∏–∑–¥–∞–ª–µ–∫–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü–µ—Ä–≤–∞—è –º–æ–¥–µ–ª—å –Ω–∞ —É–ª–∏—Ü–µ –°–µ–∑–∞–º ‚Äî ELMo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å ELMo –±—ã–ª–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ —Å—Ç–∞—Ç—å–µ:\n",
    "* [[paper] üéì Peters M. E. et al. (2018). Deep contextualized word representations](https://arxiv.org/abs/1802.05365)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L06/elmo.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/1802.05365\">Deep contextualized word representations</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–∑–ª–∏—á–Ω—ã–º –∑–Ω–∞—á–µ–Ω–∏—è–º —Å–ª–æ–≤–∞ *play* —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Ä–∞–∑–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã\n",
    "—É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è. –ù—É–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –∑–Ω–∞—á–µ–Ω–∏–µ —Å–ª–æ–≤–∞, –Ω–æ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—É—é\n",
    "–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é ‚Äî **–∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ\n",
    "–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤**. –ö–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –ø—Ä–∏—Å–≤–∞–∏–≤–∞—é—Ç —Å–ª–æ–≤–∞–º —Ä–∞–∑–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏—Ö —Å–µ–º–∞–Ω—Ç–∏–∫–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è. –¢–∞–∫–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –≤—ã—á–∏—Å–ª—è—é—Ç—Å—è –ø–æ—Å—Ä–µ–¥—Å—Ç–≤–æ–º –æ–±—É—á–µ–Ω–∏—è —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏: ELMo = **E**mbeddings from **L**anguage **Mo**dels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L06/elmo_2.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/1810.04805\">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –æ–±—É—á–µ–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–æ–≤ ELMo –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å (bidirectional Language Model –∏–ª–∏ biLM), –æ—Å–Ω–æ–≤–∞–Ω–Ω–∞—è –Ω–∞ —Ä–µ–∫—É—Ä—Ä–µ–Ω—Ç–Ω—ã—Ö –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç—è—Ö.\n",
    "\n",
    "–ú–æ–¥–µ–ª—å –≤—ã—á–∏—Å–ª—è–µ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –ø–æ—è–≤–ª–µ–Ω–∏—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–æ–≤ $t_1, t_2, \\dots, t_N$ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–≤—É—Ö –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞:\n",
    "- –ø—Ä—è–º–æ–π (forward):\n",
    "  - —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º —Å–ª–æ–≤–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø–µ—Ä–µ–¥ –Ω–∏–º\n",
    "  - –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å $t_k$ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ –ø—Ä–µ–¥—à–µ—Å—Ç–≤—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ $t_1, ..., t_{k-1}$\n",
    "- –æ–±—Ä–∞—Ç–Ω—ã–π (backward):\n",
    "  - —É—á–∏—Ç—ã–≤–∞–µ—Ç—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–ª–æ–≤–µ –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –ø–æ—Å–ª–µ –Ω–µ–≥–æ\n",
    "  - –æ—Ü–µ–Ω–∏–≤–∞–µ—Ç—Å—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å $t_k$ –ø—Ä–∏ —É—Å–ª–æ–≤–∏–∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ $t_{k+1}, \\dots, t_N$\n",
    "\n",
    "–í–∞–∂–Ω–æ: ELMo –Ω–µ –∏–º–µ–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞–º.\n",
    "\n",
    "–ú–æ–¥–µ–ª—å —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –¥–≤—É—Ö —Å–ª–æ–µ–≤, –∫–∞–∂–¥—ã–π –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –¥–≤—É–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–Ω—É—é —Å–µ—Ç—å –¥–æ–ª–≥–æ–π –∫—Ä–∞—Ç–∫–æ—Å—Ä–æ—á–Ω–æ–π –ø–∞–º—è—Ç–∏ (biLSTM).\n",
    "\n",
    "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –∏–∑ –ø—Ä—è–º–æ–≥–æ –∏ –æ–±—Ä–∞—Ç–Ω–æ–≥–æ –ø—Ä–æ—Ö–æ–¥–∞ –Ω–∞ –ø–µ—Ä–≤–æ–º —Å–ª–æ–µ —Ñ–æ—Ä–º–∏—Ä—É–µ—Ç –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–¥–∞—é—Ç—Å—è –Ω–∞ –≤—Ö–æ–¥ –≤—Ç–æ—Ä–æ–≥–æ —Å–ª–æ—è –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "–†–µ–∑—É–ª—å—Ç–∏—Ä—É—é—â–∏–µ –≤–µ–∫—Ç–æ—Ä—ã ‚Äî –≤–∑–≤–µ—à–µ–Ω–Ω–∞—è —Å—É–º–º–∞ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —Å–ª–æ–≤ –∏ –¥–≤—É—Ö –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –∏ –≤—Ç–æ—Ä–æ–≥–æ —Å–ª–æ–µ–≤ biLSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L06/elmo_architecture.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://www.researchgate.net/publication/359157231_Identifying_Contradictions_in_the_Legal_Proceedings_Using_Natural_Language_Models\">Identifying Contradictions in the Legal Proceedings Using Natural Language Models</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–∫–æ–ª—å–∫—É –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –∑–∞–¥–∞—á–µ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è, –µ–π –Ω–µ —Ç—Ä–µ–±—É—é—Ç—Å—è —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã, –ø–æ—è–≤–ª—è–µ—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª—å—à–∏–µ –æ–±—ä–µ–º—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ú–æ–¥–µ–ª—å –≤—ã—É—á–∏–≤–∞–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –æ–±—â–∏–µ –∑–Ω–∞–Ω–∏—è –æ —è–∑—ã–∫–µ, –Ω–µ –ø—Ä–∏–≤—è–∑—ã–≤–∞—è—Å—å –∫ –∫–∞–∫–æ–π-–ª–∏–±–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–µ.\n",
    "\n",
    "ELMo —Å—Ç–∞–ª–∞ –≤–∞–∂–Ω—ã–º —à–∞–≥–æ–º –∫ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏—é —Ç—Ä–∞–Ω—Å—Ñ–µ—Ä–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ NLP. –í—ã—Ö–æ–¥—ã –º–æ–¥–µ–ª–∏ ELMo –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –∫–∞–∫ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞.\n",
    "\n",
    "–í —Å–ª—É—á–∞–µ word2vec –∫–∞–∂–¥–æ–º—É —Å–ª–æ–≤—É —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –æ–¥–∏–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–π  –≤–µ–∫—Ç–æ—Ä, –∏ —ç—Ç–∏ –≤–µ–∫—Ç–æ—Ä—ã —Å–ª–æ–≤ –º–æ–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è—Ç—å –∏ –∑–∞–≥—Ä—É–∂–∞—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏.\n",
    "ELMo –∂–µ —Å—Ç—Ä–æ–∏—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ –∑–∞–≤–∏—Å–∏–º—ã–µ –≤–µ–∫—Ç–æ—Ä—ã. –ß—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –≤–µ–∫—Ç–æ—Ä—ã —Å–ª–æ–≤ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –Ω—É–∂–Ω–æ —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–ø—É—Å—Ç–∏—Ç—å –≤—Å—ë —ç—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —á–µ—Ä–µ–∑ –º–æ–¥–µ–ª—å. –ü—Ä–∏ —ç—Ç–æ–º –æ–±—É—á–µ–Ω–∏–µ —É–∂–µ –Ω–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç—Å—è ‚Äî –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ —Ä–µ–∂–∏–º–µ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤.\n",
    "\n",
    "–≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å –º–Ω–æ–≥–æ–∑–Ω–∞—á–Ω–æ—Å—Ç—å —Å–ª–æ–≤. –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è —Å–ª–æ–≤–∞ *bank* ELMo —Å–æ–∑–¥–∞—Å—Ç —Ä–∞–∑–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: –æ–¥–∏–Ω ‚Äî –æ—Ç—Ä–∞–∂–∞—é—â–∏–π –∑–Ω–∞—á–µ–Ω–∏–µ \"–±–µ—Ä–µ–≥ —Ä–µ–∫–∏\", –¥—Ä—É–≥–æ–π ‚Äî –¥–ª—è –∑–Ω–∞—á–µ–Ω–∏—è \"—Ñ–∏–Ω–∞–Ω—Å–æ–≤–∞—è –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L06/bank_embeddings.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://github.com/hengluchang/visualizing_contextual_vectors\">Visualizing ELMo Contextual Vectors (code for generating figure)</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –í—Ç–æ—Ä–∞—è –º–æ–¥–µ–ª—å –Ω–∞ —É–ª–∏—Ü–µ –°–µ–∑–∞–º ‚Äî BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å BERT –±—ã–ª–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∞ –≤ —Å—Ç–∞—Ç—å–µ:\n",
    "* [[paper] üéì Devlin J. et al. (2019). BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)\n",
    "\n",
    "–ò–¥–µ–∏, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω—ã —Ä–∞–Ω–µ–µ –∏ —É–¥–∞—á–Ω–æ –æ–±—ä–µ–¥–∏–Ω–∏–ª–∏—Å—å –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –º–æ–¥–µ–ª–∏ BERT:\n",
    "- –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –∑–∞–¥–∞—á–µ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–æ—Ç–æ—Ä–∞—è –Ω–µ —Ç—Ä–µ–±—É–µ—Ç —Ä–∞–∑–º–µ—Ç–∫–∏, –∏ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏ ‚Äî ELMo\n",
    "- –º–µ—Ö–∞–Ω–∏–∑–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –±–µ–∑ RNN, ‚Äî –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä\n",
    "- –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ–π —á–∞—Å—Ç–∏ –º–æ–¥–µ–ª–∏ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ (–¥–µ–∫–æ–¥–µ—Ä) ‚Äî GPT\n",
    "\n",
    "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ–∫ ELMo: –∞–Ω–∞–ª–∏–∑–∏—Ä—É—è –ª–µ–≤—ã–π –∏ –ø—Ä–∞–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ—Ç–¥–µ–ª—å–Ω–æ —Å –ø–æ–º–æ—â—å—é biLSTM, –º—ã –º–æ–∂–µ–º —Ç–µ—Ä—è—Ç—å —á–∞—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏. –•–æ—Ç–µ–ª–æ—Å—å –±—ã —É—á–∏—Ç—ã–≤–∞—Ç—å –ª–µ–≤—ã–π –∏ –ø—Ä–∞–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ.\n",
    "\n",
    "–ù–æ–≤—à–µ—Å—Ç–≤–æ BERT ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ **—ç–Ω–∫–æ–¥–µ—Ä–∞** –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å \"–æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ\" –≤–Ω–∏–º–∞–Ω–∏–µ–º –≤–µ–∫—Ç–æ—Ä—ã —Å–ª–æ–≤.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L06/bert.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://botpenguin.com/glossary/bert\">What is BERT?</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ —Å–æ–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤ —ç–Ω–∫–æ–¥–µ—Ä–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞.\n",
    "\n",
    "–ù–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª—å –ø–æ–ª—É—á–∞–µ—Ç –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–æ–≤, –Ω–∞ –≤—ã—Ö–æ–¥–µ –æ—Ç–¥–∞–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞, –æ–±–æ–≥–∞—â–µ–Ω–Ω–æ–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º. –≠–Ω–∫–æ–¥–µ—Ä —Å–æ–¥–µ—Ä–∂–∏—Ç –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è (Self-Attention), –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –∫ –∫–∞–∂–¥–æ–º—É —Ç–æ–∫–µ–Ω—É –∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç —É–ª–∞–≤–ª–∏–≤–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L06/bert_input.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://jalammar.github.io/illustrated-bert/\">The Illustrated BERT</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–≤–µ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏:\n",
    "- –±–∞–∑–æ–≤–∞—è (base): 12 —Å–ª–æ–µ–≤, —Ä–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è ‚Äî 768, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ‚Äî 110 –º–∏–ª–ª–∏–æ–Ω–æ–≤\n",
    "- —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è (large): 24 —Å–ª–æ—è, —Ä–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è ‚Äî 1024, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ‚Äî 340 –º–∏–ª–ª–∏–æ–Ω–æ–≤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L06/bert_base_large.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://jalammar.github.io/illustrated-bert/\">The Illustrated BERT</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BERT –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ –¥–≤—É—Ö –∑–∞–¥–∞—á–∞—Ö:\n",
    "- –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —è–∑—ã–∫–æ–≤–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ (masked language modeling, MLM)\n",
    "- –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (next sentence prediction, NSP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ú–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —è–∑—ã–∫–æ–≤–æ–µ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "15% —Å–ª—É—á–∞–π–Ω–æ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ –≤—Å–µ–º—É –∫–æ—Ä–ø—É—Å—É –º–∞—Å–∫–∏—Ä—É–µ—Ç—Å—è ‚Äî –∑–∞–º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ —Å–ø–µ—Ü—Ç–æ–∫–µ–Ω `[MASK]`. –ó–∞–¥–∞—á–∞ –º–æ–¥–µ–ª–∏ ‚Äî –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ç–æ–∫–µ–Ω –Ω–∞ –º–µ—Å—Ç–µ –º–∞—Å–∫–∏.\n",
    "\n",
    "–ï—Å–ª–∏ –º–æ–¥–µ–ª—å –≤—Å–µ–≥–¥–∞ –¥–æ–ª–∂–Ω–∞ –±—É–¥–µ—Ç –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω–æ–µ —Å–ª–æ–≤–æ —Ç–æ–ª—å–∫–æ –¥–ª—è –º–∞—Å–æ–∫, —Ç–æ –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤ –≤–µ–∫—Ç–æ—Ä—ã –±—É–¥—É—Ç –æ–±—É—á–∞—Ç—å—Å—è —Ö—É–∂–µ. –ù—É–∂–Ω–æ \"–æ–±–º–∞–Ω—É—Ç—å\" –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –æ–Ω–∞ —Å–º–æ—Ç—Ä–µ–ª–∞ –Ω–∞ –≤—Å–µ —Å–ª–æ–≤–∞ –≤—Ö–æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.\n",
    "\n",
    "–°—Ä–µ–¥–∏ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö 15% —Ç–æ–∫–µ–Ω–æ–≤:\n",
    "- 80% –º–∞—Å–∫–∏—Ä—É—é—Ç—Å—è: my dog is `[MASK]`\n",
    "- 10% –º–µ–Ω—è—é—Ç—Å—è –Ω–∞ —Å–ª—É—á–∞–π–Ω–æ–µ —Å–ª–æ–≤–æ: my dog is apple\n",
    "- 10% –æ—Å—Ç–∞—é—Ç—Å—è: my dog is hairy\n",
    "\n",
    "–≠—Ç–æ —Ä–∞–∑–±–∏–µ–Ω–∏–µ –º–µ–Ω—è–µ—Ç—Å—è –Ω–∞ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–µ –æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L06/masked_language_modeling.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://jalammar.github.io/illustrated-bert/\">The Illustrated BERT</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–µ–Ω–∏–µ –Ω–∞ –∑–∞–¥–∞—á–µ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã —Ç–æ–∫–µ–Ω–æ–≤. –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä—ã –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á–∞—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–º–∏–º–æ –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å–ª–æ–≤, —Ö–æ—Ç–µ–ª–æ—Å—å –±—ã –ø–æ–ª—É—á–∞—Ç—å —Ç–∞–∫–∂–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –î–ª—è —ç—Ç–æ–≥–æ –ø–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å, —Å–ª–µ–¥—É–µ—Ç –ª–∏ –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∑–∞ –¥—Ä—É–≥–∏–º.\n",
    "\n",
    "–ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Ä–∞–∑–¥–µ–ª–µ–Ω—ã —Å–ø–µ—Ü—Ç–æ–∫–µ–Ω–æ–º `[SEP]`. –ó–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –æ—Ç–≤–µ—á–∞–µ—Ç —Å–ø–µ—Ü—Ç–æ–∫–µ–Ω `[CLS]`. –û–Ω —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ–±–æ –≤—Å–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–∏. –í—ã—Ö–æ–¥ `[CLS]` —Ç–æ–∫–µ–Ω–∞ –ø—Ä–æ–ø—É—Å–∫–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π —Ä–∞–∑–º–µ—Ä–∞ 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L06/next_sentence_prediction.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://jalammar.github.io/illustrated-bert/\">The Illustrated BERT</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–ª–µ–¥—É—é—Ç –¥—Ä—É–≥ –∑–∞ –¥—Ä—É–≥–æ–º –≤ –∫–æ—Ä–ø—É—Å–µ.\n",
    "\n",
    "–í—Ö–æ–¥: `[CLS] the man went to the [MASK] store [SEP] he bought a gallon [MASK] milk [SEP]`\n",
    "\n",
    "–ú–µ—Ç–∫–∞: `IsNext`\n",
    "\n",
    "–û—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –≤—ã–±–∏—Ä–∞—é—Ç—Å—è —Å–ª—É—á–∞–π–Ω–æ.\n",
    "\n",
    "–í—Ö–æ–¥: `[CLS] the man [MASK] to the store [SEP] penguin [MASK] are flight ##less birds [SEP]`\n",
    "\n",
    "–ú–µ—Ç–∫–∞: `NotNext`\n",
    "\n",
    "–û–±—É—á–µ–Ω–∏–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ –¥–≤—É–º –∑–∞–¥–∞—á–∞–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ. –ó–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å —Å—á–∏—Ç–∞–µ—Ç—Å—è –æ—Ç–¥–µ–ª—å–Ω–æ –¥–ª—è –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ —Ç–æ–∫–µ–Ω—É `[MASK]` –∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ–≤–∞ –ø–æ —Ç–æ–∫–µ–Ω—É `[CLS]`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ [Transformers üõ†Ô∏è[doc]](https://huggingface.co/docs/transformers/index) —Å–æ–∑–¥–∞–Ω–∞ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ–º HuggingFace ‚Äî —ç—Ç–æ –ø–ª–∞—Ç—Ñ–æ—Ä–º–∞ –∏ —Å–æ–æ–±—â–µ—Å—Ç–≤–æ –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –∏ –æ–±–º–µ–Ω–∞ –º–æ–¥–µ–ª—è–º–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞ (–∏ –Ω–µ —Ç–æ–ª—å–∫–æ). –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –≥–æ—Ç–æ–≤—ã–µ –º–æ–¥–µ–ª–∏, —É–∑–Ω–∞—Ç—å –æ–± –∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –∏ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–∏, –∞ —Ç–∞–∫–∂–µ –¥–µ–ª–∏—Ç—å—Å—è —Å–≤–æ–∏–º–∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∞–º–∏ –∏ –∏–¥–µ—è–º–∏ —Å –¥—Ä—É–≥–∏–º–∏ —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞–º–∏. –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ [Transformers üõ†Ô∏è[doc]](https://huggingface.co/docs/transformers/index) –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å –æ—Ç–∫—Ä—ã—Ç—ã–º–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –±–∏–±–ª–∏–æ—Ç–µ–∫–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω—ã –∫–ª–∞—Å—Å—ã –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä ‚Äî –≤ —Ç–æ–º —á–∏—Å–ª–µ –¥–ª—è –º–æ–¥–µ–ª–∏ [BERT üõ†Ô∏è[doc]](https://huggingface.co/docs/transformers/model_doc/bert).\n",
    "\n",
    "–ù–∞–º –ø–æ–Ω–∞–¥–æ–±—è—Ç—Å—è –∫–ª–∞—Å—Å—ã `BertTokenizer` [üõ†Ô∏è[doc]](https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertTokenizer) –∏ `BertForMaskedLM` [üõ†Ô∏è[doc]](https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertForMaskedLM). –î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–µ—Ç–æ–¥ `.from_pretrained()`.\n",
    "\n",
    "BERT ‚Äî —ç—Ç–æ –æ–±—â–µ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã. –° –µ—ë –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±—ã–ª–∏ –æ–±—É—á–µ–Ω—ã –º–æ–¥–µ–ª–∏ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —è–∑—ã–∫–∞—Ö –∏ –¥–∞—Ç–∞—Å–µ—Ç–∞—Ö. –í—Å–µ –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–∞ HuggingFace, –º–æ–∂–Ω–æ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤ —Ä–∞–∑–¥–µ–ª–µ [Models üõ†Ô∏è[doc]](https://huggingface.co/models). –ß—Ç–æ–±—ã –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å, –Ω—É–∂–Ω–æ —É–∫–∞–∑–∞—Ç—å –µ—ë –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BertTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ [BERT base cased üõ†Ô∏è[doc]](https://huggingface.co/bert-base-cased) –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from IPython.display import clear_output\n",
    "\n",
    "en_tz = BertTokenizer.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º –∞–Ω–≥–ª–∏–π—Å–∫–æ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–∞ `.tokenize()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"He remains characteristically confident and optimistic.\"\n",
    "tokenized_sent = en_tz.tokenize(sent)\n",
    "tokenized_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ –∫–∞–∫–æ–µ-—Ç–æ —Å–ª–æ–≤–æ –Ω–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–æ –≤ —Å–ª–æ–≤–∞—Ä–µ —Ü–µ–ª–∏–∫–æ–º, –ø—Ä–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –æ–Ω–æ –¥–µ–ª–∏—Ç—Å—è –Ω–∞ –ø–æ–¥—Å–ª–æ–≤–∞.\n",
    "\n",
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫–∏–µ –∏–Ω–¥–µ–∫—Å—ã –≤ —Å–ª–æ–≤–∞—Ä–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å–ª–æ–≤–∞–º, —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–∞ `convert_tokens_to_ids()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_tz.convert_tokens_to_ids(tokenized_sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –¥–ª—è –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã BERT –¥–ª—è –¥—Ä—É–≥–æ–≥–æ —è–∑—ã–∫–∞ (–Ω–µ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ) –∏ –ø–æ–ø—Ä–æ–±—É–µ–º –ø–æ–¥–æ–±—Ä–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ, –≥–¥–µ –ø—Ä–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –æ–¥–Ω–æ –∏–ª–∏ –±–æ–ª–µ–µ —Å–ª–æ–≤ –¥–µ–ª—è—Ç—Å—è –Ω–∞ –ø–æ–¥—Å–ª–æ–≤–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ—Ä –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_tz = BertTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_tz.tokenize(\"–°–µ–ª—å—Å–∫–æ—Ö–æ–∑—è–π—Å—Ç–≤–µ–Ω–Ω–æ-–º–∞—à–∏–Ω–æ—Å—Ç—Ä–æ–∏—Ç–µ–ª—å–Ω—ã–π\"), ru_tz.tokenize(\n",
    "    \"–ß–∞—Å—Ç–Ω–æ–ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å–∫–∏–π\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ—Ä –¥–ª—è –Ω–µ–º–µ—Ü–∫–æ–≥–æ —è–∑—ã–∫–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_tz = BertTokenizer.from_pretrained(\"google-bert/bert-base-german-cased\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_tz.tokenize(\"die Aufmerksamkeitsdefizitst√∂rung\"), de_tz.tokenize(\"das Ampelm√§nnchen\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BertForMaskedLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º —Å–∞–º—É –º–æ–¥–µ–ª—å [BERT base cased üõ†Ô∏è[doc]](https://huggingface.co/bert-base-cased) –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForMaskedLM\n",
    "\n",
    "en_model = BertForMaskedLM.from_pretrained(\"google-bert/bert-base-cased\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–∫–æ–ª—å–∫—É –º–æ–¥–µ–ª—å –æ–±—É—á–∞–ª–∞—Å—å –Ω–∞ –∑–∞–¥–∞—á–µ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è, –æ–Ω–∞ —Å–ø–æ—Å–æ–±–Ω–∞ –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–µ —Å–ª–æ–≤–∞ –Ω–∞ –º–µ—Å—Ç–µ —Å–ø–µ—Ü—Ç–æ–∫–µ–Ω–∞ `[MASK]`.\n",
    "\n",
    "–ù–∞–ø–∏—à–µ–º —Ñ—É–Ω–∫—Ü–∏—é `predict_mask`, –∫–æ—Ç–æ—Ä–∞—è –Ω–∞—Ö–æ–¥–∏—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è –º–∞—Å–∫–∏.\n",
    "- –î–æ–±–∞–≤–∏–º —Å–ø–µ—Ü—Ç–æ–∫–µ–Ω—ã `[CLS]` –∏ `[SEP]`\n",
    "- –¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç (`text`)\n",
    "- –û–ø—Ä–µ–¥–µ–ª–∏–º –∏–Ω–¥–µ–∫—Å –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞\n",
    "- –ü–µ—Ä–µ–≤–µ–¥–µ–º —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–ª–æ–≤–∞ (`tokenized_text`) –≤ –∏–Ω–¥–µ–∫—Å—ã\n",
    "- –ó–∞–ø–∏—à–µ–º –∏–Ω–¥–µ–∫—Å—ã –≤ —Ç–µ–Ω–∑–æ—Ä\n",
    "- –ü—Ä–∏–º–µ–Ω–∏–º –º–æ–¥–µ–ª—å –∫ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–º—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é\n",
    "- –ó–∞–ø–∏—à–µ–º –≤—ã—Ö–æ–¥—ã –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ–≤–∞\n",
    "- –ü—Ä–∏–º–µ–Ω–∏–º Softmax (`torch.softmax()`) –∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º –¥–ª—è –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ª–æ–≤–∞, –∫–æ—Ç–æ—Ä–æ–µ –Ω–∞–π–¥–µ–º —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –≤—ã—Ö–æ–¥–æ–≤ –º–æ–¥–µ–ª–∏ (`predictions`) –ø–æ –∏–Ω–¥–µ–∫—Å—É (`masked_index`)\n",
    "- –ó–∞–ø–∏—à–µ–º k —Å–∞–º—ã—Ö –±–æ–ª—å—à–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤–µ—Å–æ–≤ –∏ –∏—Ö –∏–Ω–¥–µ–∫—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—Ç —Å–ª–æ–≤–∞–º –≤ —Å–ª–æ–≤–∞—Ä–µ\n",
    "- –ü—Ä–æ–π–¥–µ–º –≤ —Ü–∏–∫–ª–µ –ø–æ —Å–ø–∏—Å–∫—É –∏–Ω–¥–µ–∫—Å–æ–≤:\n",
    "  - –ü–µ—Ä–µ–≤–µ–¥–µ–º –∫–∞–∂–¥—ã–π –∏–Ω–¥–µ–∫—Å –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ç–æ–∫–µ–Ω\n",
    "  - –ó–∞–ø–∏—à–µ–º –µ–≥–æ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def predict_mask(tokenizer, model, text, top_k=5):\n",
    "\n",
    "    text = f\"[CLS] {text} [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(text)\n",
    "    masked_index = tokenized_text.index(\"[MASK]\")\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    tokens_tensor = torch.tensor([indexed_tokens])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor)\n",
    "        predictions = outputs[\"logits\"].squeeze()  # token_len x vocabulary_size\n",
    "\n",
    "    probs = torch.softmax(predictions[masked_index, :], dim=-1)\n",
    "    top_k_weights, top_k_indices = torch.topk(probs, top_k)\n",
    "\n",
    "    for i, pred_idx in enumerate(top_k_indices):\n",
    "        predicted_token = tokenizer.convert_ids_to_tokens([pred_idx])[0]\n",
    "        token_weight = top_k_weights[i]\n",
    "        print(\n",
    "            \"[MASK]: '%s'\" % predicted_token,\n",
    "            \" | weights:\",\n",
    "            round(token_weight.item(), 3),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_mask(en_tz, en_model, \"My [MASK] is so cute.\", top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã BERT –¥–ª—è –¥—Ä—É–≥–æ–≥–æ —è–∑—ã–∫–∞ (–Ω–µ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ) –∏ –ø—Ä–∏–º–µ–Ω–∏–º —Ñ—É–Ω–∫—Ü–∏—é –∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é, –≥–¥–µ –æ–¥–Ω–æ —Å–ª–æ–≤–æ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ—Ä –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru_model = BertForMaskedLM.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_mask(ru_tz, ru_model, \"–ú–æ—è [MASK] –æ—á–µ–Ω—å –º–∏–ª–∞—è.\", top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ—Ä –¥–ª—è –Ω–µ–º–µ—Ü–∫–æ–≥–æ —è–∑—ã–∫–∞:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "de_model = BertForMaskedLM.from_pretrained(\"google-bert/bert-base-german-cased\")\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_mask(de_tz, de_model, \"Meine [MASK] ist sehr nett.\", top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏-—ç–Ω–∫–æ–¥–µ—Ä—ã –∏ –∏—Ö —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–ª–µ –ø–æ—è–≤–ª–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ BERT —Å—Ç–∞–ª–∏ –ø–æ—è–≤–ª—è—Ç—å—Å—è –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–Ω–∫–æ–¥–µ—Ä–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞.\n",
    "\n",
    "**–ú–æ–¥–µ–ª—å RoBERTa**\n",
    "\n",
    "[[paper] üéì Liu Y. et al. (2019). RoBERTa: A Robustly Optimized BERT Pretraining Approach](https://arxiv.org/abs/1907.11692)\n",
    "\n",
    "–Ø–≤–ª—è–µ—Ç—Å—è —É–ª—É—á—à–µ–Ω–Ω–æ–π –≤–µ—Ä—Å–∏–µ–π –º–æ–¥–µ–ª–∏ BERT –∑–∞ —Å—á–µ—Ç –±–æ–ª–µ–µ —Ç—â–∞—Ç–µ–ª—å–Ω–æ–≥–æ –ø–æ–¥–±–æ—Ä–∞ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "- –ë–æ–ª—å—à–∏–π –æ–±—ä–µ–º –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö (–≤ 10 —Ä–∞–∑ –±–æ–ª—å—à–µ ‚Äî —Å 16 –ì–± –¥–æ 160 –ì–±).\n",
    "- –£–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –±–∞—Ç—á–∞ (—Å 256 –¥–æ 8 000) –∏ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ —Å–ª–æ–≤–∞—Ä—è (—Å 30 000 –¥–æ 50 000 —Å–ª–æ–≤).\n",
    "- –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏–µ: –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è 10 —Ä–∞–∑–Ω—ã—Ö —Å–ø–æ—Å–æ–±–æ–≤ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–∏—è, —á–µ—Ä–µ–∑ –∫–∞–∂–¥—ã–µ 4 –ø—Ä–æ—Ö–æ–¥–∞ –ø–æ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –º–µ–Ω—è–µ—Ç—Å—è –ø–æ–∑–∏—Ü–∏—è –º–∞—Å–∫–∏—Ä—É–µ–º–æ–≥–æ —Ç–æ–∫–µ–Ω–∞, —á—Ç–æ –ø–æ–º–æ–≥–∞–µ—Ç –º–æ–¥–µ–ª–∏ –ª—É—á—à–µ –ø–æ–Ω–∏–º–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n",
    "- –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –Ω–∞ –∑–∞–¥–∞—á–µ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è, –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏—Å–∫–ª—é—á–∞–µ—Ç—Å—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ú–æ–¥–µ–ª—å ALBERT**\n",
    "\n",
    "[[paper] üéì Lan Zh. et al. (2020). ALBERT: A Lite BERT for Self-supervised Learning of Language Representations](https://arxiv.org/abs/1909.11942)\n",
    "\n",
    "–°–æ–∫—Ä–∞—â–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –º–æ–¥–µ–ª—å—é BERT –±–µ–∑ —Å–Ω–∏–∂–µ–Ω–∏—è –∫–∞—á–µ—Å—Ç–≤–∞.\n",
    "- –§–∞–∫—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω–Ω–∞—è –ø–∞—Ä–∞–º–µ—Ç—Ä–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞\n",
    "\n",
    " –î–ª—è –º–æ–¥–µ–ª–∏ BERT E = H (E ‚Äî —Ä–∞–∑–º–µ—Ä —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤, H ‚Äî —Ä–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è). –°–ª–æ–π —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∏–º–µ–µ—Ç —Ä–∞–∑–º–µ—Ä V √ó E (V ‚Äî —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è). –ü—Ä–∏ —É–≤–µ–ª–∏—á–µ–Ω–∏–∏ —Ä–∞–∑–º–µ—Ä–∞ —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è  —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ä —Å–ª–æ—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤. –î–ª—è BERT-base E = H = 768, –¥–ª—è BERT-large E = H = 1024\n",
    "\n",
    " –ß—Ç–æ–±—ã —Ä–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è –∏ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –±—ã–ª–∏ —Ä–∞–∑–Ω—ã–º–∏, –ø–æ—Å–ª–µ —Å–ª–æ—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ (V √ó E) –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–π —Å–ª–æ–π (E √ó H). –ü–æ–∑–≤–æ–ª—è–µ—Ç —É–≤–µ–ª–∏—á–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Å–∫—Ä—ã—Ç–æ–≥–æ —Å–ª–æ—è, –Ω–µ –º–µ–Ω—è—è —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞. –î–ª—è –º–æ–¥–µ–ª–∏ ALBERT E = 128, H = 4096.\n",
    "\n",
    "- –û–±–º–µ–Ω –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –º–µ–∂–¥—É —Å–ª–æ—è–º–∏\n",
    "\n",
    " –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã —Å–µ—Ç–µ–π –Ω–∞ –æ—Å–Ω–æ–≤–µ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –ø–æ–ª–∞–≥–∞—é—Ç—Å—è –Ω–∞ –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å —Å–ª–æ–µ–≤. –û–¥–Ω–∞–∫–æ –±—ã–ª–æ –∑–∞–º–µ—á–µ–Ω–æ, —á—Ç–æ –Ω–µ–π—Ä–æ—Å–µ—Ç—å –≤—ã—É—á–∏–≤–∞–µ—Ç—Å—è –≤—ã–ø–æ–ª–Ω—è—Ç—å —Å—Ö–æ–∂–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –Ω–∞ —Ä–∞–∑–Ω—ã—Ö —Å–ª–æ—è—Ö. –≠—Ç–∞ –≤–æ–∑–º–æ–∂–Ω–∞—è –∏–∑–±—ã—Ç–æ—á–Ω–æ—Å—Ç—å —É—Å—Ç—Ä–∞–Ω—è–µ—Ç—Å—è –≤ ALBERT —Å –ø–æ–º–æ—â—å—é –æ–±–º–µ–Ω–∞ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ –º–µ–∂–¥—É —Å–ª–æ—è–º–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è –∏ –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω—ã–º–∏ —Å–ª–æ—è–º–∏.\n",
    "\n",
    "- –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "\n",
    " –í–º–µ—Å—Ç–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–æ–≤–∞—è –∑–∞–¥–∞—á–∞: –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä—è–¥–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (Sentence Order Prediction, SOP).  –ü–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã ‚Äî –¥–≤–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã ‚Äî —Ç–µ –∂–µ, –Ω–æ —Å –∏—Ö –∏–∑–º–µ–Ω–µ–Ω–Ω—ã–º –ø–æ—Ä—è–¥–∫–æ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L06/BERT_fine_tuning.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/1810.04805\">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –∂–µ —Å—Ä–∞–≤–Ω–∏–≤–∞—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–±–æ—Ç—ã –º–æ–¥–µ–ª–µ–π?\n",
    "\n",
    "–ú–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–Ω–∫–æ–¥–µ—Ä–∞ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è —Ç–æ–≥–æ, —á—Ç–æ–±—ã –ø–æ–ª—É—á–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ–∫—Ç–æ—Ä–Ω—ã–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Å–ª–æ–≤ –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –î–∞–ª–µ–µ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –ø—Ä–∏–º–µ–Ω—è—é—Ç—Å—è –¥–ª—è —Ä–µ—à–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∑–∞–¥–∞—á:\n",
    "\n",
    "- –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–∞—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π\n",
    "  - [[doc] üõ†Ô∏è Multi-Genre Natural Language Inference (MultiNLI)](https://cims.nyu.edu/~sbowman/multinli/) ‚Äî –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ª–æ–≥–∏—á–µ—Å–∫–æ–π —Å–≤—è–∑–∏ –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–∞–º–∏ (–¥–ª—è –¥–≤—É—Ö —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–π A –∏ B –≤—ã—è—Å–Ω–∏—Ç—å, —Å–ª–µ–¥—É–µ—Ç –ª–∏ B –∏–∑ A)\n",
    "  - [[doc] üõ†Ô∏è Microsoft Research Paraphrase Corpus (MRPC)](https://www.microsoft.com/en-us/download/details.aspx?id=52398) ‚Äî –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å, —è–≤–ª—è—é—Ç—Å—è –ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–∞—Ä–∞—Ñ—Ä–∞–∑–∞–º–∏ (–≤—ã—Ä–∞–∂–∞—é—Ç –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π —Å–º—ã—Å–ª)\n",
    "- –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–¥–Ω–æ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "  - [[doc] üõ†Ô∏è Corpus of Linguistic Acceptability (CoLA)](https://nyu-mll.github.io/CoLA/) ‚Äî –±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –ø–æ –ø—Ä–∏–µ–º–ª–µ–º–æ—Å—Ç–∏ (–ø—Ä–∏–µ–º–ª–µ–º—ã–µ, –Ω–µ–ø—Ä–∏–µ–º–ª–µ–º—ã–µ)\n",
    "  - [[doc] üõ†Ô∏è Stanford Sentiment Treebank (SST)](https://nlp.stanford.edu/sentiment/index.html) ‚Äî –±–∏–Ω–∞—Ä–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ (–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ, –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ)\n",
    "- –ø–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å\n",
    "  - [[doc] üõ†Ô∏è Stanford Question Answering Dataset (SQuAD)](https://rajpurkar.github.io/SQuAD-explorer/) ‚Äî –≤—ã–¥–µ–ª–∏—Ç—å –≤ —Ç–µ–∫—Å—Ç–µ –ø–æ–¥–ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å, –∫–æ—Ç–æ—Ä–∞—è —è–≤–ª—è–µ—Ç—Å—è –æ—Ç–≤–µ—Ç–æ–º –Ω–∞ –∑–∞–¥–∞–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å\n",
    "- —Ç–µ–≥–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏\n",
    "  - [[doc] üõ†Ô∏è CoNLL-2003](https://aclanthology.org/W03-0419.pdf) ‚Äî —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π (–∏–º–µ–Ω –ª—é–¥–µ–π, –Ω–∞–∑–≤–∞–Ω–∏–π –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π, —Ç–æ–ø–æ–Ω–∏–º–æ–≤ –∏ —Ç.–ø.)\n",
    "\n",
    "–ù–∞–±–æ—Ä—ã –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω—ã –≤ –±–µ–Ω—á–º–∞—Ä–∫–∞—Ö [GLUE üõ†Ô∏è[doc]](https://gluebenchmark.com/) –∏ [SuperGLUE üõ†Ô∏è[doc]](https://super.gluebenchmark.com/) –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –î–ª—è –æ—Ü–µ–Ω–∫–∏ —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –±–µ–Ω—á–º–∞—Ä–∫ [Russian SuperGLUE üõ†Ô∏è[doc]](https://russiansuperglue.com/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ Transformers –æ—Ç Hugging Face –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–∫–∞—á–∏–≤–∞—Ç—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏—Ö –∫–∞–∫ –Ω–∞—á–∞–ª—å–Ω—ã–π –±–ª–æ–∫ –¥–ª—è –ø–æ–¥—Å—á–µ—Ç–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å–ª–æ–≤. –ü–æ–≤–µ—Ä—Ö —ç—Ç–æ–≥–æ –±–ª–æ–∫–∞ –¥–æ–±–∞–≤–ª—è—é—Ç—Å—è –¥—Ä—É–≥–∏–µ —Å–ª–æ–∏, –∏—Ö –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –∑–∞–≤–∏—Å–∏—Ç –æ—Ç –∑–∞–¥–∞—á–∏. –í–µ—Å–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–µ–¥–æ–±—É—á–µ–Ω—ã, –Ω–æ –º—ã –ø—Ä–æ–≤–æ–¥–∏–º —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É (fine-tuning) –∏–ª–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ —Ü–µ–ª–µ–≤–æ–π –∑–∞–¥–∞—á–µ.\n",
    "\n",
    "–ú—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –º–æ–∂–Ω–æ –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å –¥–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ BERT –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –î–ª—è —ç—Ç–æ–≥–æ –º—ã –∏–∑—É—á–∏–º:\n",
    "\n",
    "- –ö–∞–∫ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç\n",
    "- –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—ã—Å–æ–∫–æ—É—Ä–æ–≤–Ω–µ–≤–æ–µ API –¥–ª—è –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏\n",
    "- –ö–∞–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è (training loop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ [Transformers üõ†Ô∏è[doc]](https://huggingface.co/docs/transformers/index), [Datasets üõ†Ô∏è[doc]](https://huggingface.co/docs/datasets/index) –∏ [Evaluate üõ†Ô∏è[doc]](https://huggingface.co/docs/evaluate/index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install -q datasets==3.6.0 evaluate transformers\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –¥–∞–Ω–Ω–æ–º —Ä–∞–∑–¥–µ–ª–µ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç [Microsoft Research Paraphrase Corpus (MRPC) üõ†Ô∏è[doc]](https://www.microsoft.com/en-us/download/details.aspx?id=52398). –û–Ω —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ 5801 –ø–∞—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º –∏–º –ª–µ–π–±–ª–æ–º: —è–≤–ª—è–µ—Ç—Å—è –ø–∞—Ä–∞ –ø—Ä–µ–ª–æ–∂–µ–Ω–∏–π –ø–∞—Ä–∞—Ñ—Ä–∞–∑–∞–º–∏ –∏–ª–∏ –Ω–µ—Ç (—Ç.–µ. –∏–¥–µ—Ç –ª–∏ —Ä–µ—á—å –≤ –æ–±–æ–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –æ–± –æ–¥–Ω–æ–º –∏ —Ç–æ–º –∂–µ). –ú—ã –≤—ã–±—Ä–∞–ª–∏ –∏–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç –¥–∞—Ç–∞—Å–µ—Ç, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω –Ω–µ–±–æ–ª—å—à–æ–π: —Å –Ω–∏–º –ª–µ–≥–∫–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Hugging Face üõ†Ô∏è[doc]](https://huggingface.co/) —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ —Ç–æ–ª—å–∫–æ –º–æ–¥–µ–ª–∏, —Ç–∞–º —Ç–∞–∫–∂–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–æ –º–Ω–æ–∂–µ—Å—Ç–≤–æ [–¥–∞—Ç–∞—Å–µ—Ç–æ–≤ üõ†Ô∏è[doc]](https://huggingface.co/datasets) –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —è–∑—ã–∫–æ–≤ –∏ –∑–∞–¥–∞—á.\n",
    "\n",
    "–ù–æ —Å–µ–π—á–∞—Å –≤–µ—Ä–Ω–µ–º—Å—è –∫ –¥–∞—Ç–∞—Å–µ—Ç—É MRPC! –≠—Ç–æ –æ–¥–∏–Ω –∏–∑ 10 –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –±–µ–Ω—á–º–∞—Ä–∫–∞ [GLUE üõ†Ô∏è[doc]](https://gluebenchmark.com/) –¥–ª—è –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –≤ –∑–∞–¥–∞—á–∞—Ö –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.\n",
    "\n",
    "–ú—ã –º–æ–∂–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç —Å–ª–µ–¥—É—é—â–∏–º –æ–±—Ä–∞–∑–æ–º:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "raw_mrpc = load_dataset(\"glue\", \"mrpc\")\n",
    "clear_output()\n",
    "\n",
    "raw_mrpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –º–æ–∂–Ω–æ –∑–∞–º–µ—Ç–∏—Ç—å, –º—ã –ø–æ–ª—É—á–∏–ª–∏ –æ–±—ä–µ–∫—Ç —Ç–∏–ø–∞ `DatasetDict`, –∫–æ—Ç–æ—Ä—ã–π –≤–∫–ª—é—á–∞–µ—Ç –æ–±—É—á–∞—é—â—É—é –≤—ã–±–æ—Ä–∫—É, –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫—É –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É. –ö–∞–∂–¥–∞—è –∏–∑ –Ω–∏—Ö —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–æ–ª–æ–Ω–æ–∫ (`sentence1`, `sentence2`, `label` –∏ `idx`) –∏ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é —Å —á–∏—Å–ª–æ–º —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (`num_rows`): 3668 –ø–∞—Ä –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –≤ –æ–±—É—á–∞—é—â–µ–π —á–∞—Å—Ç–∏, 408 –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –∏ 1725 –≤ —Ç–µ—Å—Ç–æ–≤–æ–π .\n",
    "\n",
    "–ú—ã –º–æ–∂–µ–º –ø–æ–ª—É—á–∏—Ç—å –¥–æ—Å—Ç—É–ø –∫ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏ –≤ –æ–±—ä–µ–∫—Ç–µ `raw_datasets` –ø—É—Ç–µ–º –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏—è, –∫–∞–∫ –≤ —Å–ª–æ–≤–∞—Ä–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_mrpc = raw_mrpc[\"train\"]\n",
    "print(\"First element in train dataset:\\n\")\n",
    "raw_train_mrpc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–∂–Ω–æ —É–≤–∏–¥–µ—Ç—å, —á—Ç–æ –ª–µ–π–±–ª—ã —É–∂–µ —è–≤–ª—è—é—Ç—Å—è —Ü–µ–ª—ã–º–∏ —á–∏—Å–ª–∞–º–∏ (integer), –∏—Ö –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –Ω–µ –Ω—É–∂–Ω–æ. –ß—Ç–æ–±—ã —Å–æ–ø–æ—Å—Ç–∞–≤–∏—Ç—å –∏–Ω–¥–µ–∫—Å –∫–ª–∞—Å—Å–∞ —Å –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏–µ–º, –º–æ–∂–Ω–æ –≤—ã–≤–µ—Å—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π `features` —É `raw_train_dataset`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature types:\\n\")\n",
    "raw_train_mrpc.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–µ–º–µ–Ω–Ω–∞—è `label` —Ç–∏–ø–∞ `ClassLabel` —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏–º–µ–Ω–∞–º –≤ `names`. `0` —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç `not_equivalent`, `1` —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç `equivalent`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞—Ç–∞—Å–µ—Ç, –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç –≤ —á–∏—Å–ª–∞, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –º–æ–¥–µ–ª—å. –ö–∞–∫ –º—ã –≤–∏–¥–µ–ª–∏ —Ä–∞–Ω–µ–µ, —ç—Ç–æ –¥–µ–ª–∞–µ—Ç—Å—è —Å –ø–æ–º–æ—â—å—é —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞. –ú—ã –º–æ–∂–µ–º –ø–æ–¥–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä—É –æ–¥–Ω–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –∏–ª–∏ —Å–ø–∏—Å–æ–∫, —Ç.–µ. –º–æ–∂–Ω–æ —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ–ø–∞—Ä–Ω–æ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "checkpoint = \"bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "tokenized_sentences_1 = tokenizer(raw_mrpc[\"train\"][\"sentence1\"])\n",
    "tokenized_sentences_2 = tokenizer(raw_mrpc[\"train\"][\"sentence2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–Ω–∞–∫–æ –º—ã –Ω–µ –º–æ–∂–µ–º –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–¥–∞—Ç—å –¥–≤–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ –º–æ–¥–µ–ª—å –∏ –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–æ–≥–Ω–æ–∑ —Ç–æ–≥–æ, —è–≤–ª—è—é—Ç—Å—è –ª–∏ —ç—Ç–∏ –¥–≤–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–∞—Ä–∞—Ñ—Ä–∞–∑–∞–º–∏ –∏–ª–∏ –Ω–µ—Ç. –ù–∞–º –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –¥–≤–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∫–∞–∫ –ø–∞—Ä—É –∏ –ø—Ä–∏–º–µ–Ω—è—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—É—é –æ–±—Ä–∞–±–æ—Ç–∫—É. –ö —Å—á–∞—Å—Ç—å—é, —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç –≤–∑—è—Ç—å –ø–∞—Ä—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å –∏—Ö —Ç–∞–∫, –∫–∞–∫ –æ–∂–∏–¥–∞–µ—Ç –Ω–∞—à–∞ –º–æ–¥–µ–ª—å BERT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"This is the first sentence.\"\n",
    "sentence2 = \"This is the second one.\"\n",
    "inputs = tokenizer(sentence1, sentence2)\n",
    "print(f\"First sentence: {sentence1}\")\n",
    "print(f\"Second sentence: {sentence2}\")\n",
    "print(\"Result of tokeniization:\")\n",
    "inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`input_ids` —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω–¥–µ–∫—Å—ã, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç–æ–∫–µ–Ω–∞–º –ø–æ —Å–ª–æ–≤–∞—Ä—é.\n",
    "\n",
    "–ú–∞—Å–∫–∏ –≤–Ω–∏–º–∞–Ω–∏—è (`attention_mask`) ‚Äî —ç—Ç–æ —Ç–µ–Ω–∑–æ—Ä—ã —Ç–æ–π –∂–µ —Ñ–æ—Ä–º—ã, —á—Ç–æ –∏ —Ç–µ–Ω–∑–æ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–æ–≤, –∑–∞–ø–æ–ª–Ω–µ–Ω–Ω—ã–µ `0` –∏ `1`: `1` –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç–æ–∫–µ–Ω—ã –¥–æ–ª–∂–Ω—ã ‚Äú–ø—Ä–∏–≤–ª–µ–∫–∞—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ‚Äù, –∞ `0` –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Ç–æ–∫–µ–Ω—ã –Ω–µ –¥–æ–ª–∂–Ω—ã ‚Äú–ø—Ä–∏–≤–ª–µ–∫–∞—Ç—å –≤–Ω–∏–º–∞–Ω–∏–µ‚Äù (—Ç.–µ. –¥–æ–ª–∂–Ω—ã –∏–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è —Å–ª–æ—è–º–∏ –≤–Ω–∏–º–∞–Ω–∏—è –º–æ–¥–µ–ª–∏).\n",
    "\n",
    "`token_type_ids` —É–∫–∞–∑—ã–≤–∞–µ—Ç –º–æ–¥–µ–ª–∏, –∫–∞–∫–∞—è —á–∞—Å—Ç—å –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —è–≤–ª—è–µ—Ç—Å—è –ø–µ—Ä–≤—ã–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º, –∞ –∫–∞–∫–∞—è –≤—Ç–æ—Ä—ã–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ï—Å–ª–∏ –º—ã –¥–µ–∫–æ–¥–∏—Ä—É–µ–º ID –∏–∑ `input_ids` –æ–±—Ä–∞—Ç–Ω–æ –≤ —Å–ª–æ–≤–∞, –º—ã –ø–æ–ª—É—á–∏–º:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Converting indices to tokens:\")\n",
    "tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —É–∂–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∏–Ω–¥–µ–∫—Å—ã –¥–ª—è —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª–æ–≤:\n",
    "- `[SEP]` ‚Äî –º–µ—Ç–∫–∞ –∫–æ–Ω—Ü–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "- `[CLS]` ‚Äî —Ç–æ–∫–µ–Ω –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è\n",
    "- `[PAD]` ‚Äî —Ç–æ–∫–µ–Ω –¥–ª—è –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è –¥–ª–∏–Ω –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π\n",
    "\n",
    "–í–∏–¥–Ω–æ, —á—Ç–æ –º–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Å–ª–µ–¥—É—é—â–µ–º —Ñ–æ—Ä–º–∞—Ç–µ: `[CLS] sentence1 [SEP] sentence2 [SEP]` –≤ —Å–ª—É—á–∞–µ –¥–≤—É—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –ü–æ—Å–º–æ—Ç—Ä–∏–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏ `token_type_ids`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token, id in zip(\n",
    "    tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"]), inputs[\"token_type_ids\"]\n",
    "):\n",
    "    print(token, id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –≤—ã –º–æ–∂–µ—Ç–µ –∑–∞–º–µ—Ç–∏—Ç—å, —á–∞—Å—Ç–∏ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö `[CLS] sentence1 [SEP]`, –∏–º–µ—é—Ç —Ç–∏–ø —Ç–æ–∫–µ–Ω–∞ `0`, –≤ —Ç–æ –≤—Ä–µ–º—è –∫–∞–∫ –æ—Å—Ç–∞–ª—å–Ω—ã–µ —á–∞—Å—Ç–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –≤—Ç–æ—Ä–æ–º—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—é `sentence2 [SEP]`, –∏–º–µ—é—Ç —Ç–∏–ø —Ç–æ–∫–µ–Ω–∞ `1`.\n",
    "\n",
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –µ—Å–ª–∏ –≤—ã –≤—ã–±–µ—Ä–µ—Ç–µ –¥—Ä—É–≥–æ–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –º–æ–¥–µ–ª–∏, `token_type_ids` –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –±—É–¥—É—Ç –ø—Ä–∏—Å—É—Ç—Å—Ç–≤–æ–≤–∞—Ç—å –≤ –≤–∞—à–∏—Ö —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö. –û–Ω–∏ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç—Å—è —Ç–æ–ª—å–∫–æ —Ç–æ–≥–¥–∞, –∫–æ–≥–¥–∞ –º–æ–¥–µ–ª—å –±—É–¥–µ—Ç –∑–Ω–∞—Ç—å, —á—Ç–æ —Å –Ω–∏–º–∏ –¥–µ–ª–∞—Ç—å, –ø–æ—Ç–æ–º—É —á—Ç–æ –æ–Ω–∞ –≤–∏–¥–µ–ª–∞ –∏—Ö –≤–æ –≤—Ä–µ–º—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ BERT –±—ã–ª –æ–±—É—á–µ–Ω —Å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞—Ö —Ç–∏–ø–æ–≤ —Ç–æ–∫–µ–Ω–æ–≤, –∏ –ø–æ–º–∏–º–æ –∑–∞–¥–∞—á–∏ –º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è, –æ–Ω –º–æ–∂–µ—Ç —Ä–µ—à–∞—Ç—å –µ—â–µ –æ–¥–Ω—É –∑–∞–¥–∞—á—É: –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å–ª–µ–¥—É—é—â–µ–≥–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è (next sentence prediction). –°—É—Ç—å —ç—Ç–æ–π –∑–∞–¥–∞—á–∏ ‚Äî —Å–º–æ–¥–µ–ª–∏—Ä–æ–≤–∞—Ç—å —Å–≤—è–∑—å –º–µ–∂–¥—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º–∏.\n",
    "\n",
    "–í —ç—Ç–æ–π –∑–∞–¥–∞—á–µ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞—é—Ç—Å—è –ø–∞—Ä—ã –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π (—Å–æ —Å–ª—É—á–∞–π–Ω–æ –∑–∞–º–∞—Å–∫–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Ç–æ–∫–µ–Ω–∞–º–∏), –æ—Ç –º–æ–¥–µ–ª–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Å–ª–µ–¥—É—é—â–µ–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º —Ç–µ–∫—É—â–µ–≥–æ. –ß—Ç–æ–±—ã –∑–∞–¥–∞—á–∞ –Ω–µ –±—ã–ª–∞ —Å–ª–∏—à–∫–æ–º —Ç—Ä–∏–≤–∏–∞–ª—å–Ω–æ–π, –ø–æ–ª–æ–≤–∏–Ω—É –≤—Ä–µ–º–µ–Ω–∏ –º–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ —Å–æ—Å–µ–¥–Ω–∏—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è—Ö –∏–∑ –æ–¥–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞, –¥—Ä—É–≥—É—é –ø–æ–ª–æ–≤–∏–Ω—É ‚Äî –Ω–∞ –ø–∞—Ä–∞—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –≤–∑—è—Ç—ã—Ö –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤.\n",
    "\n",
    "–í –æ–±—â–µ–º —Å–ª—É—á–∞–µ –≤–∞–º –Ω–µ –Ω—É–∂–Ω–æ –±–µ—Å–ø–æ–∫–æ–∏—Ç—å—Å—è –æ –Ω–∞–ª–∏—á–∏–∏ `token_type_ids` –≤ –≤–∞—à–∏—Ö —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: –ø–æ–∫–∞ –≤—ã –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ç–æ—Ä –∏ –¥–ª—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞, –∏ –¥–ª—è –º–æ–¥–µ–ª–∏ ‚Äì —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –±—É–¥–µ—Ç –∑–Ω–∞—Ç—å, –∫–∞–∫ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –º—ã –∑–Ω–∞–µ–º, —á—Ç–æ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –º–æ–∂–µ—Ç –ø–æ–¥–≥–æ—Ç–æ–≤–∏—Ç—å —Å—Ä–∞–∑—É –ø–∞—Ä—É –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∞ –∑–Ω–∞—á–∏—Ç –º—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –µ–≥–æ –¥–ª—è —Ü–µ–ª–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞: –º–æ–∂–Ω–æ –ø–æ–¥–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä—É —Å–ø–∏—Å–æ–∫ –ø–µ—Ä–≤—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –∏ —Å–ø–∏—Å–æ–∫ –≤—Ç–æ—Ä—ã—Ö –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –≠—Ç–æ —Ç–∞–∫–∂–µ —Å—Ä–∞–±–æ—Ç–∞–µ—Ç –∏ –¥–ª—è –º–µ—Ö–∞–Ω–∏–∑–º–æ–≤ –≤—ã—Ä–∞–≤–Ω–∏–≤–∞–Ω–∏—è (`padding`) –∏ —É—Å–µ—á–µ–Ω–∏—è –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã (`truncation`).\n",
    "\n",
    "–ò—Ç–∞–∫, –æ–¥–∏–Ω –∏–∑ —Å–ø–æ—Å–æ–±–æ–≤ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –æ–±—É—á–∞—é—â–∏–π –¥–∞—Ç–∞—Å–µ—Ç:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_mrpc = tokenizer(\n",
    "    raw_mrpc[\"train\"][\"sentence1\"],\n",
    "    raw_mrpc[\"train\"][\"sentence2\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£ –¥–∞–Ω–Ω–æ–≥–æ —Å–ø–æ—Å–æ–±–∞ –µ—Å—Ç—å –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ–∫: —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –æ–±—ä–µ–∫—Ç —Å –∫–ª—é—á–∞–º–∏, `input_ids`, `attention_mask`, –∏ `token_type_ids` –∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ø–∏—Å–∫–∞ —Å–ø–∏—Å–∫–æ–≤. –≠—Ç–æ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å, —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —É –Ω–∞—Å –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ–π –ø–∞–º—è—Ç–∏ (RAM) –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ü–µ–ª–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤–æ –≤—Ä–µ–º—è —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in tokenized_mrpc.items():\n",
    "    print(f\"Key: {k}, value type: {type(v)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã —Ö—Ä–∞–Ω–∏—Ç—å –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç–∞, –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ç–æ–¥ `Dataset.map()`. –ú–µ—Ç–æ–¥ `map()` –ø—Ä–∏–º–µ–Ω—è–µ—Ç –Ω–µ–∫–æ—Ç–æ—Ä—É—é —Ñ—É–Ω–∫—Ü–∏—é –∫ –∫–∞–∂–¥–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É –¥–∞—Ç–∞—Å–µ—Ç–∞.\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –æ–ø—Ä–µ–¥–µ–ª–∏–º —Ñ—É–Ω–∫—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç –Ω–∞—à–∏ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function_mrpc(example):\n",
    "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠—Ç–∞ —Ñ—É–Ω–∫—Ü–∏—è –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ —Å–ª–æ–≤–∞—Ä—å (–ø–æ—Ö–æ–∂–∏–π –Ω–∞ —ç–ª–µ–º–µ–Ω—Ç—ã –Ω–∞—à–µ–≥–æ —Å–ª–æ–≤–∞—Ä—è) –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –Ω–æ–≤—ã–π —Å–ª–æ–≤–∞—Ä—å —Å –∫–ª—é—á–∞–º–∏ `input_ids`, `attention_mask` –∏ `token_type_ids`. –ó–∞–º–µ—Ç—å—Ç–µ, —ç—Ç–æ —Ç–∞–∫–∂–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –µ—Å–ª–∏ —Å–ª–æ–≤–∞—Ä—å `example` —Å–æ–¥–µ—Ä–∂–∏—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ (–∫–∞–∂–¥—ã–π –∫–ª—é—á –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π), –ø–æ—Å–∫–æ–ª—å–∫—É `tokenizer` —Ä–∞–±–æ—Ç–∞–µ—Ç –∏ —Å–æ —Å–ø–∏—Å–∫–∞–º–∏ –ø–∞—Ä –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –∫–∞–∫ –º—ã –∏ –≤–∏–¥–µ–ª–∏ —Ä–∞–Ω–µ–µ. –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏—Ç –Ω–∞–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç `batched=True` –≤ –≤—ã–∑–æ–≤–µ `map()`, –∫–æ—Ç–æ—Ä—ã–π —É—Å–∫–æ—Ä–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏.\n",
    "\n",
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –º—ã –æ—Å—Ç–∞–≤–∏–ª–∏ –∞—Ä–≥—É–º–µ–Ω—Ç `padding` –ø—É—Å—Ç—ã–º, –ø–æ—Ç–æ–º—É —á—Ç–æ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –Ω–µ—ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ: –≥–æ—Ä–∞–∑–¥–æ –±—ã—Å—Ç—Ä–µ–µ –¥–µ–ª–∞—Ç—å —ç—Ç–æ –≤–æ –≤—Ä–µ–º—è —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è –±–∞—Ç—á–∞, –≤ —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –º—ã –±—É–¥–µ–º –¥–æ–ø–æ–ª–Ω—è—Ç—å –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã —Ç–æ–ª—å–∫–æ —ç–ª–µ–º–µ–Ω—Ç—ã –±–∞—Ç—á–∞, –∞ –Ω–µ —Ü–µ–ª–æ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞. –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç —Å—ç–∫–æ–Ω–æ–º–∏—Ç—å –≤—Ä–µ–º—è –≤ —Å–ª—É—á–∞–µ –¥–ª–∏–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π.\n",
    "\n",
    "–ù–∏–∂–µ –ø—Ä–∏–º–µ—Ä —Ç–æ–≥–æ, –∫–∞–∫ –º—ã –ø—Ä–∏–º–µ–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏ –∫ —Ü–µ–ª–æ–º—É –¥–∞—Ç–∞—Å–µ—Ç—É. –ü–æ—Å–∫–æ–ª—å–∫—É –º—ã —É–∫–∞–∑—ã–≤–∞–µ–º `batched=True` –ø—Ä–∏ –≤—ã–∑–æ–≤–µ `map`, —Ñ—É–Ω–∫—Ü–∏—è –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ —Å—Ä–∞–∑—É –∫ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º —ç–ª–µ–º–µ–Ω—Ç–∞–º –¥–∞—Ç–∞—Å–µ—Ç–∞ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ, –∞ –Ω–µ –∫ –∫–∞–∂–¥–æ–º—É –ø–æ –æ—Ç–¥–µ–ª—å–Ω–æ—Å—Ç–∏. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–¥–µ–ª–∞—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é –±–æ–ª–µ–µ –±—ã—Å—Ç—Ä–æ–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_mrpc = raw_mrpc.map(tokenize_function_mrpc, batched=True)\n",
    "clear_output()\n",
    "\n",
    "tokenized_mrpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic padding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–§—É–Ω–∫—Ü–∏—è, –æ—Ç–≤–µ—á–∞—é—â–∞—è –∑–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤–Ω—É—Ç—Ä–∏ –±–∞—Ç—á–∞, –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è `collate_function`. –≠—Ç–æ –∞—Ä–≥—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –≤—ã –º–æ–∂–µ—Ç–µ –ø–µ—Ä–µ–¥–∞—Ç—å –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ `DataLoader`. –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —ç—Ç–æ —Ñ—É–Ω–∫—Ü–∏—è, –∫–æ—Ç–æ—Ä–∞—è –ø—Ä–æ—Å—Ç–æ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞–µ—Ç –æ–±—ä–µ–∫—Ç—ã –≤ —Ç–µ–Ω–∑–æ—Ä—ã PyTorch –∏ –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö. –í –Ω–∞—à–µ–º —Å–ª—É—á–∞–µ —ç—Ç–æ –Ω–µ–≤–æ–∑–º–æ–∂–Ω–æ, –ø–æ—Å–∫–æ–ª—å–∫—É –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã–µ —É –Ω–∞—Å –µ—Å—Ç—å, –Ω–µ –±—É–¥—É—Ç –∏–º–µ—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞. –ú—ã –Ω–∞–º–µ—Ä–µ–Ω–Ω–æ –Ω–µ —Å—Ç–∞–ª–∏ –¥–µ–ª–∞—Ç—å `padding`, —á—Ç–æ–±—ã –ø—Ä–∏–º–µ–Ω—è—Ç—å –µ–≥–æ —Ç–æ–ª—å–∫–æ –ø–æ –º–µ—Ä–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –≤ –∫–∞–∂–¥–æ–º –±–∞—Ç—á–µ –∏ –∏–∑–±–µ–≥–∞—Ç—å —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã—Ö –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –±–æ–ª—å—à–∏–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º –æ—Ç—Å—Ç—É–ø–æ–≤.\n",
    "\n",
    "–§—É–Ω–∫—Ü–∏—è `collate_function` –±—É–¥–µ—Ç –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤—ã–±–æ—Ä–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º—ã —Ö–æ—Ç–∏–º –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤ –±–∞—Ç—á. –ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ [Transformers üõ†Ô∏è[doc]](https://huggingface.co/docs/transformers/index) –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é —á–µ—Ä–µ–∑ –∫–ª–∞—Å—Å `DataCollatorWithPadding`. –ü—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ —Ç—Ä–µ–±—É–µ—Ç—Å—è —É–∫–∞–∑–∞—Ç—å —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä: —á—Ç–æ–±—ã –∑–Ω–∞—Ç—å, –∫–∞–∫–æ–π —Ç–æ–∫–µ–Ω –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –∏ —Å–ª–µ–≤–∞ –∏–ª–∏ —Å–ø—Ä–∞–≤–∞ –Ω—É–∂–Ω–æ –¥–æ–ø–æ–ª–Ω—è—Ç—å –¥–∞–Ω–Ω—ã–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã –ø—Ä–æ—Ç–µ—Å—Ç–∏—Ä–æ–≤–∞—Ç—å, –¥–∞–≤–∞–π—Ç–µ –≤–æ–∑—å–º–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º—ã —Ö–æ—Ç–∏–º –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –≤ –±–∞—Ç—á. –ú—ã —É–¥–∞–ª–∏–º –∫–æ–ª–æ–Ω–∫–∏ `idx`, `sentence1` –∏ `sentence2`, —Ç.–∫. –æ–Ω–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç —Å—Ç—Ä–æ–∫–∏ (–∞ –º—ã –Ω–µ –º–æ–∂–µ–º –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å —Å—Ç—Ä–æ–∫–∏ –≤ —Ç–µ–Ω–∑–æ—Ä—ã) –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ –¥–ª–∏–Ω—É –∫–∞–∂–¥–æ–π –∑–∞–ø–∏—Å–∏ –≤ –±–∞—Ç—á–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = tokenized_mrpc[\"train\"][:8]\n",
    "samples = {\n",
    "    k: v for k, v in samples.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]\n",
    "}\n",
    "[len(x) for x in samples[\"input_ids\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–µ—É–¥–∏–≤–∏—Ç–µ–ª—å–Ω–æ: –º—ã –ø–æ–ª—É—á–∏–ª–∏ –æ–±—ä–µ–∫—Ç—ã —Ä–∞–∑–Ω–æ–π –¥–ª–∏–Ω—ã –æ—Ç 32 –¥–æ 67. –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –ø–æ–¥—Ä–∞–∑—É–º–µ–≤–∞–µ—Ç, —á—Ç–æ –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã –±—É–¥—É—Ç –¥–æ–ø–æ–ª–Ω–µ–Ω—ã –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –≤ –±–∞—Ç—á–µ, —Ç–æ –µ—Å—Ç—å –¥–æ 67.\n",
    "\n",
    "–ë–µ–∑ –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏—è –≤—Å–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –¥–æ–ø–æ–ª–Ω–µ–Ω—ã –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –≤–æ –≤—Å–µ–º –Ω–∞–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö, –∏–ª–∏ –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã, –∫–æ—Ç–æ—Ä—É—é –º–æ–∂–µ—Ç –ø—Ä–∏–Ω—è—Ç—å –º–æ–¥–µ–ª—å.\n",
    "\n",
    "–î–∞–≤–∞–π—Ç–µ –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ `data_collator` –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –¥–æ–ø–æ–ª–Ω—è–µ—Ç –±–∞—Ç—á:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_collator(samples)\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã–≥–ª—è–¥–∏—Ç –Ω–µ–ø–ª–æ—Ö–æ! –¢–µ–ø–µ—Ä—å –º—ã –ø—Ä–∏—à–ª–∏ –æ—Ç –æ–±—ã—á–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –∫ –±–∞—Ç—á—É, —Å –∫–æ—Ç–æ—Ä—ã–º –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∞—à–∞ –º–æ–¥–µ–ª—å.\n",
    "\n",
    "–ú–æ–∂–µ–º –ø—Ä–∏—Å—Ç—É–ø–∏—Ç—å –∫ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–µ!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º Trainer API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ [Transformers üõ†Ô∏è[doc]](https://huggingface.co/docs/transformers/index) –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –∫–ª–∞—Å—Å `Trainer`, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–º–æ–≥–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–µ—Å—Ç–∏ —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –ª—é–±–æ–π –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ. –ü–æ—Å–ª–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö, —Å–¥–µ–ª–∞–Ω–Ω–æ–π –≤ –ø—Ä–æ—à–ª–æ–º —Ä–∞–∑–¥–µ–ª–µ, –æ—Å—Ç–∞–Ω–µ—Ç—Å—è —Å–¥–µ–ª–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è `Trainer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–≤—ã–π —à–∞–≥ –ø–µ—Ä–µ–¥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º `Trainer` ‚Äî –∑–∞–¥–∞–Ω–∏–µ –∫–ª–∞—Å—Å–∞ `TrainingArguments`, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –≤—Å–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è `Trainer` (–¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –æ–±—É—á–µ–Ω–∏—è –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–∏). –ï–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∞—Ä–≥—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –Ω—É–∂–Ω–æ –∑–∞–¥–∞—Ç—å, ‚Äî —ç—Ç–æ –∫–∞—Ç–∞–ª–æ–≥, –≤ –∫–æ—Ç–æ—Ä–æ–º –±—É–¥–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –æ–±—É—á–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å, –∞ —Ç–∞–∫–∂–µ –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã–µ —Ç–æ—á–∫–∏. –î–ª—è –≤—Å–µ–≥–æ –æ—Å—Ç–∞–ª—å–Ω–æ–≥–æ –º–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"./results\", report_to=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—Ç–æ—Ä–æ–π —à–∞–≥ ‚Äì –∑–∞–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏. –ú—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–ª–∞—Å—Å `AutoModelForSequenceClassification` —Å –¥–≤—É–º—è –ª–µ–π–±–ª–∞–º–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ –±—É–¥–µ—Ç –≤—ã–≤–µ–¥–µ–Ω–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ. –≠—Ç–æ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ—Ç–æ–º—É, —á—Ç–æ BERT –Ω–µ –±—ã–ª –ø—Ä–µ–¥–æ–±—É—á–µ–Ω –¥–ª—è –∑–∞–¥–∞—á–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø–∞—Ä –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, –µ–≥–æ –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ª–æ–π –Ω–µ –±—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω, –≤–º–µ—Å—Ç–æ –Ω–µ–≥–æ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω —Å–ª–æ–π, –ø–æ–∑–≤–æ–ª—è—é—â–∏–π —Ä–∞–±–æ—Ç–∞—Ç—å —Å —Ç–∞–∫–æ–π –∑–∞–¥–∞—á–µ–π. –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è —Å–æ–æ–±—â–∞—é—Ç, —á—Ç–æ –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –≤–µ—Å–∞ –Ω–µ –±—É–¥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω—ã, –∏ –¥–ª—è –Ω–æ–≤—ã—Ö –±—É–¥—É—Ç –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã —Å–ª—É—á–∞–π–Ω—ã–µ –≤–µ—Å–∞. –í –∑–∞–∫–ª—é—á–µ–Ω–∏–∏ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å, —á—Ç–æ –º—ã –∏ —Å–¥–µ–ª–∞–µ–º –ø—Ä—è–º–æ —Å–µ–π—á–∞—Å.\n",
    "\n",
    "–ü–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ –º—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ –º–æ–¥–µ–ª—å, –º—ã –º–æ–∂–µ–º –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å `Trainer` –∏ –ø–µ—Ä–µ–¥–∞—Ç—å —Ç—É–¥–∞ –Ω—É–∂–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã: `model`, `training_args`, –æ–±—É—á–∞—é—â—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏, `data_collator` –∏ `processing_class`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer_mrpc = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_mrpc[\"train\"],\n",
    "    eval_dataset=tokenized_mrpc[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –º–æ–¥–µ–ª–∏ –Ω–∞ –Ω–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω—É–∂–Ω–æ –≤—ã–∑–≤–∞—Ç—å –º–µ—Ç–æ–¥ `train()` —É `Trainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_mrpc.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠—Ç–æ –∑–∞–ø—É—Å—Ç–∏—Ç –ø—Ä–æ—Ü–µ—Å—Å –¥–æ–æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π –¥–æ–ª–∂–µ–Ω –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –º–∏–Ω—É—Ç –Ω–∞ GPU –∏ –±—É–¥–µ—Ç –≤—ã–≤–æ–¥–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∫–∞–∂–¥—ã–µ 500 –∏—Ç–µ—Ä–∞—Ü–∏–π. –û–¥–Ω–∞–∫–æ —ç—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–µ —Å–∫–∞–∂—É—Ç –Ω–∞–º, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ –∏–ª–∏ –ø–ª–æ—Ö–æ –º–æ–¥–µ–ª—å —Ä–∞–±–æ—Ç–∞–µ—Ç. –ò –≤–æ—Ç –ø–æ—á–µ–º—É:\n",
    "\n",
    "1. –ú—ã –Ω–µ —Å–æ–æ–±—â–∏–ª–∏ `Trainer`, —á—Ç–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–æ–≤–æ–¥–∏—Ç—å –≤–∞–ª–∏–¥–∞—Ü–∏—é: –¥–ª—è —ç—Ç–æ–≥–æ –Ω—É–∂–Ω–æ –ø—Ä–∏—Å–≤–æ–∏—Ç—å –∞—Ä–≥—É–º–µ–Ω—Ç—É `evaluation_strategy` –∑–Ω–∞—á–µ–Ω–∏–µ `\"steps\"` (–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—ã–µ `eval_steps`) –∏–ª–∏ `\"epoch\"` (–≤–∞–ª–∏–¥–∏—Ä–æ–≤–∞—Ç—å –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏–∏ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏).\n",
    "2. –ú—ã –Ω–µ —É–∫–∞–∑–∞–ª–∏ `Trainer` –∞—Ä–≥—É–º–µ–Ω—Ç `compute_metrics()` ‚Äì —Ñ—É–Ω–∫—Ü–∏—é –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π —á–∞—Å—Ç–∏. –í —Ç–∞–∫–æ–º —Å–ª—É—á–∞–µ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –±—É–¥–µ—Ç —Ç–æ–ª—å–∫–æ –≤—ã–≤–æ–¥–∏—Ç—å—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å, —á—Ç–æ –Ω–µ –æ—á–µ–Ω—å –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í–∞–ª–∏–¥–∞—Ü–∏—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –º—ã –º–æ–∂–µ–º —Å–æ–∑–¥–∞—Ç—å –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è –ø–æ–ª–µ–∑–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é `compute_metrics()`. –§—É–Ω–∫—Ü–∏—è –¥–æ–ª–∂–Ω–∞ –ø—Ä–∏–Ω–∏–º–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –æ–±—ä–µ–∫—Ç `EvalPrediction` (–∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–π –∫–æ—Ä—Ç–µ–∂ —Å –ø–æ–ª—è–º–∏ `predictions` –∏ `label_ids`) –∏ –≤–æ–∑–≤—Ä–∞—â–∞—Ç—å —Å–ª–æ–≤–∞—Ä—å, –≥–¥–µ –∫–ª—é—á–∏ ‚Äî –Ω–∞–∑–≤–∞–Ω–∏—è –º–µ—Ç—Ä–∏–∫, –∞ –∑–Ω–∞—á–µ–Ω–∏—è ‚Äî –æ—Ü–µ–Ω–∫–∏ —ç—Ç–∏—Ö –º–µ—Ç—Ä–∏–∫.\n",
    "\n",
    "–ß—Ç–æ–±—ã –ø–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è, –º—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ—É–Ω–∫—Ü–∏—é `Trainer.predict()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_mrpc = trainer_mrpc.predict(tokenized_mrpc[\"validation\"])\n",
    "print(f\"First 5 elements in predicted labels:\\n{predictions_mrpc.predictions[:5]}\")\n",
    "print(f\"Shape of predicted labels: {predictions_mrpc.predictions.shape}\")\n",
    "print(f\"First 5 elements in true labels: {predictions_mrpc.label_ids[:5]}\")\n",
    "print(f\"Shape of true labels: {predictions_mrpc.label_ids.shape}\")\n",
    "print(f\"Metrics: {predictions_mrpc.metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–µ–∑—É–ª—å—Ç–∞—Ç —Ñ—É–Ω–∫—Ü–∏–∏ `predict()` ‚Äî –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã–π –∫–æ—Ä—Ç–µ–∂ —Å –ø–æ–ª—è–º–∏ `predictions`, `label_ids` –∏ `metrics`. –ü–æ–ª–µ `metrics` —Å–æ–¥–µ—Ä–∂–∏—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –Ω–∞ –Ω–∞—à–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ –∏ –∑–Ω–∞—á–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫. –ü–æ—Å–ª–µ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ —Ñ—É–Ω–∫—Ü–∏–∏ `compute_metrics()` –∏ –ø–µ—Ä–µ–¥–∞—á–∏ –µ–µ –≤ `Trainer` –ø–æ–ª–µ `metrics` —Ç–∞–∫–∂–µ –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ñ—É–Ω–∫—Ü–∏–∏ `compute_metrics()`.\n",
    "\n",
    "–ö–∞–∫ –º–æ–∂–Ω–æ –∑–∞–º–µ—Ç–∏—Ç—å, `predictions` ‚Äî –º–∞—Å—Å–∏–≤ —Ä–∞–∑–º–µ—Ä–æ–º 408 √ó 2 (408 ‚Äî —á–∏—Å–ª–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ, –∫–æ—Ç–æ—Ä—ã–π –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏). –≠—Ç–æ –ª–æ–≥–∏—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –Ω–∞—à–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞, –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–≥–æ `–≤ predict()`. –ß—Ç–æ–±—ã –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å –∏—Ö –≤ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏ —Å—Ä–∞–≤–Ω–∏—Ç—å —Å –Ω–∞—à–∏–º–∏ –ª–µ–π–±–ª–∞–º–∏, –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É–∑–Ω–∞—Ç—å –∏–Ω–¥–µ–∫—Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –≤—Ç–æ—Ä–æ–π –æ—Å–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "preds_mrpc = np.argmax(predictions_mrpc.predictions, axis=-1)\n",
    "print(f\"First 5 elements in predicted labels after argmax:\\n{preds_mrpc[:5]}\")\n",
    "print(f\"Shape: {preds_mrpc.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –º—ã –º–æ–∂–µ–º —Å—Ä–∞–≤–Ω–∏—Ç—å —ç—Ç–∏ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å –∏—Å—Ç–∏–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏. –î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏ `compute_metric()` –º—ã –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –º–µ—Ç—Ä–∏–∫–∞–º–∏ –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ [Evaluate üõ†Ô∏è[doc]](https://huggingface.co/docs/evaluate/index). –ú—ã –º–æ–∂–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞ MRPC –º–µ—Ç—Ä–∏–∫–∏ —Ç–∞–∫ –∂–µ –ø—Ä–æ—Å—Ç–æ, –∫–∞–∫ –º—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ –¥–∞—Ç–∞—Å–µ—Ç, –Ω–æ –Ω–∞ —ç—Ç–æ—Ç —Ä–∞–∑ —Å –ø–æ–º–æ—â—å—é —Ñ—É–Ω–∫—Ü–∏–∏ `evaluate.load()`. –í–æ–∑–≤—Ä–∞—â–∞–µ–º—ã–π –æ–±—ä–µ–∫—Ç –∏–º–µ–µ—Ç –º–µ—Ç–æ–¥ `compute()`, –∫–æ—Ç–æ—Ä—ã–π –º—ã –º–æ–∂–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –º–µ—Ç—Ä–∏–∫–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric_mrpc = evaluate.load(\"glue\", \"mrpc\")\n",
    "metric_mrpc.compute(predictions=preds_mrpc, references=predictions_mrpc.label_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–≠—Ç–∏ –º–µ—Ç—Ä–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ MRPC –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–∞ –±–µ–Ω—á–º–∞—Ä–∫–µ GLUE. –í —Ç–∞–±–ª–∏—Ü–µ –∏–∑ —Å—Ç–∞—Ç—å–∏ –æ BERT —É–∫–∞–∑–∞–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ F1 –æ—Ü–µ–Ω–∫–∏ –≤ 88.9 –¥–ª—è –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏. –≠—Ç–æ –±—ã–ª–∞ –æ—Ü–µ–Ω–∫–∞ –¥–ª—è –≤–∞—Ä–∏–∞–Ω—Ç–∞ –º–æ–¥–µ–ª–∏ `uncased`, –∞ –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ `cased`, —ç—Ç–∏–º –∏ –æ–±—ä—è—Å–Ω—è–µ—Ç—Å—è –±–æ–ª–µ–µ —Ö–æ—Ä–æ—à–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç.\n",
    "\n",
    "–°–æ–±–∏—Ä–∞—è –≤–º–µ—Å—Ç–µ –≤—Å–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –≤—ã—à–µ, –º—ã –ø–æ–ª—É—á–∏–º –Ω–∞—à—É —Ñ—É–Ω–∫—Ü–∏—é `compute_metrics()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_mrpc(eval_preds):\n",
    "    metric = evaluate.load(\"glue\", \"mrpc\")\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã —É–≤–∏–¥–µ—Ç—å —ç—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –≤ –¥–µ–π—Å—Ç–≤–∏–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏, –Ω–∏–∂–µ –º—ã –æ–ø—Ä–µ–¥–µ–ª–∏–º –µ—â–µ –æ–¥–∏–Ω `Trainer` —Å —Ñ—É–Ω–∫—Ü–∏–µ–π `compute_metrics()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\", eval_strategy=\"epoch\", report_to=\"none\"\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n",
    "\n",
    "trainer_mrpc = Trainer(\n",
    "    model,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_mrpc[\"train\"],\n",
    "    eval_dataset=tokenized_mrpc[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics_mrpc,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ –º—ã —Å–æ–∑–¥–∞–ª–∏ –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç `TrainingArguments` —Å –Ω–æ–≤–æ–π –º–æ–¥–µ–ª—å—é ‚Äî –∏–Ω–∞—á–µ –º—ã –±—ã –ø—Ä–æ–¥–æ–ª–∂–∏–ª–∏ –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–∞—è —É–∂–µ —è–≤–ª—è–µ—Ç—Å—è –æ–±—É—á–µ–Ω–Ω–æ–π. –ß—Ç–æ–±—ã –∑–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –∑–∞–Ω–æ–≤–æ, –Ω–∞–¥–æ –≤—ã–ø–æ–ª–Ω–∏—Ç—å:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_mrpc.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ —ç—Ç–æ—Ç —Ä–∞–∑ –±—É–¥—É—Ç –≤—ã–≤–æ–¥–∏—Ç—å—Å—è –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å –∏ –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ –ø–æ –æ–∫–æ–Ω—á–∞–Ω–∏–∏ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏ –æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –¥–æ—Å—Ç–∏—á—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∏–∑ –ø—Ä–µ–¥—ã–¥—É—â–µ–π —á–∞—Å—Ç–∏ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –∫–ª–∞—Å—Å–∞ `Trainer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ –æ–±—É—á–µ–Ω–∏—é"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–µ–¥ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–µ–π —Ü–∏–∫–ª–∞ –æ–±—É—á–µ–Ω–∏—è –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–¥–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–æ–≤. –ü–µ—Ä–≤—ã–π: –∑–∞–≥—Ä—É–∑—á–∏–∫–∏ –¥–∞–Ω–Ω—ã—Ö (–¥–∞–ª–µ–µ ‚Äî `dataloaders`), –∫–æ—Ç–æ—Ä—ã–µ –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –∏—Ç–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –±–∞—Ç—á–∞–º –¥–∞–Ω–Ω—ã—Ö. –ü–µ—Ä–µ–¥ —ç—Ç–∏–º –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–ø–µ—Ä–∞—Ü–∏–π –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏ –∫ –Ω–∞—à–µ–º—É `tokenized_datasets`. –í –ø—Ä–æ—à–ª—ã–π —Ä–∞–∑ –∑–∞ –Ω–∞—Å —ç—Ç–æ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–µ–ª–∞–ª `Trainer`. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–¥–µ–ª–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ:\n",
    "- –£–¥–∞–ª–∏—Ç—å –∫–æ–ª–æ–Ω–∫–∏, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è–º, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–¥–µ–ª—å –Ω–µ –ø—Ä–∏–Ω–∏–º–∞–µ—Ç –Ω–∞ –≤—Ö–æ–¥ (–Ω–∞–ø—Ä–∏–º–µ—Ä, `sentence1` –∏ `sentence2`).\n",
    "- –ü–µ—Ä–µ–∏–º–µ–Ω–æ–≤–∞—Ç—å –∫–æ–ª–æ–Ω–∫—É `label` –≤ `labels` (–ø–æ—Ç–æ–º—É —á—Ç–æ –º–æ–¥–µ–ª—å –æ–∂–∏–¥–∞–µ—Ç –∞—Ä–≥—É–º–µ–Ω—Ç, –Ω–∞–∑–≤–∞–Ω–Ω—ã–π `labels`).\n",
    "- –ó–∞–¥–∞—Ç—å —Ç–∏–ø –¥–∞–Ω–Ω—ã—Ö –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ `pytorch tensors` –≤–º–µ—Å—Ç–æ —Å–ø–∏—Å–∫–æ–≤.\n",
    "\n",
    "–ù–∞—à `tokenized_datasets` –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å—Ç—Ä–æ–µ–Ω–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ –ø—Ä–∏–≤–µ–¥–µ–Ω–Ω—ã—Ö –≤—ã—à–µ —à–∞–≥–æ–≤. –ú—ã –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ —É –Ω–∞—Å –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç —Ç–æ–ª—å–∫–æ —Ç–µ –ø–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ –æ–∂–∏–¥–∞–µ—Ç –Ω–∞—à–∞ –º–æ–¥–µ–ª—å:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_mrpc = tokenized_mrpc.remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
    "tokenized_mrpc = tokenized_mrpc.rename_column(\"label\", \"labels\")\n",
    "tokenized_mrpc.set_format(\"torch\")\n",
    "tokenized_mrpc[\"train\"].column_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å, –∫–æ–≥–¥–∞ –¥–∞—Ç–∞—Å–µ—Ç –≥–æ—Ç–æ–≤, –º—ã –º–æ–∂–µ–º –∑–∞–¥–∞—Ç—å `dataloader`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader_mrpc = DataLoader(\n",
    "    tokenized_mrpc[\"train\"], shuffle=True, batch_size=8, collate_fn=data_collator\n",
    ")\n",
    "eval_dataloader_mrpc = DataLoader(\n",
    "    tokenized_mrpc[\"validation\"], batch_size=8, collate_fn=data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è –≤ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–∏ –æ—à–∏–±–æ–∫ –≤ —Å–¥–µ–ª–∞–Ω–Ω–æ–π –Ω–∞–º–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ, –º—ã –º–æ–∂–µ–º –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –æ–¥–∏–Ω –±–∞—Ç—á –¥–∞–Ω–Ω—ã—Ö:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader_mrpc:\n",
    "    break\n",
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ, —á—Ç–æ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ —Ä–∞–∑–º–µ—Ä—ã, –≤–µ—Ä–æ—è—Ç–Ω–æ, –±—É–¥—É—Ç –Ω–µ–º–Ω–æ–≥–æ –æ—Ç–ª–∏—á–∞—Ç—å—Å—è –≤ –≤–∞—à–µ–º —Å–ª—É—á–∞–µ, —Ç–∞–∫ –∫–∞–∫ –º—ã —É—Å—Ç–∞–Ω–æ–≤–∏–ª–∏ `shuffle=True` –¥–ª—è –æ–±—É—á–∞—é—â–µ–≥–æ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö, —Ç–∞–∫–∂–µ –º—ã –¥–æ–ø–æ–ª–Ω—è–µ–º (padding) –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –≤–Ω—É—Ç—Ä–∏ –±–∞—Ç—á–∞.\n",
    "\n",
    "–¢–µ–ø–µ—Ä—å –º—ã –ø–æ–ª–Ω–æ—Å—Ç—å—é –∑–∞–≤–µ—Ä—à–∏–ª–∏ —ç—Ç–∞–ø –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∏, –ø–µ—Ä–µ–π–¥–µ–º –∫ –º–æ–¥–µ–ª–∏. –ú—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –µ–µ —Ç–æ—á–Ω–æ —Ç–∞–∫ –∂–µ, –∫–∞–∫ –≤ –ø—Ä–µ–¥—ã–¥—É—â–µ–º –ø—Ä–∏–º–µ—Ä–µ:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model_mrpc = AutoModelForSequenceClassification.from_pretrained(\n",
    "    checkpoint, num_labels=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã —É–±–µ–¥–∏—Ç—å—Å—è, —á—Ç–æ –æ–±—É—á–µ–Ω–∏–µ –ø–æ–π–¥–µ—Ç –≥–ª–∞–¥–∫–æ, –ø–æ–¥–∞–¥–∏–º –Ω–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –æ–¥–∏–Ω –±–∞—Ç—á:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_mrpc = model_mrpc(**batch)\n",
    "print(outputs_mrpc.loss, outputs_mrpc.logits.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—Å–µ –º–æ–¥–µ–ª–∏ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤ –≤–æ–∑–≤—Ä–∞—â–∞—é—Ç –∑–Ω–∞—á–µ–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å, –µ—Å–ª–∏ –≤ –¥–∞–Ω–Ω—ã—Ö –±—ã–ª–∏ `labels`, –∞ —Ç–∞–∫–∂–µ –ª–æ–≥–∏—Ç—ã (–≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Ç–µ–Ω–∑–æ—Ä 8 √ó 2).\n",
    "\n",
    "–ú—ã –ø–æ—á—Ç–∏ –≥–æ—Ç–æ–≤—ã –∫ –Ω–∞–ø–∏—Å–∞–Ω–∏—é –æ–±—É—á–∞—é—â–µ–≥–æ —Ü–∏–∫–ª–∞! –ú—ã –ø—Ä–æ–ø—É—Å—Ç–∏–ª–∏ —Ç–æ–ª—å–∫–æ –¥–≤–µ –≤–µ—â–∏: –æ–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è (learning rate scheduler). –í–≤–∏–¥—É —Ç–æ–≥–æ, —á—Ç–æ –º—ã –ø—ã—Ç–∞–µ–º—Å—è –ø–æ–≤—Ç–æ—Ä–∏—Ç—å –≤—Ä—É—á–Ω—É—é —Ç–æ, —á—Ç–æ –¥–µ–ª–∞–ª –∑–∞ –Ω–∞—Å `Trainer`, –º—ã –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–∞–∫–∏–µ –∂–µ –∑–Ω–∞—á–µ–Ω–∏—è –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é. –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä, –∏—Å–ø–æ–ª—å–∑—É–µ–º—ã–π –≤ Trainer, ‚Äî `AdamW`, –∫–æ—Ç–æ—Ä—ã–π —è–≤–ª—è–µ—Ç—Å—è –ø–æ—á—Ç–∏ –ø–æ–ª–Ω–æ–π –∫–æ–ø–∏–µ–π Adam, –∑–∞ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ–º –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ (weight decay). –û–Ω–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —à—Ç—Ä–∞—Ñ –∑–∞ –≤—ã—Å–æ–∫–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤–µ—Å–æ–≤ –Ω–µ–π—Ä–æ–Ω–Ω–æ–π —Å–µ—Ç–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer_mrpc = AdamW(model_mrpc.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–∫–æ–Ω–µ—Ü, –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–ª–∞–Ω–∏—Ä–æ–≤—â–∏–∫ —Å–∫–æ—Ä–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–π —É–º–µ–Ω—å—à–∞–µ—Ç —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏ –∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏. –ü—Ä–∏ —Ç–∏–ø–µ `\"linear\"` —Å–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è –ª–∏–Ω–µ–π–Ω–æ —É–º–µ–Ω—å—à–∞–µ—Ç—Å—è –æ—Ç –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–æ 0 –∑–∞ –∑–∞–¥–∞–Ω–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤. –û–Ω–æ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ —á–∏—Å–ª–∞ —ç–ø–æ—Ö –∏ —á–∏—Å–ª–∞ –±–∞—Ç—á–µ–π (–¥–ª–∏–Ω—ã –Ω–∞—à–µ–≥–æ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö).\n",
    "\n",
    "–ß–∏—Å–ª–æ —ç–ø–æ—Ö –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤ `Trainer` —Ä–∞–≤–Ω–æ 3, —Ç–∞–∫ –∂–µ –º—ã –∑–∞–¥–∞–¥–∏–º –µ–≥–æ –∏ —Å–µ–π—á–∞—Å:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_epochs_mrpc = 3\n",
    "num_training_steps_mrpc = num_epochs_mrpc * len(train_dataloader_mrpc)\n",
    "lr_scheduler_mrpc = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer_mrpc,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps_mrpc,\n",
    ")\n",
    "print(num_training_steps_mrpc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –û–±—É—á–∞—é—â–∏–π —Ü–∏–∫–ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–ª–µ–¥–Ω–∏–π –º–æ–º–µ–Ω—Ç: –º—ã —Ö–æ—Ç–∏–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU –≤ —Å–ª—É—á–∞–µ, –µ—Å–ª–∏ —É –Ω–∞—Å –±—É–¥–µ—Ç —Ç–∞–∫–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å (–Ω–∞ CPU –ø—Ä–æ—Ü–µ—Å—Å –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞—Å–æ–≤ –≤–º–µ—Å—Ç–æ –ø–∞—Ä—ã –º–∏–Ω—É—Ç). –ß—Ç–æ–±—ã –¥–æ–±–∏—Ç—å—Å—è —ç—Ç–æ–≥–æ, –º—ã –æ–ø—Ä–µ–¥–µ–ª–∏–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é `device` –∏ ¬´–ø—Ä–∏–∫—Ä–µ–ø–∏–º¬ª –∫ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–µ –Ω–∞—à—É –º–æ–¥–µ–ª—å –∏ –¥–∞–Ω–Ω—ã–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model_mrpc.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –º—ã –≥–æ—Ç–æ–≤—ã –∫ –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–∏! –ß—Ç–æ–±—ã –∏–º–µ—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ –æ —Ç–æ–º, —Å–∫–æ–ª—å–∫–æ –≤—Ä–µ–º–µ–Ω–∏ —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å, –º—ã –¥–æ–±–∞–≤–∏–º –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –ø—Ä–æ–≥—Ä–µ—Å—Å–∞, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏–ª–ª—é—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å, —Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤ –æ–±—É—á–µ–Ω–∏—è —É–∂–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ. –≠—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –±–∏–±–∏–ª–∏–æ—Ç–µ–∫–∏ [tqdm üõ†Ô∏è[doc]](https://tqdm.github.io/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "progress_bar_mrpc = tqdm(range(num_training_steps_mrpc))\n",
    "\n",
    "model_mrpc.train()\n",
    "for epoch in range(num_epochs_mrpc):\n",
    "    for batch in train_dataloader_mrpc:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model_mrpc(**batch)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer_mrpc.step()\n",
    "        lr_scheduler_mrpc.step()\n",
    "        optimizer_mrpc.zero_grad()\n",
    "        progress_bar_mrpc.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í—ã –º–æ–∂–µ—Ç–µ –∑–∞–º–µ—Ç–∏—Ç—å, —á—Ç–æ –ø—Ä–æ—Ü–µ—Å—Å –æ–±—É—á–µ–Ω–∏—è –≤—ã–≥–ª—è–¥–∏—Ç –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∏–º –Ω–∞ —Ç–æ, –∫–∞–∫ –æ–Ω –≤—ã–≥–ª—è–¥–µ–ª –≤ –Ω–∞—à–∏—Ö –ø–µ—Ä–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–∞—Ö. –ú—ã –Ω–µ —É–∫–∞–∑—ã–≤–∞–ª–∏ –º–æ–¥–µ–ª–∏, —á—Ç–æ–±—ã –æ–Ω–∞ –Ω–∞–º —á—Ç–æ-—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–ª–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—É—á–µ–Ω–∏—è. –î–ª—è —ç—Ç–æ–≥–æ –º—ã –¥–æ–±–∞–≤–∏–º —Ü–∏–∫–ª –≤–∞–ª–∏–¥–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã–π —Ü–∏–∫–ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–Ω–µ–µ –º—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ –º–µ—Ç—Ä–∏–∫—É, –∫–æ—Ç–æ—Ä—É—é –Ω–∞–º –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–ª–∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ [Evaluate üõ†Ô∏è[doc]](https://huggingface.co/docs/evaluate/index). –ú—ã —É–∂–µ –∑–Ω–∞–µ–º, —á—Ç–æ –µ—Å—Ç—å –º–µ—Ç–æ–¥ `metric.compute()`, –æ–¥–Ω–∞–∫–æ –º–µ—Ç—Ä–∏–∫–∏ –º–æ–≥—É—Ç –Ω–∞–∫–∞–ø–ª–∏–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –∏—Ç–µ—Ä–∏—Ä–æ–≤–∞–Ω–∏—è –ø–æ –±–∞—Ç—á—É, –¥–ª—è —ç—Ç–æ–≥–æ –µ—Å—Ç—å –º–µ—Ç–æ–¥ `add_batch()`. –ü–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ –º—ã –ø—Ä–æ–π–¥–µ–º—Å—è –ø–æ –≤—Å–µ–º –±–∞—Ç—á–∞–º, –º—ã —Å–º–æ–∂–µ–º –≤—ã—á–∏—Å–ª–∏—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Å –ø–æ–º–æ—â—å—é `metric.compute()`. –í–æ—Ç –ø—Ä–∏–º–µ—Ä —Ç–æ–≥–æ, –∫–∞–∫ —ç—Ç–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –≤ —Ü–∏–∫–ª–µ –≤–∞–ª–∏–¥–∞—Ü–∏–∏:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric_mrpc = evaluate.load(\"glue\", \"mrpc\")\n",
    "model_mrpc.eval()\n",
    "for batch in eval_dataloader_mrpc:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model_mrpc(**batch)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    metric_mrpc.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
    "\n",
    "metric_mrpc.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è –¥—Ä—É–≥–∏—Ö –∑–∞–¥–∞—á"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–º–∏–º–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π, —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —ç–Ω–∫–æ–¥–µ—Ä–∞ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –¥–æ–æ–±—É—á–µ–Ω–∞ –¥–ª—è —Ç–∞–∫–∏—Ö –∑–∞–¥–∞—á, –∫–∞–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–∫–µ–Ω–∞ –∏ –ø–æ–∏—Å–∫ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ—Ä–æ–º –ø–µ—Ä–≤–æ–π –∑–∞–¥–∞—á–∏ —è–≤–ª—è–µ—Ç—Å—è —Ä–∞–∑–º–µ—Ç–∫–∞ —Ç–µ–∫—Å—Ç–æ–≤, –≤ —á–∞—Å—Ç–Ω–æ—Å—Ç–∏, –≤—ã–¥–µ–ª–µ–Ω–∏–µ –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π (**Named Entity Recognition**, ***NER***):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-content/L06/out/ner.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Å–ª—É—á–∞–µ –≤—Ç–æ—Ä–æ–π –∑–∞–¥–∞—á–∏, –ø–æ-–∞–Ω–≥–ª–∏–π—Å–∫–∏ –Ω–∞–∑—ã–≤–∞–µ–º–æ–π ***Question Answering (QA)***, –æ—Ç–≤–µ—Ç **–∏–∑–≤–ª–µ–∫–∞–µ—Ç—Å—è** (extract) –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. –ö–æ–Ω—Ç–µ–∫—Å—Ç –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—É—Å—Ç—ã–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L06/qa_example.png\" width=\"500\"></center>\n",
    "\n",
    "<center><em>Source: <a href=\"https://www.deleeuw.me.uk/posts/Using-PrimeQA-For-NLP-Question-Answering/\">Using PrimeQA For NLP Question Answering</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ—Ä—ã —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è –¥–∞–Ω–Ω—ã—Ö –∑–∞–¥–∞—á –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –≤ —Ç—å—é—Ç–æ—Ä–∏–∞–ª–∞—Ö Hugging Face:\n",
    "- [[doc] üõ†Ô∏è Token classification](https://huggingface.co/learn/nlp-course/en/chapter7/2?fw=pt)\n",
    "- [[doc] üõ†Ô∏è Question answering](https://huggingface.co/learn/nlp-course/en/chapter7/7?fw=pt)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
