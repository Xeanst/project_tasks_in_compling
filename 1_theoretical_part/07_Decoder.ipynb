{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">–ú–æ–¥–µ–ª–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ–∫–æ–¥–µ—Ä–∞ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ —Å–æ—Å—Ç–æ–∏—Ç –∏–∑ —ç–Ω–∫–æ–¥–µ—Ä–∞ –∏ –¥–µ–∫–æ–¥–µ—Ä–∞.\n",
    "\n",
    "–ù–∞ –æ—Å–Ω–æ–≤–µ —ç–Ω–∫–æ–¥–µ—Ä–∞ –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞ –º–æ–¥–µ–ª—å BERT –∏ –ø–æ–¥–æ–±–Ω—ã–µ –µ–π (RoBERTa, ALBERT). –û–Ω–∏ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö –≤–µ–∫—Ç–æ—Ä–Ω—ã—Ö –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–π —Å–ª–æ–≤ –∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π. –ó–∞—Ç–µ–º –º–æ–¥–µ–ª–∏ –¥–æ–æ–±—É—á–∞—é—Ç—Å—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∑–∞–¥–∞—á–∏, —á—Ç–æ —Ç—Ä–µ–±—É–µ—Ç –Ω–∞–ª–∏—á–∏—è —Ä–∞–∑–º–µ—á–µ–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "–ù–∞ –æ—Å–Ω–æ–≤–µ –¥–µ–∫–æ–¥–µ—Ä–∞ –±—ã–ª–∞ —Å–æ–∑–¥–∞–Ω–∞ –º–æ–¥–µ–ª—å GPT ‚Äî Generative Pretrained Transformer. –ú–æ–¥–µ–ª—å GPT –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ –Ω–∞ –∑–∞–¥–∞—á–µ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è, —Ç–æ –µ—Å—Ç—å –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏) —Å–ª–µ–¥—É—é—â–µ–≥–æ —Å–ª–æ–≤–∞ –≤ —Ç–µ–∫—Å—Ç–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ß–µ—Ç—ã—Ä–µ –ø–æ–∫–æ–ª–µ–Ω–∏—è GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é GPT –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å–ª–µ–¥—É—é—â–µ–µ:\n",
    "\n",
    "1. –í—Ö–æ–¥–Ω–æ–π —Ç–µ–∫—Å—Ç —Ç–æ–∫–µ–Ω–∏–∑–∏—Ä—É–µ—Ç—Å—è –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —á–∏—Å–µ–ª (—Ç–æ–∫–µ–Ω–æ–≤).\n",
    "2. –°–ø–∏—Å–æ–∫ —Ç–æ–∫–µ–Ω–æ–≤ –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ Embedding layer (–ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π) –∏ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤—ã–≤–∞–µ—Ç—Å—è –≤ —Å–ø–∏—Å–æ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.\n",
    "3. –ö –∫–∞–∂–¥–æ–º—É —ç–º–±–µ–¥–¥–∏–Ω–≥—É –ø—Ä–∏–±–∞–≤–ª—è–µ—Ç—Å—è **positional embedding**.\n",
    "4. –°–ø–∏—Å–æ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø—Ä–æ—Ö–æ–¥–∏—Ç —á–µ—Ä–µ–∑ –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–¥–∏–Ω–∞–∫–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤ (Transformer Decoder Block).\n",
    "5. –ü–æ—Å–ª–µ —Ç–æ–≥–æ –∫–∞–∫ —Å–ø–∏—Å–æ–∫ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –ø—Ä–æ–π–¥—ë—Ç —á–µ—Ä–µ–∑ –ø–æ—Å–ª–µ–¥–Ω–∏–π –±–ª–æ–∫, —ç–º–±–µ–¥–¥–∏–Ω–≥, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π –ø–æ—Å–ª–µ–¥–Ω–µ–º—É —Ç–æ–∫–µ–Ω—É, –º–∞—Ç—Ä–∏—á–Ω–æ —É–º–Ω–æ–∂–∞–µ—Ç—Å—è –Ω–∞ –≤—Å—ë —Ç–æ—Ç –∂–µ –≤—Ö–æ–¥–Ω–æ–π, –Ω–æ —É–∂–µ —Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–π Embedding Layer, –∏ –ø–æ—Å–ª–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è SoftMax –ø–æ–ª—É—á–∞–µ—Ç—Å—è —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞.\n",
    "6. –ò–∑ —ç—Ç–æ–≥–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–π —Ç–æ–∫–µ–Ω (–Ω–∞–ø—Ä–∏–º–µ—Ä, —Å –ø–æ–º–æ—â—å—é argmax).\n",
    "7. –ü–æ–ª—É—á–µ–Ω–Ω—ã–π —Ç–æ–∫–µ–Ω –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ –≤—Ö–æ–¥–Ω–æ–º—É —Å–ø–∏—Å–∫—É —Ç–æ–∫–µ–Ω–æ–≤, —à–∞–≥–∏ 1‚Äî6 –ø–æ–≤—Ç–æ—Ä—è—é—Ç—Å—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/gpt3.gif\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://jalammar.github.io/how-gpt3-works-visualizations-animations/\">How GPT3 Works ‚Äî Visualizations and Animations</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[paper] üéì Improving Language Understanding by Generative Pre-Training (2018)](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)\n",
    "\n",
    "- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 117 –º–∏–ª–ª–∏–æ–Ω–æ–≤.\n",
    "- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤: 12.\n",
    "- –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: 5 –ì–ë.\n",
    "- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: 512 —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "\n",
    "–ü–µ—Ä–≤–∞—è –≤–µ—Ä—Å–∏—è —ç—Ç–æ–π –º–æ–¥–µ–ª–∏ –±—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ –Ω–∞ 7000 –∫–Ω–∏–≥.\n",
    "\n",
    "–ö–∞–∫ —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –æ–Ω–∞ —Ä–∞–±–æ—Ç–∞–ª–∞ –Ω–µ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ, –Ω–æ –ø—Ä–∏ –¥–æ–æ–±—É—á–µ–Ω–∏–∏ –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö –ø–æ–∫–∞–∑—ã–≤–∞–ª–∞ –≤—ã—Å–æ–∫–æ–µ –∫–∞—á–µ—Å—Ç–≤–æ.\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ SOTA —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã GPT-1 –¥–µ—Ä–∂–∞–ª–∏—Å—å –Ω–µ–¥–æ–ª–≥–æ, —Ç–∞–∫ –∫–∞–∫ –ø–æ—è–≤–∏–ª—Å—è BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/gpt1.jpg\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf\">Improving Language Understanding by Generative Pre-Training</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[paper] üéì Language Models are Unsupervised Multitask Learners (2019)](https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)\n",
    "\n",
    "- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 1.5 –º–∏–ª–ª–∏–∞—Ä–¥–∞.\n",
    "- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤: 48.\n",
    "- –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: 40 –ì–ë.\n",
    "- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: 1024 —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "\n",
    "\n",
    "–ù–æ–≤–∞—è GPT-2 –Ω–µ —Å–æ–¥–µ—Ä–∂–∞–ª–∞ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã—Ö –Ω–æ–≤–æ–≤–≤–µ–¥–µ–Ω–∏–π, –æ—Å–Ω–æ–≤–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è –¥–æ—Å—Ç–∏–≥–∞–ª–∏—Å—å –∑–∞ —Å—á–µ—Ç —É–≤–µ–ª–∏—á–µ–Ω–∏—è —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏ –∏ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –¥–∞–Ω–Ω—ã—Ö (–∫ –∫–Ω–∏–≥–∞–º –¥–æ–±–∞–≤–∏–ª–∏ 8 –º–∏–ª–ª–∏–æ–Ω–æ–≤ —Å–∞–π—Ç–æ–≤).\n",
    "\n",
    "GPT-2 –Ω–∞—É—á–∏–ª–∞—Å—å –ø–∏—Å–∞—Ç—å –¥–ª–∏–Ω–Ω—ã–µ —Å–≤—è–∑–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/gpt2.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://en.wikipedia.org/wiki/GPT-2\">GPT-2</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∂–µ GPT-2 —É–∂–µ –º–æ–≥–ª–∞ –±–µ–∑ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –≤—ã–ø–æ–ª–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä—ã–µ –∑–∞–¥–∞—á–∏, –¥–ª—è –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ –±—ã–ª–æ —è–≤–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –ù–∞–ø—Ä–∏–º–µ—Ä, –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–æ–ø–∏—Å–∞—Ç—å `TL;DR` –ø–æ—Å–ª–µ —Ç–µ–∫—Å—Ç–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/gpt2_tldr.jpg\" width=\"850\"></center>\n",
    "\n",
    "<center><em>–ü—Ä–∏–º–µ—Ä —Ä–∞–±–æ—Ç—ã GPT-2</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[paper] üéì Language Models are Few-Shot Learners (2020)](https://arxiv.org/pdf/2005.14165.pdf)\n",
    "\n",
    "- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: 175 –º–∏–ª–ª–∏–∞—Ä–¥–æ–≤.\n",
    "- –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤: 96.\n",
    "- –†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö: 45 –¢–ë (—Ç.–µ. 45 000 –ì–ë).\n",
    "- –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞: 2048 —Ç–æ–∫–µ–Ω–æ–≤.\n",
    "\n",
    "GPT-3 –æ–±—É—á–µ–Ω–∞ –Ω–∞ –µ—â—ë –±–æ–ª—å—à–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö ‚Äî –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞, –≤—Å—è –∞–Ω–≥–ª–∏–π—Å–∫–∞—è –í–∏–∫–∏–ø–µ–¥–∏—è —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç —Ç–æ–ª—å–∫–æ 0,6% –∏–∑ –Ω–∏—Ö.\n",
    "\n",
    "–ú–æ–¥–µ–ª—å –Ω–∞—É—á–∏–ª–∞—Å—å —Ä–µ—à–∞—Ç—å –º–Ω–æ–≥–æ NLP-–∑–∞–¥–∞—á –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <table >\n",
    "     <tr>\n",
    "       <td>\n",
    "       \n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/gpt3_gec.jpg\" width=\"440\"></center>\n",
    "\n",
    "<em>–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –æ—à–∏–±–æ–∫</em>\n",
    "\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/gpt3_sa.jpg\" width=\"450\"></center>\n",
    "\n",
    "<em>–ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏</em>\n",
    "\n",
    "\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/gpt3_mt.jpg\" width=\"500\"></center>\n",
    "\n",
    "<em>–ú–∞—à–∏–Ω–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥</em>\n",
    "\n",
    "\n",
    "</td>\n",
    "     </tr>\n",
    "    </table>\n",
    "    </div>\n",
    "\n",
    "<center><em>–ü—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç—ã GPT-3 beta</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPT-3 —Ç–∞–∫–∂–µ —Å–ø–æ—Å–æ–±–Ω–∞ –ø–∏—Å–∞—Ç—å –∏ –ø–æ–Ω–∏–º–∞—Ç—å –ø—Ä–æ–≥—Ä–∞–º–º–Ω—ã–π –∫–æ–¥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "    <table >\n",
    "     <tr>\n",
    "       <td>\n",
    "       \n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/gpt3_code_promt.jpg\" width=\"300\"></center>\n",
    "\n",
    "<em>–ó–∞–ø—Ä–æ—Å</em>\n",
    "\n",
    "</td>\n",
    "\n",
    "<td>\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/gpt3_code_response.jpg\" width=\"400\"></center>\n",
    "\n",
    "<em>–ü—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞</em>\n",
    "\n",
    "\n",
    "</td>\n",
    "     </tr>\n",
    "    </table>\n",
    "    </div>\n",
    "\n",
    "<center><em>–ü—Ä–∏–º–µ—Ä—ã —Ä–∞–±–æ—Ç—ã GPT-3 beta</em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°—Ç–∞—Ç—å—è –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç.\n",
    "\n",
    "- –ù–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø—Ä–æ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏.\n",
    "- –†–∞–±–æ—Ç–∞–µ—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º –¥–æ 8192 —Ç–æ–∫–µ–Ω–æ–≤. –ï—Å—Ç—å –≤–µ—Ä—Å–∏—è, –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é—â–∞—è 32 768 —Ç–æ–∫–µ–Ω–æ–≤ (50 —Å—Ç—Ä–∞–Ω–∏—Ü).\n",
    "\n",
    "–ü–æ–º–∏–º–æ —Ç–µ–∫—Å—Ç–æ–≤, —É–º–µ–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏, —è–≤–ª—è–µ—Ç—Å—è –º—É–ª—å—Ç–∏–º–æ–¥–∞–ª—å–Ω–æ–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/gpt4.jpg\" width=\"550\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://thecymes.com/article/the-game-changing-features-of-openais-chatgpt-4\">The game-changing features of OpenAI's GPT 4</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –¢–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞ —Ä–∞–±–æ—Ç—É –º–æ–¥–µ–ª–∏ ruGPT-3 –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –û–Ω–∞ –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ —Ç—Ä–µ—Ö –≤–∞—Ä–∏–∞–Ω—Ç–∞—Ö:\n",
    "- [[doc] üõ†Ô∏è](https://huggingface.co/ai-forever/rugpt3small_based_on_gpt2) `ai-forever/rugpt3small_based_on_gpt2` ‚Äî small\n",
    "- [[doc] üõ†Ô∏è](https://huggingface.co/ai-forever/rugpt3medium_based_on_gpt2) `ai-forever/rugpt3medium_based_on_gpt2` ‚Äî medium\n",
    "- [[doc] üõ†Ô∏è](https://huggingface.co/ai-forever/rugpt3large_based_on_gpt2) `ai-forever/rugpt3large_based_on_gpt2` ‚Äî large\n",
    "\n",
    "–î–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –∫–ª–∞—Å—Å `AutoTokenizer` [üõ†Ô∏è[doc]](https://huggingface.co/docs/transformers/v4.45.2/en/model_doc/auto#transformers.AutoTokenizer), –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ ‚Äî –∫–ª–∞—Å—Å `AutoModelForCausalLM` [üõ†Ô∏è[doc]](https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForCausalLM).\n",
    "\n",
    "–í—ã–±–µ—Ä–µ–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –º–æ–¥–µ–ª—å. API –¥–ª—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –æ–¥–∏–Ω–∞–∫–æ–≤—ã–π, –¥–ª—è –ø–æ–¥–º–µ–Ω—ã –º–æ–¥–µ–ª–∏ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –∏–∑–º–µ–Ω–∏—Ç—å –Ω–∞–∑–≤–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ `model_name`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"ai-forever/rugpt3large_based_on_gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –º—ã —Ö–æ—Ç–∏–º –ø—Ä–∏ –ø–æ–º–æ—â–∏ —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å: **¬´–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2+2?¬ª**, —Ç–æ –º–æ–∂–µ–º –ø–æ–¥–∞—Ç—å –Ω–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç:\\\n",
    "`¬´–í–æ–ø—Ä–æ—Å: –°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2+2? –û—Ç–≤–µ—Ç: ‚Ä¶ ¬ª`\\\n",
    "–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω—ã–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ–º —Ç–∞–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –±—É–¥–µ—Ç –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å, –ø–æ—ç—Ç–æ–º—É –º–æ–¥–µ–ª—å –¥–æ–ø–∏—à–µ—Ç `¬´4¬ª`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"–í–æ–ø—Ä–æ—Å: '–°–∫–æ–ª—å–∫–æ –±—É–¥–µ—Ç 2+2?'\\n–û—Ç–≤–µ—Ç:\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "out = model.generate(input_ids, do_sample=False, max_length=20, pad_token_id=20)\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –ø—Ä–∏–º–µ—Ä —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏–∏. –ö–∞–∫ –∏ BERT-like –º–æ–¥–µ–ª–∏, GPT –∏—Å–ø–æ–ª—å–∑—É–µ—Ç —Ç–æ–∫–µ–Ω–∏–∑–∞—Ü–∏—é –Ω–∞ –ø–æ–¥—Å–ª–æ–≤–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"–¢–æ–∫–µ–Ω–∏–∑–∏—Ä—É–π –º–µ–Ω—è\"  # raw text\n",
    "tokens = tokenizer.encode(text, add_special_tokens=False)  # applying ruGPT-3 tokenizer\n",
    "decoded_tokens = [\n",
    "    tokenizer.decode([token]) for token in tokens\n",
    "]  # converting ids to tokens\n",
    "\n",
    "print(\"text:\", text)\n",
    "print(\"tokens: \", tokens)\n",
    "print(\"decoded tokens: \", decoded_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å –≤—ã–¥–∞—ë—Ç —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞, —ç—Ç—É –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –º–æ–∂–Ω–æ –ø–æ-—Ä–∞–∑–Ω–æ–º—É –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞.\n",
    "\n",
    "–î–ª—è –Ω–∞–≥–ª—è–¥–Ω–æ—Å—Ç–∏ –ø—Ä–∏–º–µ–Ω–∏–º –≤—Å–µ –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç–æ–¥—ã –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ: '–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: \"–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å\" ‚Äî —ç—Ç–æ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "text = '–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: \"–Ø–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å\" ‚Äî —ç—Ç–æ'\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ñ–∞–¥–Ω—ã–π –ø–æ–∏—Å–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–∞–º—ã–π –ø—Ä–æ—Å—Ç–æ–π —Å–ø–æ—Å–æ–± ‚Äî –∂–∞–¥–Ω—ã–π –ø–æ–∏—Å–∫ (greedy search): –∫–∞–∂–¥—ã–π —Ä–∞–∑ –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è —Ç–æ–∫–µ–Ω, —É –∫–æ—Ç–æ—Ä–æ–≥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å.\n",
    "\n",
    "–ü—Ä–∏ —Ç–∞–∫–æ–º —Å–ø–æ—Å–æ–±–µ –º—ã –Ω–µ –ø–æ–ª—É—á–∏–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ –æ–¥–∏–Ω –∏ —Ç–æ—Ç –∂–µ –∑–∞–ø—Ä–æ—Å, –∏, —á—Ç–æ –µ—â—ë —Ö—É–∂–µ, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –º–æ–∂–µ—Ç –∑–∞—Å—Ç—Ä–µ–≤–∞—Ç—å –≤ –ª–æ–∫–∞–ª—å–Ω—ã—Ö –º–∏–Ω–∏–º—É–º–∞—Ö –∏ –≤—ã–¥–∞–≤–∞—Ç—å –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä `the the the the ...`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/greedy_seacrh.png\" width=\"500\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://habr.com/ru/articles/589663/\">–ö—Ä–∞—Ç–∫–∏–π —ç–∫—Å–∫—É—Ä—Å –≤ ruGPT-3</a></em></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of greedy search\n",
    "out = model.generate(input_ids, do_sample=False, max_length=45)\n",
    "\n",
    "# Decoding\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –õ—É—á–µ–≤–æ–π –ø–æ–∏—Å–∫"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—É—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –∏ –∫–∞—á–µ—Å—Ç–≤–µ–Ω–Ω—ã–π —Å–ø–æ—Å–æ–± ‚Äî —ç—Ç–æ –ª—É—á–µ–≤–æ–π –ø–æ–∏—Å–∫ (beam search). –ù–∞ –∫–∞–∂–¥–æ–º —à–∞–≥–µ –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –Ω–µ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Å–∞–º—ã–π –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ç–æ–∫–µ–Ω, –∞ —Å—Ä–∞–∑—É –Ω–µ—Å–∫–æ–ª—å–∫–æ (–∑–∞ –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ—Ç–≤–µ—á–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä `num_beams`). –î–∞–ª—å—à–µ –ø—Ä–æ–¥–æ–ª–∂–∞–µ—Ç—Å—è –ø–æ–∏—Å–∫ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑ –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤. –ü—É—Ç–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–∞–∑–≤–µ—Ç–≤–ª—è—é—Ç—Å—è, —á—Ç–æ –¥–∞–µ—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ –≤–∞—Ä–∏–∞–Ω—Ç–æ–≤ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/beam_search.png\" width=\"500\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://habr.com/ru/articles/589663/\">–ö—Ä–∞—Ç–∫–∏–π —ç–∫—Å–∫—É—Ä—Å –≤ ruGPT-3</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ–±–ª–∞–¥–∞–µ—Ç —Ö–æ—Ä–æ—à–µ–π –∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å—é (—Å–≤—è–∑–Ω–æ—Å—Ç—å—é), –Ω–æ –æ–±—ã—á–Ω–æ —É –Ω–∏—Ö –Ω–µ —Ö–≤–∞—Ç–∞–µ—Ç \"—á–µ–ª–æ–≤–µ—á–Ω–æ—Å—Ç–∏\", –æ–Ω–∏ –∫–∞–∂—É—Ç—Å—è —Å—É—Ö–∏–º–∏ –∏ —Å–∫—É—á–Ω—ã–º–∏. –¢–∞–∫–∂–µ —ç—Ç–æ –Ω–µ –ø–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ—à–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –ø–æ–≤—Ç–æ—Ä—è—é—â–∏—Ö—Å—è —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of beam search\n",
    "out = model.generate(input_ids, do_sample=False, num_beams=5, max_length=45)\n",
    "\n",
    "# Decoding\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–∂–Ω–æ –≤—ã–≤–µ—Å—Ç–∏ –Ω–µ —Ç–æ–ª—å–∫–æ –Ω–∞–∏–±–æ–ª–µ–µ –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç, –Ω–æ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –¥—Ä—É–≥–∏–º –ª—É—á–∞–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set return_num_sequences > 1\n",
    "out = model.generate(\n",
    "    input_ids, do_sample=False, num_beams=45, max_length=40, num_return_sequences=5\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * \"-\")\n",
    "for i, beam_output in enumerate(out):\n",
    "    print(\"{}: {}\\n\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ –º–æ–∂–Ω–æ —É–º–µ–Ω—å—à–∏—Ç—å, –µ—Å–ª–∏ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø—Ä–µ—Ç –Ω–∞ –ø–æ–≤—Ç–æ—Ä *n*-–≥—Ä–∞–º–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can prohibit repeating bigrams\n",
    "out = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=False,\n",
    "    num_beams=45,\n",
    "    max_length=40,\n",
    "    num_return_sequences=5,\n",
    "    no_repeat_ngram_size=2,\n",
    ")\n",
    "\n",
    "print(\"Output:\\n\" + 100 * \"-\")\n",
    "for i, beam_output in enumerate(out):\n",
    "    print(\"{}: {}\\n\".format(i, tokenizer.decode(beam_output, skip_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã –¥–æ–±–∞–≤–∏—Ç—å —Ç–µ–∫—Å—Ç—É –Ω–µ–ø—Ä–µ–¥—Å–∫–∞–∑—É–µ–º–æ—Å—Ç–∏ –∏ —á–µ–ª–æ–≤–µ—á–Ω–æ—Å—Ç–∏, –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–Ω–æ–µ —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ —Å —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–æ–π. –ë—É–¥–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –Ω–µ —Å–∞–º—ã–π –≤–µ—Ä–æ—è—Ç–Ω—ã–π —Ç–æ–∫–µ–Ω, –∞ —Å–ª—É—á–∞–π–Ω—ã–π, —Å —É—á—ë—Ç–æ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π.\n",
    "\n",
    "–ü–∞—Ä–∞–º–µ—Ç—Ä —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä—ã –ø–æ–∑–≤–æ–ª—è–µ—Ç –∫–æ–Ω—Ç—Ä–æ–ª–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–µ–ø–µ–Ω—å —Å–ª—É—á–∞–π–Ω–æ—Å—Ç–∏. –ü—Ä–∏ –Ω—É–ª–µ–≤–æ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ –º–µ—Ç–æ–¥ —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å –∂–∞–¥–Ω—ã–º —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º, –ø—Ä–∏  –±–æ–ª—å—à–æ–π —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–µ —Ç–æ–∫–µ–Ω—ã –±—É–¥—É—Ç –≤—ã–±–∏—Ä–∞—Ç—å—Å—è –ø–æ–ª–Ω–æ—Å—Ç—å—é —Å–ª—É—á–∞–π–Ω–æ. –û–±—ã—á–Ω–æ —Ö–æ—Ä–æ—à–æ —Ä–∞–±–æ—Ç–∞–µ—Ç —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω–µ `0.8‚Äì2.0`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/llm_temperature.png\" width=\"1000\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://www.hopsworks.ai/dictionary/llm-temperature\">LLM Temperature</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–§–æ—Ä–º—É–ª–∞ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–∞ –Ω–∞ —Ñ–æ—Ä–º—É–ª—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –ë–æ–ª—å—Ü–º–∞–Ω–∞: —á–µ–º –≤—ã—à–µ —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ —Å–∏—Å—Ç–µ–º—ã, —Ç–µ–º –±–æ–ª—å—à–µ \"—Ä–∞–∑–º–∞–∑—ã–≤–∞–µ—Ç—Å—è\" —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –µ—ë –≤–æ–∑–º–æ–∂–Ω—ã—Ö —Å–æ—Å—Ç–æ—è–Ω–∏–π, –æ—Ç—Å—é–¥–∞ —Å–ª–æ–≤–æ \"—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞\".\n",
    "\n",
    "$$\\large p=\\text{softmax}(\\log(p)/t)$$\n",
    "\n",
    "–°—Ç–æ–∏—Ç –æ—Ç–º–µ—Ç–∏—Ç—å, —á—Ç–æ —Å–ª—É—á–∞–π–Ω–∞—è –ø—Ä–∏—Ä–æ–¥–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –±—É–¥–µ—Ç –∏–Ω–æ–≥–¥–∞ –ø—Ä–∏–≤–æ–¥–∏—Ç—å –∫ –ø–æ–ª–Ω–æ—Å—Ç—å—é –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixing random state\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "# Sampling eith temperature\n",
    "out = model.generate(input_ids, do_sample=True, temperature=1.3, max_length=45)\n",
    "\n",
    "# Decoding\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –°–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ top-k –∏ top-p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –∑–∞–ø—Ä–µ—Ç–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –≤–≤–æ–¥—è—Ç `top-k` –∏–ª–∏ `top-p` –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è. –í —ç—Ç–æ–º —Å–ª—É—á–∞–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è —Ç–æ–∂–µ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º, –Ω–æ –∑–∞—Ä–∞–Ω–µ–µ –æ—Ç—Å–µ–∫–∞—é—Ç—Å—è –≤—Å–µ –º–∞–ª–æ–≤–µ—Ä–æ—è—Ç–Ω—ã–µ —Ç–æ–∫–µ–Ω—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Å–ª—É—á–∞–µ `top-k` –∑–∞–Ω—É–ª—è—é—Ç—Å—è –≤—Å–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –∫—Ä–æ–º–µ `k` —Å–∞–º—ã—Ö –≤–µ—Ä–æ—è—Ç–Ω—ã—Ö.\n",
    "\n",
    "–£—Å—Ç–∞–Ω–æ–≤–∏–≤ $k=6$, –º—ã –±—É–¥–µ–º –≤—ã–±–∏—Ä–∞—Ç—å —Å–ª–µ–¥—É—é—â–µ–µ —Å–ª–æ–≤–æ —Ç–æ–ª—å–∫–æ –∏–∑ 6 —Å–ª–æ–≤ —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å—é:\n",
    "- *nice, dog, car, woman, guy, man* –Ω–∞ 1-–º —à–∞–≥–µ\n",
    "- *drives, is, turns, stops, down, a* –Ω–∞ 2-–º —à–∞–≥–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/top-k.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://huggingface.co/blog/how-to-generate\">How to generate text: using different decoding methods for language generation with Transformers</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í —Å–ª—É—á–∞–µ `top-p` –æ—Å—Ç–∞–µ—Ç—Å—è –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä —Ç–æ–∫–µ–Ω–æ–≤, —á—Ç–æ–±—ã —Å—É–º–º–∞ –∏—Ö –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –±—ã–ª–∞ –Ω–µ –±–æ–ª—å—à–µ `p`. –°–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–≤, –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö –º—ã –≤—ã–±–∏—Ä–∞–µ–º, –º–æ–∂–µ—Ç –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –º–µ–Ω—è—Ç—å—Å—è (—É–≤–µ–ª–∏—á–∏–≤–∞—Ç—å—Å—è –∏ —É–º–µ–Ω—å—à–∞—Ç—å—Å—è).\n",
    "\n",
    "–£—Å—Ç–∞–Ω–æ–≤–∏–º $p=0.92$ –∏ –±—É–¥–µ–º –≤—ã–±–∏—Ä–∞—Ç—å –∏–∑:\n",
    "- 9 —Å–ª–æ–≤ –Ω–∞ 1-–º —à–∞–≥–µ\n",
    "- 3 —Å–ª–æ–≤ –Ω–∞ 2-–º —à–∞–≥–µ\n",
    "\n",
    "–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ `top-p` –Ω–∞–∑—ã–≤–∞—é—Ç —è–¥–µ—Ä–Ω—ã–º —Å–µ–º–ø–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º (nucleus sampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/top-p.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://huggingface.co/blog/how-to-generate\">How to generate text: using different decoding methods for language generation with Transformers</a></em></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state\n",
    "torch.random.manual_seed(42)\n",
    "\n",
    "# Sampling with top-k and top-p restrictions\n",
    "out = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=1.0,\n",
    "    top_k=10,\n",
    "    top_p=0.9,\n",
    "    max_length=45,\n",
    ")\n",
    "# Decoding\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –±–µ–∑ —É—á–∏—Ç–µ–ª—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã –º–æ–¥–µ–ª—å \"–Ω–∞—É—á–∏–ª–∞—Å—å\" –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç—ã –≤ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–º —Å—Ç–∏–ª–µ / –Ω–∞ –Ω–æ–≤–æ–º —è–∑—ã–∫–µ, –º–æ–∂–Ω–æ –æ—Å—É—â–µ—Å—Ç–≤–∏—Ç—å —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –±–µ–∑ —É—á–∏—Ç–µ–ª—è. –§–∞–∫—Ç–∏—á–µ—Å–∫–∏, –º—ã –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –æ–±—É—á–∞—Ç—å –º–æ–¥–µ–ª—å –Ω–∞ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö –¥–ª—è –∑–∞–¥–∞—á–∏ —è–∑—ã–∫–æ–≤–æ–≥–æ –º–æ–¥–µ–ª–∏—Ä–æ–≤–∞–Ω–∏—è, —Ç–æ–ª—å–∫–æ –¥–æ–±–∞–≤–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è –Ω–∞—à–µ–π –∑–∞–¥–∞—á–∏.\n",
    "\n",
    "–í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è –º–æ–¥–µ–ª—å—é –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞, —á—Ç–æ–±—ã –æ–Ω–∞ –ø–æ–º–µ—Å—Ç–∏–ª–∞—Å—å –Ω–∞ GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install -q datasets==3.6.0 transformers\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"ai-forever/rugpt3small_based_on_gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–∞—é—â–∏–π —Ç–µ–∫—Å—Ç –Ω–∞—Ä–µ–∑–∞–µ—Ç—Å—è –Ω–∞ —Å–ª—É—á–∞–π–Ω—ã–µ –±–ª–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç—Å—è –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–∑ 1024 (2048 —É GPT-3) —Ç–æ–∫–µ–Ω–æ–≤, —Ä–∞–∑–¥–µ–ª—è—è—Å—å —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º `<|endoftext|>` —Å–∏–º–≤–æ–ª–æ–º. –í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª—å —É—á–∏—Ç—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å (–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å) –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω –≤ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –æ–¥–∏–Ω –∑–∞ –¥—Ä—É–≥–∏–º –ø—Ä–∏ –ø–æ–º–æ—â–∏ Cross-Entropy Loss.\n",
    "\n",
    "–¢–∞–∫ –∫–∞–∫ –≤—Ö–æ–¥–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—Å–µ–≥–¥–∞ –∑–∞–ø–æ–ª–Ω–µ–Ω–∞ –¥–æ –∫–æ–Ω—Ü–∞, padding –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è. –ù–æ –≤–æ –≤—Ä–µ–º—è –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –¥–ª–∏–Ω–∞ –≤—Ö–æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–π, –ø–æ—ç—Ç–æ–º—É –Ω–∞–¥–æ —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞—Ç—å, —á–µ–º –¥–æ–ø–æ–ª–Ω—è—Ç—å –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –ø–æ–∑–∏—Ü–∏–∏. –ü–æ –¥–µ—Ñ–æ–ª—Ç—É –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ç–æ—Ç –∂–µ `<|endoftext|>`.\n",
    "\n",
    "–í –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –≤–µ—Ä—Å–∏—è—Ö GPT –≤—ã—à–µ—Å–∫–∞–∑–∞–Ω–Ω–æ–µ –º–æ–∂–µ—Ç –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å—Å—è. –ù–∞–ø—Ä–∏–º–µ—Ä, –≤ ruGPT3 –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª—å—à–µ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤: `<s\\>`, `<s>`, `<pad>`, `<unk>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë—É–¥–µ–º —É—á–∏—Ç—å GPT –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∏—Ö–∏ –ú–∞—è–∫–æ–≤—Å–∫–æ–≥–æ. –í –∫–∞—á–µ—Å—Ç–≤–µ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö –≤–æ–∑—å–º—ë–º –≤—Å–µ–≥–æ –ª–∏—à—å –æ–¥–∏–Ω —Å—Ç–∏—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"–î—ã–º —Ç–∞–±–∞—á–Ω—ã–π –≤–æ–∑–¥—É—Ö –≤—ã–µ–ª.\n",
    "–ö–æ–º–Ω–∞—Ç–∞ ‚Äî\n",
    "–≥–ª–∞–≤–∞ –≤ –∫—Ä—É—á–µ–Ω—ã—Ö–æ–≤—Å–∫–æ–º –∞–¥–µ.\n",
    "–í—Å–ø–æ–º–Ω–∏ ‚Äî\n",
    "–∑–∞ —ç—Ç–∏–º –æ–∫–Ω–æ–º\n",
    "–≤–ø–µ—Ä–≤—ã–µ\n",
    "—Ä—É–∫–∏ —Ç–≤–æ–∏, –∏—Å—Å—Ç—É–ø–ª–µ–Ω–Ω—ã–π, –≥–ª–∞–¥–∏–ª.\n",
    "–°–µ–≥–æ–¥–Ω—è —Å–∏–¥–∏—à—å –≤–æ—Ç,\n",
    "—Å–µ—Ä–¥—Ü–µ –≤ –∂–µ–ª–µ–∑–µ.\n",
    "–î–µ–Ω—å –µ—â–µ ‚Äî\n",
    "–≤—ã–≥–æ–Ω–∏—à—å,\n",
    "–º–æ–∂–µ—Ç –±—ã—Ç—å, –∏–∑—Ä—É–≥–∞–≤.\n",
    "–í –º—É—Ç–Ω–æ–π –ø–µ—Ä–µ–¥–Ω–µ–π –¥–æ–ª–≥–æ –Ω–µ –≤–ª–µ–∑–µ—Ç\n",
    "—Å–ª–æ–º–∞–Ω–Ω–∞—è –¥—Ä–æ–∂—å—é —Ä—É–∫–∞ –≤ —Ä—É–∫–∞–≤.\n",
    "–í—ã–±–µ–≥—É,\n",
    "—Ç–µ–ª–æ –≤ —É–ª–∏—Ü—É –±—Ä–æ—à—É —è.\n",
    "–î–∏–∫–∏–π,\n",
    "–æ–±–µ–∑—É–º–ª—é—Å—å,\n",
    "–æ—Ç—á–∞—è–Ω—å–µ–º –∏—Å—Å–µ—á–∞ÃÅ—Å—å.\n",
    "–ù–µ –Ω–∞–¥–æ —ç—Ç–æ–≥–æ,\n",
    "–¥–æ—Ä–æ–≥–∞—è,\n",
    "—Ö–æ—Ä–æ—à–∞—è,\n",
    "–¥–∞–π –ø—Ä–æ—Å—Ç–∏–º—Å—è —Å–µ–π—á–∞—Å.\n",
    "–í—Å–µ —Ä–∞–≤–Ω–æ\n",
    "–ª—é–±–æ–≤—å –º–æ—è ‚Äî\n",
    "—Ç—è–∂–∫–∞—è –≥–∏—Ä—è –≤–µ–¥—å ‚Äî\n",
    "–≤–∏—Å–∏—Ç –Ω–∞ —Ç–µ–±–µ,\n",
    "–∫—É–¥–∞ –Ω–∏ –±–µ–∂–∞–ª–∞ –±.\n",
    "–î–∞–π –≤ –ø–æ—Å–ª–µ–¥–Ω–µ–º –∫—Ä–∏–∫–µ –≤—ã—Ä–µ–≤–µ—Ç—å\n",
    "–≥–æ—Ä–µ—á—å –æ–±–∏–∂–µ–Ω–Ω—ã—Ö –∂–∞–ª–æ–±.\n",
    "–ï—Å–ª–∏ –±—ã–∫–∞ —Ç—Ä—É–¥–æ–º —É–º–æ—Ä—è—Ç ‚Äî\n",
    "–æ–Ω —É–π–¥–µ—Ç,\n",
    "—Ä–∞–∑–ª—è–∂–µ—Ç—Å—è –≤ —Ö–æ–ª–æ–¥–Ω—ã—Ö –≤–æ–¥–∞—Ö.\n",
    "–ö—Ä–æ–º–µ –ª—é–±–≤–∏ —Ç–≤–æ–µ–π,\n",
    "–º–Ω–µ\n",
    "–Ω–µ—Ç—É –º–æ—Ä—è,\n",
    "–∞ —É –ª—é–±–≤–∏ —Ç–≤–æ–µ–π –∏ –ø–ª–∞—á–µ–º –Ω–µ –≤—ã–º–æ–ª–∏—à—å –æ—Ç–¥—ã—Ö.\n",
    "–ó–∞—Ö–æ—á–µ—Ç –ø–æ–∫–æ—è —É—Å—Ç–∞–≤—à–∏–π —Å–ª–æ–Ω ‚Äî\n",
    "—Ü–∞—Ä—Å—Ç–≤–µ–Ω–Ω—ã–π –ª—è–∂–µ—Ç –≤ –æ–ø–æ–∂–∞—Ä–µ–Ω–Ω–æ–º –ø–µ—Å–∫–µ.\n",
    "–ö—Ä–æ–º–µ –ª—é–±–≤–∏ —Ç–≤–æ–µ–π,\n",
    "–º–Ω–µ\n",
    "–Ω–µ—Ç—É —Å–æ–ª–Ω—Ü–∞,\n",
    "–∞ —è –∏ –Ω–µ –∑–Ω–∞—é, –≥–¥–µ —Ç—ã –∏ —Å –∫–µ–º.\n",
    "–ï—Å–ª–∏ –± —Ç–∞–∫ –ø–æ—ç—Ç–∞ –∏–∑–º—É—á–∏–ª–∞,\n",
    "–æ–Ω\n",
    "–ª—é–±–∏–º—É—é –Ω–∞ –¥–µ–Ω—å–≥–∏ –± –∏ —Å–ª–∞–≤—É –≤—ã–º–µ–Ω—è–ª,\n",
    "–∞ –º–Ω–µ\n",
    "–Ω–∏ –æ–¥–∏–Ω –Ω–µ —Ä–∞–¥–æ—Å—Ç–µ–Ω –∑–≤–æ–Ω,\n",
    "–∫—Ä–æ–º–µ –∑–≤–æ–Ω–∞ —Ç–≤–æ–µ–≥–æ –ª—é–±–∏–º–æ–≥–æ –∏–º–µ–Ω–∏.\n",
    "–ò –≤ –ø—Ä–æ–ª–µ—Ç –Ω–µ –±—Ä–æ—à—É—Å—å,\n",
    "–∏ –Ω–µ –≤—ã–ø—å—é —è–¥–∞,\n",
    "–∏ –∫—É—Ä–æ–∫ –Ω–µ —Å–º–æ–≥—É –Ω–∞–¥ –≤–∏—Å–∫–æ–º –Ω–∞–∂–∞—Ç—å.\n",
    "–ù–∞–¥–æ –º–Ω–æ—é,\n",
    "–∫—Ä–æ–º–µ —Ç–≤–æ–µ–≥–æ –≤–∑–≥–ª—è–¥–∞,\n",
    "–Ω–µ –≤–ª–∞—Å—Ç–Ω–æ –ª–µ–∑–≤–∏–µ –Ω–∏ –æ–¥–Ω–æ–≥–æ –Ω–æ–∂–∞.\n",
    "–ó–∞–≤—Ç—Ä–∞ –∑–∞–±—É–¥–µ—à—å,\n",
    "—á—Ç–æ —Ç–µ–±—è –∫–æ—Ä–æ–Ω–æ–≤–∞–ª,\n",
    "—á—Ç–æ –¥—É—à—É —Ü–≤–µ—Ç—É—â—É—é –ª—é–±–æ–≤—å—é –≤—ã–∂–µ–≥,\n",
    "–∏ —Å—ÉÃÅ–µ—Ç–Ω—ã—Ö –¥–Ω–µ–π –≤–∑–º–µ—Ç–µ–Ω–Ω—ã–π –∫–∞—Ä–Ω–∞–≤–∞–ª\n",
    "—Ä–∞—Å—Ç—Ä–µ–ø–ª–µ—Ç —Å—Ç—Ä–∞–Ω–∏—Ü—ã –º–æ–∏—Ö –∫–Ω–∏–∂–µ–∫‚Ä¶\n",
    "–°–ª–æ–≤ –º–æ–∏—Ö —Å—É—Ö–∏–µ –ª–∏—Å—Ç—å—è –ª–∏\n",
    "–∑–∞—Å—Ç–∞–≤—è—Ç –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è,\n",
    "–∂–∞–¥–Ω–æ –¥—ã—à–∞?\n",
    "–î–∞–π —Ö–æ—Ç—å\n",
    "–ø–æ—Å–ª–µ–¥–Ω–µ–π –Ω–µ–∂–Ω–æ—Å—Ç—å—é –≤—ã—Å—Ç–µ–ª–∏—Ç—å\n",
    "—Ç–≤–æ–π —É—Ö–æ–¥—è—â–∏–π —à–∞–≥..\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –±–∏–±–ª–∏–æ—Ç–µ–∫–µ Transformers –µ—Å—Ç—å –≥–æ—Ç–æ–≤—ã–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞—Ç–∞—Å–µ—Ç–∞ –∏ –∑–∞–≥—Ä—É–∑—á–∏–∫–∞ –¥–∞–Ω–Ω—ã—Ö. –ù–∞ –≤—Ö–æ–¥ –Ω—É–∂–µ–Ω –≤—Å–µ–≥–æ –ª–∏—à—å –æ–¥–∏–Ω `.txt` —Ñ–∞–π–ª —Å –æ–±—É—á–∞—é—â–∏–º —Ç–µ–∫—Å—Ç–æ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save text train data as .txt file\n",
    "train_path = \"train_dataset.txt\"\n",
    "with open(train_path, mode=\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], padding=\"max_length\", truncation=False, max_length=64\n",
    "    )\n",
    "\n",
    "\n",
    "dataset = load_dataset(\"text\", data_files={\"train\": train_path})\n",
    "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# –°rop the text into optimal length pieces\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ –∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º –æ–±—ä–µ–∫—Ç –∫–ª–∞—Å—Å–∞ `Trainer`, –∫–æ—Ç–æ—Ä—ã–π —Å–¥–µ–ª–∞–µ—Ç –≤—Å—é —Ä–∞–±–æ—Ç—É –∑–∞ –Ω–∞—Å. –î–∞–ª–µ–µ –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –≤—Å–µ–≥–æ –ª–∏—à—å –∑–∞–ø—É—Å—Ç–∏—Ç—å `trainer.train()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./finetuned\",  # The output directory\n",
    "    overwrite_output_dir=True,  # overwrite the content of the output directory\n",
    "    num_train_epochs=200,  # number of training epochs\n",
    "    per_device_train_batch_size=32,  # batch size for training\n",
    "    per_device_eval_batch_size=32,  # batch size for evaluation\n",
    "    warmup_steps=10,  # number of warmup steps for learning rate scheduler\n",
    "    gradient_accumulation_steps=16,  # to make \"virtual\" batch size larger\n",
    "    report_to=\"none\",\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    optimizers=(\n",
    "        torch.optim.AdamW(model.parameters(), lr=1e-5),\n",
    "        None,\n",
    "    ),  # Optimizer and learnig rate scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ì–æ—Ç–æ–≤–æ! –¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –ø–æ—Å–º–æ—Ç—Ä–∏–º, —á—Ç–æ –∂–µ —Å–æ—á–∏–Ω–∏—Ç GPT –≤ —Å—Ç–∏–ª–µ –ú–∞—è–∫–æ–≤—Å–∫–æ–≥–æ, –µ—Å–ª–∏ –Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞—Ç—å —Ç–∞–∫—É—é —Å—Ç—Ä–æ—á–∫—É:\n",
    "\n",
    "\"–ö–∞–∫ –∂–µ —Å–ª–æ–∂–Ω–æ —É—á–∏—Ç—å –º–∞—Ç–∞–Ω–∞–ª–∏–∑!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random state\n",
    "torch.random.manual_seed(42)\n",
    "\n",
    "# Probability sampling with limit example\n",
    "text = \"–ö–∞–∫ –∂–µ —Å–ª–æ–∂–Ω–æ —É—á–∏—Ç—å –º–∞—Ç–∞–Ω–∞–ª–∏–∑!\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model.generate(\n",
    "        input_ids,\n",
    "        do_sample=True,\n",
    "        num_beams=3,\n",
    "        temperature=1.9,\n",
    "        top_p=0.9,\n",
    "        max_length=200,\n",
    "        pad_token_id=512,\n",
    "    )\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ó–∞—Ç—Ä–∞–≤–æ—á–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –æ—Ç–ª–∏—á–∏–µ –æ—Ç BERT-like –º–æ–¥–µ–ª–µ–π, –¥–ª—è GPT —ç—Ç–∞–ø –¥–æ–æ–±—É—á–µ–Ω–∏—è –Ω–µ –æ–±—è–∑–∞—Ç–µ–ª–µ–Ω. –î–ª—è —Ç–æ–≥–æ —á—Ç–æ–±—ã –¥–æ–ø–∏—Å—ã–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, –º–æ–¥–µ–ª—å –¥–æ–ª–∂–Ω–∞ –æ—á–µ–Ω—å —Ö–æ—Ä–æ—à–æ –ø–æ–Ω–∏–º–∞—Ç—å –µ–≥–æ —Å–º—ã—Å–ª –∏ –∏–º–µ—Ç—å –∑–Ω–∞–Ω–∏—è –æ —Ä–µ–∞–ª—å–Ω–æ–º –º–∏—Ä–µ. –í–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∑–Ω–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –ø–æ–ø—ã—Ç–∞—Ç—å—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å, –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä—É—è –ª–µ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Ç–µ–∫—Å—Ç–∞. –ü–æ—Å–∫–æ–ª—å–∫—É GPT —Å–ø–æ—Å–æ–±–Ω–∞ –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —Ç–µ–∫—Å—Ç, –º—ã –º–æ–∂–µ–º —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –ª—é–±—É—é NLP-–∑–∞–¥–∞—á—É –∫–∞–∫ –∑–∞–¥–∞—á—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (–ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è) —Ç–µ–∫—Å—Ç–∞. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç —Ä–µ—à–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º –∏–ª–∏ –±–µ–∑ –Ω–µ–≥–æ.\n",
    "\n",
    "–ü–æ–¥–±–æ—Ä –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–π —Ç–µ–∫—Å—Ç–∞ –Ω–∞–∑—ã–≤–∞–µ—Ç—Å—è \"–∑–∞—Ç—Ä–∞–≤–æ—á–Ω–æ–µ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ\" (prompt engineering). –°—É—Ç—å –∑–∞—Ç—Ä–∞–≤–æ—á–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Ç–æ–º, —á—Ç–æ–±—ã –ø–æ–¥–æ–±—Ä–∞—Ç—å —Ç–∞–∫–∏–µ –∑–∞–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –∏ –Ω–∞—á–∞–ª–∞ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, —á—Ç–æ–±—ã –¥–∞–ª—å—à–µ –º–æ–¥–µ–ª—å –≤—ã–¥–∞–≤–∞–ª–∞ —Ä–æ–≤–Ω–æ —Ç–æ, —á—Ç–æ –Ω–∞–¥–æ. –ü–æ–¥–±–∏—Ä–∞—è \"–∑–∞—Ç—Ä–∞–≤–∫–∏\" –∏ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≥–µ–Ω–µ—Ä–∞—Ç–æ—Ä–∞ (—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞, `top-k`, `top-p`), –º–æ–∂–Ω–æ –¥–æ–±–∏—Ç—å—Å—è —Ö–æ—Ä–æ—à–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤ —Ç–æ–ª—å–∫–æ –∑–∞ —Å—á–µ—Ç –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "–°—É—â–µ—Å—Ç–≤—É–µ—Ç –¥–≤–∞ –ø–æ–¥—Ö–æ–¥–∞ –¥–ª—è –∑–∞—Ç—Ä–∞–≤–æ—á–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è:\n",
    "- zero-shot: —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á—É –∏ –ø–µ—Ä–µ–¥–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é;\n",
    "- few-shot: —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á—É, –ø–æ–¥–∞—Ç—å –≤ –º–æ–¥–µ–ª—å –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏ –∑–∞—Ç–µ–º –ø–µ—Ä–µ–¥–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏—é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"ai-forever/rugpt3large_based_on_gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name).to(device)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero-shot learning\n",
    "text = \"–° –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π 'cat' –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—Å—è –∫–∞–∫ '\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "out = model.generate(input_ids, do_sample=False, max_length=15)\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# few-shot learning\n",
    "text = \"–° –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –Ω–∞ —Ä—É—Å—Å–∫–∏–π 'cat' –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—Å—è –∫–∞–∫ '–∫–æ—à–∫–∞', 'dog' –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—Å—è –∫–∞–∫ '—Å–æ–±–∞–∫–∞', –∞ 'bird' –ø–µ—Ä–µ–≤–æ–¥–∏—Ç—Å—è –∫–∞–∫ '\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "out = model.generate(input_ids, do_sample=False, max_length=35)\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–°–¥–µ–ª–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—É—é —Å–∏—Å—Ç–µ–º—É –±–µ–∑ –æ–±—É—á–µ–Ω–∏—è: –±—É–¥–µ–º –ø–æ–¥–∞–≤–∞—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –≤ –≤–∏–¥–µ —Ç–µ–∫—Å—Ç–∞ –∏ —Å–º–æ—Ç—Ä–µ—Ç—å, –∫–∞–∫ –º–æ–¥–µ–ª—å –ø—Ä–æ–¥–æ–ª–∂–∏—Ç –µ–≥–æ. –î–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –±—É–¥–µ–º –ø–æ–¥–∞–≤–∞—Ç—å —Ç–µ–∫—Å—Ç —Å –Ω–µ–∑–∞–∫—Ä—ã—Ç–æ–π –∫–∞–≤—ã—á–∫–æ–π, —á—Ç–æ–±—ã –≤—ã–Ω—É–¥–∏—Ç—å –º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–º–µ–Ω–∞ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42)\n",
    "\n",
    "# Film recomendation\n",
    "text = \"–Ø –ª—é–±–ª—é —Å–æ–≤–µ—Ç—Å–∫–∏–µ –∫–æ–º–µ–¥–∏–∏: ‚Äú–ü—Ä–∏–∫–ª—é—á–µ–Ω–∏—è –®—É—Ä–∏–∫–∞‚Äù, ‚Äú\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "out = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=1.2,\n",
    "    top_k=15,\n",
    "    top_p=0.95,\n",
    "    max_length=35,\n",
    ")\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.random.manual_seed(42)\n",
    "\n",
    "# Music recomendation\n",
    "text = \"–¢–µ–º –ª—é–¥—è–º, –∫–æ–º—É –Ω—Ä–∞–≤–∏—Ç—Å—è ‚Äú–ê–ª–∏—Å–∞‚Äù, —Ç–∞–∫–∂–µ –ø–æ–Ω—Ä–∞–≤—è—Ç—Å—è –≥—Ä—É–ø–ø—ã ‚Äú\"\n",
    "input_ids = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
    "out = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_k=10,\n",
    "    top_p=0.95,\n",
    "    max_length=38,\n",
    ")\n",
    "\n",
    "generated_text = list(map(tokenizer.decode, out))[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ê–Ω–∞–ª–∏–∑ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –±–∏–Ω–∞—Ä–Ω—É—é –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –±–µ–∑ –¥–æ–æ–±—É—á–µ–Ω–∏—è.\n",
    "\n",
    "–î–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–µ—Ä—É –ø–µ—Ä–ø–ª–µ–∫—Å–∏–∏. –í —Ç–µ–æ—Ä–∏–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –ø–µ—Ä–ø–ª–µ–∫—Å–∏—è ‚Äî –º–µ—Ä–∞ —Ç–æ–≥–æ, –Ω–∞—Å–∫–æ–ª—å–∫–æ —Ö–æ—Ä–æ—à–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞–µ—Ç –≤—ã–±–æ—Ä–∫—É. –ì–æ–≤–æ—Ä—è –ø—Ä–æ—Å—Ç—ã–º —è–∑—ã–∫–æ–º, –ø–µ—Ä–ø–ª–µ–∫—Å–∏—è ‚Äî –º–µ—Ä–∞ \"—É–¥–∏–≤–ª—ë–Ω–Ω–æ—Å—Ç–∏\" –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "–ù–∞ –≤—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –º—ã –ø–æ–¥–∞—ë–º –∑–∞—Ç—Ä–∞–≤–∫—É –≤ —Ñ–æ—Ä–º–∞—Ç–µ `<–º–µ—Ç–∫–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏> + <–æ—Ç–∑—ã–≤>`. –î–∞–ª–µ–µ –º—ã —Å—á–∏—Ç–∞–µ–º –ø–µ—Ä–ø–ª–µ–∫—Å–∏—é –∫–∞–∂–¥–æ–≥–æ –∏–∑ –Ω–∏—Ö. –í—ã–±–∏—Ä–∞–µ–º –Ω–∞–∏–º–µ–Ω—å—à—É—é –ø–µ—Ä–ø–ª–µ–∫—Å–∏—é –∏–∑ –¥–≤—É—Ö –∏ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–µ–º –º–µ—Ç–∫—É –æ—Ç–∑—ã–≤—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def calculate_perplexity(sentence, model, tokenizer):\n",
    "    # Add tone lable to sentence\n",
    "    sentence_positive = \"–¥–æ–≤–æ–ª–µ–Ω:\" + sentence\n",
    "    sentence_negative = \"–Ω–µ–¥–æ–≤–æ–ª–µ–Ω:\" + sentence\n",
    "    list_sent = [sentence_positive, sentence_negative]\n",
    "    ppl_values = []\n",
    "\n",
    "    for sentence in list_sent:\n",
    "        # Tokenize sentence\n",
    "        encodings = tokenizer(sentence, return_tensors=\"pt\")\n",
    "        input_ids = encodings.input_ids.to(device)\n",
    "        # Apply model\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_ids=input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "        # Count perplexity\n",
    "        ppl = math.exp(loss.item() * input_ids.size(1))\n",
    "        ppl_values.append(ppl)\n",
    "\n",
    "    # Choose sentence with lower perplexity\n",
    "    if ppl_values[0] > ppl_values[1]:\n",
    "        return \"–æ—Ç—Ä–∏—Ü–∞—Ç–µ–ª—å–Ω—ã–π\"\n",
    "    else:\n",
    "        return \"–ø–æ–ª–æ–∂–∏—Ç–µ–ª—å–Ω—ã–π\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative = \"—è —á—É—Ç—å –Ω–µ –∑–∞—Å–Ω—É–ª –≤–æ –≤—Ä–µ–º—è —Ñ–∏–ª—å–º–∞\"\n",
    "print(f'–û—Ç–∑—ã–≤ \"{negative}\": {calculate_perplexity(negative, model, tokenizer)}')\n",
    "positive = \"—Å—é–∂–µ—Ç –Ω–µ–≤–µ—Ä–æ—è—Ç–Ω–æ –∑–∞—Ö–≤–∞—Ç—ã–≤–∞—é—â–∏–π\"\n",
    "print(f'–û—Ç–∑—ã–≤ \"{positive}\": {calculate_perplexity(positive, model, tokenizer)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –î–æ–æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è—Ö"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–∏–Ω –∏–∑ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö –±—ã—Å—Ç—Ä–æ —Ä–∞–∑–≤–∏–≤–∞—é—â–∏—Ö—Å—è —Ç—Ä–µ–Ω–¥–æ–≤ –≤ NLP ‚Äî —Ä–µ—à–∞—Ç—å –º–Ω–æ–∂–µ—Å—Ç–≤–æ –∑–∞–¥–∞—á –æ–¥–Ω–æ–π –æ–±—â–µ–π –º–æ–¥–µ–ª—å—é.\n",
    "\n",
    "- –ü—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –±–æ–ª—å—à–æ–º –æ–±—ä–µ–º–µ –Ω–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∑–∞–∫–ª–∞–¥—ã–≤–∞–µ—Ç —à–∏—Ä–æ–∫–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —è–∑—ã–∫–∞\n",
    "- –î–æ–æ–±—É—á–µ–Ω–∏–µ –ø–æ–¥ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é –∑–∞–¥–∞—á—É —Ç—Ä–µ–±—É–µ—Ç –Ω–∞–ª–∏—á–∏—è —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –∫–æ—Ä–ø—É—Å–æ–≤ –≥–æ—Ä–∞–∑–¥–æ –º–µ–Ω—å—à–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞\n",
    "- –ü—Ä–∏ –ø—Ä–∞–≤–∏–ª—å–Ω—ã—Ö –∑–∞—Ç—Ä–∞–≤–∫–∞—Ö (–∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è—Ö) –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç —Ä–µ—à–∞—Ç—å –∑–∞–¥–∞—á–∏, –∫–æ—Ç–æ—Ä—ã–µ –æ–Ω–∏ –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –≤–∏–¥–µ–ª–∏\n",
    "- –í—Å–µ –≤–æ–∑–º–æ–∂–Ω—ã–µ NLP –∑–∞–¥–∞—á–∏ –º–æ–∂–Ω–æ —Å–≤–µ—Å—Ç–∏ –∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –ø–µ—Ä–µ–≤–æ–¥–∞ –¥–ª—è –º–∞—à–∏–Ω–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–∞ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –æ–ø–µ—á–∞—Ç–æ–∫, –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–º–µ–Ω–æ–≤–∞–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –∏–º–µ–Ω–æ–≤–∞–Ω–Ω—ã—Ö —Å—É—â–Ω–æ—Å—Ç–µ–π. –ì–ª–∞–≤–Ω–æ–µ ‚Äî –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞—Ç—Ä–∞–≤–∫—É –∏–ª–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ú–æ–¥–µ–ª—å T5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[paper] üéì Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer (2019)](https://arxiv.org/abs/1910.10683)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å T5 (Text-to-Text Transfer Transformer) –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –∫ Transfer learning –≤ NLP. –ï—ë –∫–ª—é—á–µ–≤–∞—è –∏–¥–µ—è ‚Äî —Å–≤–µ–¥–µ–Ω–∏–µ –≤—Å–µ—Ö –∑–∞–¥–∞—á –∫ —Ñ–æ—Ä–º–∞—Ç—É \"—Ç–µ–∫—Å—Ç-–≤-—Ç–µ–∫—Å—Ç\", –≥–¥–µ –∏ –≤—Ö–æ–¥, –∏ –≤—ã—Ö–æ–¥ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è—é—Ç —Å–æ–±–æ–π —Å—Ç—Ä–æ–∫–∏ —Ç–µ–∫—Å—Ç–∞. –≠—Ç–æ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø—Ä–∏–º–µ–Ω—è—Ç—å –æ–¥–Ω—É –∏ —Ç—É –∂–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ –ø–æ–¥—Ö–æ–¥ –∫ —Ä–∞–∑–Ω–æ—Ä–æ–¥–Ω—ã–º –∑–∞–¥–∞—á–∞–º, —Ç–∞–∫–∏–º –∫–∞–∫ –ø–µ—Ä–µ–≤–æ–¥, –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è, —Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ –∏ –æ—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/T5.gif\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://habr.com/ru/articles/543412/\">–¢—Ä–∞–Ω—Å—Ñ–µ—Ä–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —Å –¢5</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ –º–æ–º–µ–Ω—Ç —Å–æ–∑–¥–∞–Ω–∏—è –º–æ–¥–µ–ª–∏ T5 –ø–∞—Ä–∞–¥–∏–≥–º–∞ \"–æ–¥–Ω–∞ –º–æ–¥–µ–ª—å ‚Äî –æ–¥–Ω–∞ –∑–∞–¥–∞—á–∞\" –µ—â–µ –Ω–µ –∏–∑–º–µ–Ω–∏–ª–∞—Å—å. –í —Å–≤–æ–∏—Ö —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞—Ö –∞–≤—Ç–æ—Ä—ã —Å—Ç–∞—Ç—å–∏ –ø—ã—Ç–∞–ª–∏—Å—å –æ–±—É—á–∏—Ç—å –æ–¥–Ω—É –º–æ–¥–µ–ª—å —Ä–µ—à–∞—Ç—å —Å—Ä–∞–∑—É –Ω–µ—Å–∫–æ–ª—å–∫–æ –∑–∞–¥–∞—á. –û–¥–Ω–∞–∫–æ —É –Ω–∏—Ö –Ω–µ –±—ã–ª–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –∑–∞–¥–∞—á, –∏–∑-–∑–∞ —á–µ–≥–æ –æ–±–æ–±–æ—â–µ–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –ø–æ–∫–∞–∑–∞–ª–∞ —Ö—É–¥—à–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á–∞—Ö, —á–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "–û–¥–Ω–∞–∫–æ T5 —Å—Ç–∞–ª–∞ –≤–∞–∂–Ω—ã–º —à–∞–≥–æ–º –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏–∏ –ø–æ–¥—Ö–æ–¥–∞ –∫ NLP-–∑–∞–¥–∞—á–∞–º –∏ –ø–æ–∫–∞–∑–∞–ª–∞ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª —É–Ω–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö text-to-text –º–æ–¥–µ–ª–µ–π.\n",
    "\n",
    "–ó–∞–¥–∞—á–∞ –≤ –º–æ–¥–µ–ª—å –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è —á–µ—Ä–µ–∑ –ø—Ä–µ—Ñ–∏–∫—Å (–æ–±—Ä–∞—Ç–∏—Ç–µ –≤–Ω–∏–º–∞–Ω–∏–µ –Ω–∞ –Ω–∞—á–∞–ª–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –Ω–∏–∂–µ). –ú–æ–¥–µ–ª–∏ –≤ —Ä–∞–∑–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è—Ö (small, base, large) –µ—Å—Ç—å –Ω–∞ HuggingFace. –î–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º –≤–∑—è—Ç—å –æ–¥–Ω—É –∏–∑ –Ω–∏—Ö –∏ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å —Å—Ö–æ–¥—É —Ä–µ—à–∏—Ç—å –∑–∞–¥–∞—á—É —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from IPython.display import clear_output\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = 't5-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ–∑—å–º–µ–º –∫–∞–∫–æ–π-–Ω–∏–±—É–¥—å —Ç–µ–∫—Å—Ç –∏ –ø–æ–ø—Ä–æ–±—É–µ–º —Å–¥–µ–ª–∞—Ç—å —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_prefix = \"summarize: {}\"\n",
    "\n",
    "text = \"\"\"\n",
    "Badgers burrowing under rail tracks have halted trains in the northern and southern Netherlands, forcing lengthy cancellations on at least two lines.\n",
    "All trains were halted Tuesday afternoon on a busy line between the southern cities of Den Bosch and Boxtel after the animals dug into a dike carrying rails. The national railway company said the line would be out of service for at least a week.\n",
    "The digging means \"the rails can subside and then the safety of train traffic can no longer be guaranteed,\" ProRail, the company that maintains the Dutch rail network said in a statement.\n",
    "Earlier this month, badgers also burrowed under tracks near the northern village of Molkwerum in Friesland province, knocking a line out of service until next month while workers seek permission to shift the animals.\n",
    "Badgers are protected animals in the Netherlands, so rail operators have to get permission to move them or disturb their habitat before repairs can begin.\n",
    "\"\"\"\n",
    "\n",
    "inputs = tokenizer([task_prefix.format(text)], return_tensors=\"pt\", padding=True)\n",
    "\n",
    "output_sequences = model.generate(\n",
    "    num_beams=5,\n",
    "    max_length=100,\n",
    "    no_repeat_ngram_size=3,\n",
    "    early_stopping=True,\n",
    "    num_return_sequences=1,\n",
    "    input_ids=inputs[\"input_ids\"],\n",
    "    attention_mask=inputs[\"attention_mask\"],\n",
    "    do_sample=False,  # disable sampling to test if batching affects output\n",
    ")\n",
    "\n",
    "summaries = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
    "print(summaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–±–æ—Ç–∞–µ—Ç –Ω–µ–ø–ª–æ—Ö–æ, –Ω–æ, –∫–æ–Ω–µ—á–Ω–æ, –¥–ª—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –Ω—É–∂–Ω–æ —Ç—é–Ω–∏—Ç—å –º–æ–¥–µ–ª—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ú–æ–¥–µ–ª—å FLAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[paper] üéì Finetuned Language Models Are Zero-Shot Learners (2021)](https://arxiv.org/abs/2109.01652)\n",
    "\n",
    "–í —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ —É–∂–µ –∑–∞–º–µ—Ç–µ–Ω —Å–¥–≤–∏–≥ –≤ —Å—Ç–æ—Ä–æ–Ω—É –æ–±—â–∏—Ö –º–æ–¥–µ–ª–µ–π: —É–∂–µ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–ª—Å—è –ø–æ–¥—Ö–æ–¥ –∫ –æ–±—É—á–µ–Ω–∏—é —á–µ—Ä–µ–∑ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/instruction_tuning.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/2109.01652\">Finetuned Language Models Are Zero-Shot Learners</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–¥–µ—è: —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –º–Ω–æ–≥–æ –∑–∞–¥–∞—á –∫–∞–∫ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏ –¥–æ–æ–±—É—á–∏—Ç—å –Ω–∞ –≤—Å–µ—Ö –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ. 62 –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–µ—à–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã—Ö NLP –∑–∞–¥–∞—á –±—ã–ª–∏ –ø–µ—Ä–µ–¥–µ–ª–∞–Ω—ã –≤ –æ–¥–∏–Ω –±–æ–ª—å—à–æ–π –¥–∞—Ç–∞—Å–µ—Ç —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã—Ö –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π, —á—Ç–æ–±—ã –æ–±—É—á–∏—Ç—å –º–æ–¥–µ–ª—å —Ä–µ—à–∞—Ç—å —Å—Ä–∞–∑—É –≤—Å—ë."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/datasets.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/2109.01652\">Finetuned Language Models Are Zero-Shot Learners</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏–º–µ—Ä—ã –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π:\n",
    "- `Please translate this sentence to French: 'The dog\n",
    "runs.'`\n",
    "- `What is the sentiment of this text? Options: Negative, Positive, Neutral.`\n",
    "\n",
    "–ë—ã–ª–æ –∑–∞–º–µ—á–µ–Ω–æ, —á—Ç–æ –º–æ–¥–µ–ª—å –æ–±–ª–∞–¥–∞–µ—Ç –æ–±–æ–±—â–∞—é—â–µ–π —Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç—å—é –∏ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä—ã–µ –æ–Ω–∞ –Ω–∏–∫–æ–≥–¥–∞ –Ω–µ –≤–∏–¥–µ–ª–∞. –¢–∞–∫ –∫–∞–∫ –º–æ–¥–µ–ª—å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∞ –Ω–∞ –±–æ–ª—å—à–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ —Ç–µ–∫—Å—Ç–æ–≤, –æ–Ω–∞ —É–∂–µ —Ö–æ—Ä–æ—à–æ –ø–æ–Ω–∏–º–∞–µ—Ç —è–∑—ã–∫ –∏ —ç–∫—Å—Ç—Ä–∞–ø–æ–ª–∏—Ä—É–µ—Ç –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –∏–∑ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏, –∏—Å–ø–æ–ª—å–∑—É—è —Å–≤–æ–µ –ø–æ–Ω–∏–º–∞–Ω–∏–µ —è–∑—ã–∫–∞.\n",
    "\n",
    "–û–ø–∏—Å–∞–Ω–Ω—ã–π –ø–æ–¥—Ö–æ–¥ –±—ã–ª –æ–ø—Ä–æ–±–æ–≤–∞–Ω —Å —Ä–∞–∑–Ω—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ (T5, PALM), –∏ –≤–µ–∑–¥–µ –ø–æ–ª—É—á–∞–ª–æ—Å—å —Ö–æ—Ä–æ—à–æ —Ä–µ—à–∞—Ç—å –Ω–æ–≤—ã–µ –∑–∞–¥–∞—á–∏.\n",
    "\n",
    "FLAN –≤–∞—Ä–∏–∞–Ω—Ç—ã –º–æ–¥–µ–ª–µ–π —Ç–∞–∫–∂–µ –¥–æ—Å—Ç—É–ø–Ω—ã –Ω–∞ HuggingFace. –î–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º —Å —Ç–∞–∫–∏–º –∂–µ —Ç–µ–∫—Å—Ç–æ–º."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"google/flan-t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=512)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –≤ —Å–≤–æ–±–æ–¥–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ, –ø–æ—ç—Ç–æ–º—É —Å–¥–µ–ª–∞–µ–º —Ñ—É–Ω–∫—Ü–∏—é, —á—Ç–æ–±—ã —É–¥–æ–±–Ω–µ–µ –±—ã–ª–æ –ø—Ä–æ–±–æ–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_for_instruction(instruction, text, model):\n",
    "\n",
    "    inputs = tokenizer([instruction.format(text)], return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    output_sequences = model.generate(\n",
    "        num_beams=5,\n",
    "        max_length=100,\n",
    "        no_repeat_ngram_size=3,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences=1,\n",
    "        input_ids=inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        do_sample=False,  # disable sampling to test if batching affects output\n",
    "    )\n",
    "    summaries = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
    "    return summaries[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Badgers burrowing under rail tracks have halted trains in the northern and southern Netherlands, forcing lengthy cancellations on at least two lines.\n",
    "All trains were halted Tuesday afternoon on a busy line between the southern cities of Den Bosch and Boxtel after the animals dug into a dike carrying rails. The national railway company said the line would be out of service for at least a week.\n",
    "The digging means \"the rails can subside and then the safety of train traffic can no longer be guaranteed,\" ProRail, the company that maintains the Dutch rail network said in a statement.\n",
    "Earlier this month, badgers also burrowed under tracks near the northern village of Molkwerum in Friesland province, knocking a line out of service until next month while workers seek permission to shift the animals.\n",
    "Badgers are protected animals in the Netherlands, so rail operators have to get permission to move them or disturb their habitat before repairs can begin.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Give a summary of this text: {}\"\n",
    "predict_for_instruction(instruction, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Give a very short summary of this text: {}\"\n",
    "predict_for_instruction(instruction, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Write a title for the following text:{}\"\n",
    "predict_for_instruction(instruction, text, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction = \"Suggest keywords for this text. Text: {}\"\n",
    "predict_for_instruction(instruction, text, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º —Å –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑—å—é –æ—Ç —á–µ–ª–æ–≤–µ–∫–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[paper] üéì Training language models to follow instructions with human feedback (2022)](https://arxiv.org/abs/2203.02155)\n",
    "\n",
    "Reinforcement Learning from Human Feedback (RLHF) ‚Äî –ø–æ–¥—Ö–æ–¥, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª–∏–ª –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É–ª—É—á—à–∏—Ç—å –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è—Ö. –û–Ω –±—ã–ª –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ InstructGPT.\n",
    "\n",
    "–ú–æ–¥–µ–ª—å InstructGPT ‚Äî \"–º–ª–∞–¥—à–∏–π –±—Ä–∞—Ç\" ChatGPT. –û–Ω–∞ –Ω–µ –ø—Ä–∏–≤–ª–µ–∫–ª–∞ —Å—Ç–æ–ª—å–∫–æ –≤–Ω–∏–º–∞–Ω–∏—è –æ–±—â–µ—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏, –Ω–æ –±–æ–ª–µ–µ –ø–æ–ª–µ–∑–Ω–∞ –Ω–∞–º –∫–∞–∫ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è–º, –ø–æ—Å–∫–æ–ª—å–∫—É –ø—Ä–æ—Ü–µ—Å—Å –µ–µ –æ–±—É—á–µ–Ω–∏—è –æ–ø–∏—Å–∞–Ω –≤ —Å—Ç–∞—Ç—å–µ. –û–¥–Ω–∞–∫–æ —Å–∞–º–∞ –∏–¥–µ—è –æ–±—É—á–µ–Ω–∏—è –ø—Ä–∏–º–µ–Ω–∏–º–∞ –∏ –∫ ChatGPT.\n",
    "\n",
    "–ò—Ç–∞–∫, –∫–∞–∫ –ø—Ä–µ–≤—Ä–∞—Ç–∏—Ç—å (—É–∂–µ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —É–º–Ω—É—é) GPT-3 –≤ (–µ—â–µ –±–æ–ª–µ–µ —É–º–Ω—É—é) InstructGPT?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –®–∞–≥ 1: —Å–æ–±—Ä–∞—Ç—å –Ω–∞–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π –∏ –¥–æ–æ–±—É—á–∏—Ç—å –Ω–∞ –Ω–µ–º GPT-3.\n",
    "\n",
    "–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –¥–æ–ª–∂–Ω—ã –≤–∫–ª—é—á–∞—Ç—å –Ω–µ —Ç–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ NLP-–∑–∞–¥–∞—á–∏, –Ω–æ –∏ –±–æ–ª–µ–µ \"—Ç–≤–æ—Ä—á–µ—Å–∫–∏–µ\": –ø—Ä–∏–¥—É–º–∞—Ç—å –∏—Å—Ç–æ—Ä–∏—é, –Ω–∞–ø–∏—Å–∞—Ç—å —Å–ø–∏—Å–æ–∫ —á–µ–≥–æ-–Ω–∏–±—É–¥—å, –ø–æ—Å–æ–≤–µ—Ç–æ–≤–∞—Ç—å —á—Ç–æ-—Ç–æ. –ö–∞—á–µ—Å—Ç–≤–æ –≤–∞–∂–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞: –±–æ–ª—å—à–∞—è –¥–æ–ª—è —Ä—É—á–Ω–æ–≥–æ —Ç—Ä—É–¥–∞, –≤—ã—Å–æ–∫–æ–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –∫ –∫–∞—á–µ—Å—Ç–≤—É –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–π.\n",
    "\n",
    "–ü–æ—Å–ª–µ –¥–æ–æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ GPT-3 –ø–æ–ª—É—á–∏–º SFT-–º–æ–¥–µ–ª—å (supervised fine-tuned)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –®–∞–≥ 2: –æ—Ü–µ–Ω–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –º–æ–¥–µ–ª–∏ SFT –∏ –æ–±—É—á–∏—Ç—å reward-–º–æ–¥–µ–ª—å.\n",
    "\n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç—ã SFT-–º–æ–¥–µ–ª–∏ –æ—Ü–µ–Ω–∏–≤–∞—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é —Ä–∞–∑–º–µ—Ç—á–∏–∫–æ–≤. –ë–µ—Ä–µ—Ç—Å—è —Ç–µ—Å—Ç–æ–≤—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö, —Å –ø–æ–º–æ—â—å—é SFT-–º–æ–¥–µ–ª–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –æ—Ç–≤–µ—Ç–∞. –î–∞–ª–µ–µ —Ä–∞–∑–º–µ—Ç—á–∏–∫–∏ —Ä–∞–Ω–∂–∏—Ä—É—é—Ç –æ—Ç–≤–µ—Ç—ã –º–æ–¥–µ–ª–∏ –ø–æ –∫–∞—á–µ—Å—Ç–≤—É: –ø–æ–ø–∞—Ä–Ω–æ —Å—Ä–∞–≤–Ω–∏–≤–∞—é—Ç —ç—Ç–∏ –æ—Ç–≤–µ—Ç—ã –∏ –≥–æ–≤–æ—Ä—è—Ç, –∫–∞–∫–æ–π –∏–∑ –Ω–∏—Ö –ª—É—á—à–µ.\n",
    "\n",
    "–û—Ç–≤–µ—Ç—ã —Ä–∞–∑–º–µ—Ç—á–∏–∫–æ–≤ –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è reward-–º–æ–¥–µ–ª–∏. –û–Ω–∞ –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–ø–æ—Å–æ–±–Ω–∞ –∏–º–∏—Ç–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç —Ä–∞–∑–º–µ—Ç—á–∏–∫–∞ –∏ —Ä–∞–Ω–∂–∏—Ä–æ–≤–∞—Ç—å –æ—Ç–≤–µ—Ç—ã SFT-–º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- –®–∞–≥ 3: –¥–æ–æ–±—É—á–∏—Ç—å SFT-–º–æ–¥–µ–ª—å —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º reward-–º–æ–¥–µ–ª–∏\n",
    "\n",
    "SFT-–º–æ–¥–µ–ª—å –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç–≤–µ—Ç—ã-–∫–∞–Ω–¥–∏–¥–∞—Ç—ã. –û–Ω–∏ –æ—Ü–µ–Ω–∏–≤–∞—é—Ç—Å—è —Å –ø–æ–º–æ—â—å—é reward-–º–æ–¥–µ–ª–∏, –æ–±—É—á–µ–Ω–Ω–æ–π –Ω–∞ –æ–±—Ä–∞—Ç–Ω–æ–π —Å–≤—è–∑–∏ –æ—Ç –ª—é–¥–µ–π. –û—Ü–µ–Ω–∫–∞ reward-–º–æ–¥–µ–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –≤–µ—Å–æ–≤ SFT-–º–æ–¥–µ–ª–∏. –û–Ω–∞ –¥–æ–æ–±—É—á–∞–µ—Ç—Å—è —Ç–∞–∫, —á—Ç–æ–±—ã –≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –ø–æ–ª—É—á–∞–ª–∏ –≤—ã—Å–æ–∫–∏–µ –æ—Ü–µ–Ω–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–ª—è –æ–±—É—á–µ–Ω–∏—è —Å –ø–æ–¥–∫—Ä–µ–ø–ª–µ–Ω–∏–µ–º –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–µ—Ç–æ–¥ Proximal Policy Optimization (PPO). –ú–æ–¥–µ–ª—å –Ω–µ –ø—Ä–æ—Å—Ç–æ —É—á–∏—Ç—Å—è –º–∞–∫—Å–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –æ—Ü–µ–Ω–∫—É —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤, –Ω–æ –µ—â–µ —Å—Ç–∞—Ä–∞–µ—Ç—Å—è –º–∏–Ω–∏–º–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–º–µ–Ω–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/rlhf_steps.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/2203.02155\">Training language models to follow instructions with human feedback </a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RLHF –ø–æ–∑–≤–æ–ª—è–µ—Ç –∏—Å–ø—Ä–∞–≤–∏—Ç—å —Ç–æ, —á—Ç–æ –±—ã–ª–æ –∑–∞–ª–æ–∂–µ–Ω–æ –∫–∞–∫ –≤–æ –≤—Ä–µ–º—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏—è, —Ç–∞–∫ –∏ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –º–µ—Ç–æ–¥–æ–º SFT. –≠—Ç–æ –º–æ–≥—É—Ç –±—ã—Ç—å –æ—à–∏–±–∫–∏ –∏–ª–∏ –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/prediction_vs_reward_model.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —Å—Ç—É–∫—Ç—É—Ä—ã –º–æ–¥–µ–ª–∏ –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–æ–∫–µ–Ω–∞ –∏ –º–æ–¥–µ–ª–∏ –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è</em></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://cameronrwolfe.substack.com/p/llama-2-from-the-ground-up#footnote-anchor-9-135824233\"> CAMERON R. WOLFE, \"LLaMA-2 from the Ground Up\"</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª—å –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è –∏–º–µ–µ—Ç —Ç—É –∂–µ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ –≤–µ—Å–∞, —á—Ç–æ –∏ –æ—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å. –†–∞–∑–Ω–∏—Ü–∞ –≤ —Ç–æ–º, —á—Ç–æ —Å–ª–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Ç–æ–∫–µ–Ω–∞) –∑–∞–º–µ–Ω—ë–Ω –Ω–∞ —Å–ª–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏.\n",
    "\n",
    "–ú–æ–¥–µ–ª—å —à—Ç—Ä–∞—Ñ—É–µ—Ç –∑–∞ —Ä–∞–∑–Ω–∏—Ü—É –º–µ–∂–¥—É –ø—Ä–µ–¥–ø–æ—á—Ç–∏—Ç–µ–ª—å–Ω—ã–º —á–µ–ª–æ–≤–µ—á–µ—Å–∫–∏–º –æ—Ç–≤–µ—Ç–æ–º –∏ –∏–º–µ—é—â–∏–º—Å—è –º–∞—à–∏–Ω–Ω—ã–º. –ö—Ä–æ–º–µ —Ç–æ–≥–æ, –≤ —ç—Ç–æ –≤—ã—Ä–∞–∂–µ–Ω–∏–µ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —Å–º–µ—â–µ–Ω–∏–µ, –∫–æ—Ç–æ—Ä–æ–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏–∑—É–µ—Ç—Å—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π —á–µ–ª–æ–≤–µ–∫–æ–º –æ—Ü–µ–Ω–∫–æ–π –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç–≤–µ—Ç–∞.\n",
    "\n",
    "$$\\large L_{\\text{ranking}} = - \\log (œÉ(r_{Œ∏}(x, y_c))-œÉ(r_{Œ∏}(x, y_r))-m(r))$$\n",
    "\n",
    "–°—Ç–æ–∏—Ç —É—á–µ—Å—Ç—å, —á—Ç–æ –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ –æ–±—É—á–∞–µ—Ç—Å—è –º–Ω–æ–∂–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–µ–π –≤–æ–∑–Ω–∞–≥—Ä–∞–∂–¥–µ–Ω–∏—è, –∫–æ—Ç–æ—Ä—ã–µ –æ—Ç–≤–µ—á–∞—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º –æ—Ç–≤–µ—Ç–æ–≤ –º–æ–¥–µ–ª–∏: –æ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –¥–æ –ø–æ–ª–µ–∑–Ω–æ—Å—Ç–∏ –æ—Ç–≤–µ—Ç–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –û—Ç–∫—Ä—ã—Ç—ã–µ –º–æ–¥–µ–ª–∏-–¥–µ–∫–æ–¥–µ—Ä—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú–æ–¥–µ–ª–∏, —É –∫–æ—Ç–æ—Ä—ã—Ö –±–æ–ª–µ–µ —á–µ–º –º–∏–ª–ª–∏–∞—Ä–¥ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ–±—ã—á–Ω–æ –Ω–∞–∑—ã–≤–∞—é—Ç –±–æ–ª—å—à–∏–º–∏ —è–∑—ã–∫–æ–≤—ã–º–∏ –º–æ–¥–µ–ª—è–º–∏ (–ë–Ø–ú) –∏–ª–∏ large language models (LLM). –≠—Ç–æ—Ç —Ç–µ—Ä–º–∏–Ω –æ—Ç–Ω–æ—Å–∏—Ç—Å—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ –∫ –º–æ–¥–µ–ª—è–º –Ω–∞ –æ—Å–Ω–æ–≤–µ –¥–µ–∫–æ–¥–µ—Ä–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞. –ü—Ä–∏ —ç—Ç–æ–º –≤ –¥–∞–ª—å–Ω–µ–π—à–µ–º –æ–¥–Ω–∞ –∏ —Ç–∞ –∂–µ –º–æ–¥–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ —Ä–∞–∑–ª–∏—á–Ω–æ–º –∏–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ.\n",
    "\n",
    "–ö LLM –æ—Ç–Ω–æ—Å—è—Ç—Å—è GPT, –Ω–∞—á–∏–Ω–∞—è —Å 3-–≥–æ –ø–æ–∫–æ–ª–µ–Ω–∏—è. –°—É—â–µ—Å—Ç–≤—É—é—Ç –∏ –¥—Ä—É–≥–∏–µ –±–æ–ª—å—à–∏–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –æ—Ç–∫—Ä—ã—Ç–æ–º –¥–æ—Å—Ç—É–ø–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLaMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[paper] üéì Scaling Laws for Neural Language Models (2020)](https://arxiv.org/abs/2001.08361)\n",
    "\n",
    "–ö–æ–≥–¥–∞ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –¥–∞–Ω–Ω—ã—Ö —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è, –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞. –ò–º–µ–Ω–Ω–æ —ç—Ç–æ—Ç —Ñ–∞–∫—Ç–æ—Ä –ø–æ–∑–≤–æ–ª–∏–ª LLaMA-13B –ø—Ä–µ–≤–∑–æ–π—Ç–∏ GPT-3, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ, —á—Ç–æ –æ–Ω –±—ã–ª –≤ 10 —Ä–∞–∑ –º–µ–Ω—å—à–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/data_parameters.png\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/2001.08361\">Scaling Laws for Neural Language Models</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ —Ä–∞–∑–≤–∏—Ç–∏—è –¥–µ–∫–æ–¥–µ—Ä–æ–≤. –ö–æ–Ω—Ü–µ–ø—Ü–∏—è Large Language Model Meta AI –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ –æ–±—É—á–µ–Ω–∏–∏ –º–µ–Ω—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –±–û–ª—å—à–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –¥–∞–Ω–Ω—ã—Ö.\n",
    "\n",
    "[[paper] üéì LLaMA: Open and Efficient Foundation Language Models (2023)](https://arxiv.org/abs/2302.13971)\n",
    "\n",
    "LLaMA-13B –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç GPT-3 –ø–æ –±–æ–ª—å—à–∏–Ω—Å—Ç–≤—É —Ç–µ—Å—Ç–æ–≤, –Ω–µ—Å–º–æ—Ç—Ä—è –Ω–∞ —Ç–æ, —á—Ç–æ –æ–Ω–∞ –≤ 10 —Ä–∞–∑ –º–µ–Ω—å—à–µ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Pre-normalization**: –±—ã–ª–∏ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω—ã –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–¥—É—Ä–æ–≤–Ω—è —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞.\n",
    "\n",
    "\n",
    "–ë–∞–∑–æ–≤—ã–π –ø–æ–¥—Ö–æ–¥\n",
    "```python\n",
    "x = norm(x + attention(x))\n",
    "x = norm(x + linear(x))\n",
    "```\n",
    "\n",
    "–¢–µ–∫—É—â–∏–π –ø–æ–¥—Ö–æ–¥\n",
    "```python\n",
    "x = x + attention(norm(x))\n",
    "x = x + linear(norm(x))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞–Ω—å—à–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∏ Layer Normalization: –≤—ã—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ, –¥–µ–ª–∏–º –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ, –ø–æ—Ç–æ–º —É–º–Ω–æ–∂–∞–µ–º –Ω–∞ –æ–±—É—á–∞–µ–º—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∏ –ø—Ä–∏–±–∞–≤–ª—è–µ–º –µ—â–µ –æ–¥–Ω—É.\n",
    "\n",
    "$$y_i = \\frac{x_i - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} \\cdot \\gamma_i + \\beta_i, \\quad \\text{–≥–¥–µ }\\mu = \\frac{1}{H} \\sum_{i=1}^{H} x_i, \\quad \\sigma^2 = \\frac{1}{H} \\sum_{i=1}^{H} (x_i - \\mu)^2.$$\n",
    "\n",
    "–í–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å Root Mean Square Layer Normalization. –ò–¥–µ—è –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ –≤—ã—á–∏—Ç–∞–Ω–∏–µ —Å—Ä–µ–¥–Ω–µ–≥–æ –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ ‚Äî –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –ø—É—Ç—ë–º –¥–µ–ª–µ–Ω–∏—è –∏ –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —É–º–Ω–æ–∂–µ–Ω–∏—è –Ω–∞ –æ–±—É—á–∞–µ–º—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É. –≠—Ç–æ –ø–æ–∑–≤–æ–ª–∏–ª–æ —Å–æ–∫—Ä–∞—Ç–∏—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π –∏ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –±–µ–∑ –ø–æ—Ç–µ—Ä–∏ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–∏.\n",
    "\n",
    "$$\\bar{a}_i = \\frac{a_i}{\\text{RMS}(\\mathbf{a})} g_i, \\quad \\text{–≥–¥–µ } \\text{RMS}(\\mathbf{a}) = \\sqrt{\\frac{1}{n}\\sum_{i=1}^n a_i^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* –ë—ã–ª–∞ **–∏–∑–º–µ–Ω–µ–Ω–∞ —Ñ—É–Ω—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏**: –Ω–∞ –º–µ—Å—Ç–æ ReLU –ø—Ä–∏—à–ª–∞ SwiGLU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/activation.png\" width=\"900\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://blog.csdn.net/baidu_33000721/article/details/138616702\">Frequently asked questions in large language models</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* –î–ª—è –ø–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–≥–æ —ç–Ω–∫–æ–¥–∏–Ω–≥–∞ –±—ã–ª–∏ –ø—Ä–∏–º–µ–Ω–µ–Ω—ã **‚Äúrotary positional embeddings‚Äù**.\n",
    "\n",
    "–ü–æ–º–∏–º–æ —Å–æ—Å—Ç–∞–≤–ª—è—é—â–µ–π –ø–µ—Ä–∏–æ–¥–∞ –∏ —á–∞—Å—Ç–æ—Ç—ã –≤ positional embeddings, –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è —Å–æ—Å—Ç–∞–≤–ª—è—é—â–∞—è –ø–æ–≤–æ—Ä–æ—Ç–∞. –û–Ω–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω–∞—Å–∫–æ–ª—å–∫–æ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–∞–ª–µ–∫–∏ –¥—Ä—É–≥ –æ—Ç –¥—Ä—É–≥–∞.\n",
    "\n",
    "–ù–∞ —Å—Ç–∞–¥–∏–∏ attention –±—É–¥–µ–º –ø–æ–≤–æ—Ä–∞—á–∏–≤–∞—Ç—å –≤–µ–∫—Ç–æ—Ä–∞ $q$ –∏ $k$ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ–∑–∏—Ü–∏–∏ —Ç–æ–∫–µ–Ω–∞. –ï—Å–ª–∏ –ø–æ–∑–∏—Ü–∏—è $m$, —Ç–æ –ø–æ–≤–µ—Ä–Ω–µ–º –Ω–∞ —É–≥–æ–ª $m\\cdot \\Theta$. –ï—Å–ª–∏ —Ç–æ—á–Ω–µ–µ, –ø–æ–≤–æ—Ä–∞—á–∏–≤–∞—Ç—å –±—É–¥–µ–º –Ω–µ –≤–µ—Å—å —ç–º–±–µ–¥–¥–∏–Ω–≥ —Ü–µ–ª–∏–∫–æ–º, –∞ —Ä–∞–∑–æ–±—å–µ–º –µ–≥–æ –Ω–∞ –º–Ω–æ–≥–æ –º–∞–ª–µ–Ω—å–∫–∏—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤ –ø–æ 2 –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã, –∏ –∫–∞–∂–¥—ã–π –æ—Ç–¥–µ–ª—å–Ω–æ –ø–æ–≤–µ—Ä–Ω–µ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/embeddings.png\" width=\"1000\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/2104.09864\">RoFormer: Enhanced Transformer with Rotary Position Embedding\n",
    "</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* –ú–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏—è **–º–µ—Ö–∞–Ω–∏–∑–º–∞ –≤–Ω–∏–º–∞–Ω–∏—è**\n",
    "\n",
    "–í –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–º –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–µ –≤–Ω–∏–º–∞–Ω–∏–µ: –∫–∞–∂–¥–∞—è –≥–æ–ª–æ–≤–∞ –ø—ã—Ç–∞–µ—Ç—Å—è \"–≤—ã—è–≤–∏—Ç—å\" —Å–≤–æ–∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∏–∑ —Ç–µ–∫—Å—Ç–∞. –°–Ω–∞—á–∞–ª–∞ –≤—ã—á–∏—Å–ª—è–µ—Ç—Å—è –≤–Ω–∏–º–∞–Ω–∏–µ –¥–ª—è –∫–∞–∂–¥–æ–π –≥–æ–ª–æ–≤—ã, –ø–æ—Ç–æ–º –º–∞—Ç—Ä–∏—Ü—ã –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É—é—Ç—Å—è. –£ —Ç–∞–∫–æ–≥–æ –∞–ª–≥–æ—Ä–∏—Ç–º–∞ –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏—è.\n",
    "\n",
    "$$\\text\n",
    "{Attention}(Q, K, V) = \\text{softmax}\\large(\\frac{QK^T}{\\sqrt{d_k}})V$$\n",
    "\n",
    "–†–µ–∑—É–ª—å—Ç–∞—Ç –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤–Ω–∏–º–∞–Ω–∏—è –¥–ª—è –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª—è–µ—Ç —Å–æ–±–æ–π –≤–∑–≤–µ—à–µ–Ω–Ω—É—é —Å—É–º–º—É –≤–µ–∫—Ç–æ—Ä–æ–≤ –∑–Ω–∞—á–µ–Ω–∏–π, –≥–¥–µ –≤–µ—Å–∞ —è–≤–ª—è—é—Ç—Å—è softmax –æ—Ç —Å–∫–∞–ª—è—Ä–Ω—ã—Ö –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–π –∑–∞–ø—Ä–æ—Å–∞ –∏ –∫–ª—é—á–µ–π. –°–ª–æ–∂–Ω–æ—Å—Ç—å –º–µ–Ω—è–µ—Ç—Å—è —Å –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–æ–π –Ω–∞ –ª–∏–Ω–µ–π–Ω—É—é.\n",
    "\n",
    "$$s_i = \\text{dot}(q,k_i)$$\n",
    "$$s'_i = e^{s_i}$$\n",
    "$$\\text\n",
    "{attention}(q,k,v) = \\frac{\\sum_i v_is'_i}{\\sum_j s'_j}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "–ú–æ–¥–µ–ª–∏ —Ç–∏–ø–∞ LLaMA-Chat –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã –¥–ª—è –¥–∏–∞–ª–æ–≥–æ–≤—ã—Ö –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏–π. –¢–∞–∫–∏–µ –º–æ–¥–µ–ª–∏ –æ–±—É—á–∞—é—Ç—Å—è —á–µ—Ä–µ–∑  Reinforcement Learning from Human Feedback (**RLHF**)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LLaMA2**\n",
    "\n",
    "[[paper] üéì Llama 2: Open Foundation and Fine-Tuned Chat Models (2023)](https://arxiv.org/abs/2307.09288)\n",
    "\n",
    "\n",
    "–ü–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å –ø–µ—Ä–≤–æ–π –≤–µ—Ä—Å–∏–µ–π:\n",
    "\n",
    "* +40% –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è,\n",
    "* –∫–æ–Ω—Ç–µ–∫—Å—Ç 4096 —Ç–æ–∫–µ–Ω–æ–≤ (√ó2 LLAMA),\n",
    "* –º–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è Grouped-query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GQA** ‚Äî –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è —É–∂–µ –≤–∏–¥–µ–Ω–Ω–æ–≥–æ –Ω–∞–º–∏ Self-Attention, –≤ –∫–æ—Ç–æ—Ä–æ–π –æ–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥–æ–ª–æ–≤ –≤–Ω–∏–º–∞–Ω–∏—è –¥–µ–ª–∏—Ç—Å—è –Ω–∞ –≥—Ä—É–ø–ø—ã, –≤–Ω—É—Ç—Ä–∏ –∫–æ—Ç–æ—Ä—ã—Ö Key –∏ Value –æ–±—â–∏–µ.\n",
    "\n",
    "[[paper] üéì GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints (2023)](https://arxiv.org/abs/2305.13245)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/gqa.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/2305.13245\"> GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LLaMA3**\n",
    "\n",
    "[[paper] üéì The Llama 3 Herd of Models (2024)](https://arxiv.org/abs/2407.21783)\n",
    "\n",
    "–î–≤–∞ —Ä–∞–∑–º–µ—Ä–∞ –º–æ–¥–µ–ª–∏:\n",
    "- base ‚Äì 8B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "- large ‚Äì 70B –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤\n",
    "\n",
    "–û–±–µ –º–æ–¥–µ–ª–∏ –≤ –¥–≤—É—Ö –≤–µ—Ä—Å–∏—è—Ö (pre-trained & instruct tuned). –î–æ—Å—Ç—É–ø–Ω–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É.\n",
    "\n",
    "–û—Ç–ª–∏—á–∏—è –æ—Ç –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –≤–µ—Ä—Å–∏–π:\n",
    "- —Ä–∞–∑–º–µ—Ä —Å–ª–æ–≤–∞—Ä—è —É–≤–µ–ª–∏—á–µ–Ω –¥–æ 128,256 —Ç–æ–∫–µ–Ω–æ–≤ (VS 32K –≤\n",
    "LLaMA 2)\n",
    "- —Ä–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ —É–≤–µ–ª–∏—á–µ–Ω –≤ 8 —Ä–∞–∑ (–¥–æ 15T\n",
    "—Ç–æ–∫–µ–Ω–æ–≤)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–æ–¥—Ä–æ–±–Ω–µ–µ –ø—Ä–æ –º–æ–¥–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞ –º–æ–∂–Ω–æ –ø–æ—á–∏—Ç–∞—Ç—å –≤ —Å—Ç–∞—Ç—å–µ:\n",
    "\n",
    "[[blog] ‚úèÔ∏è Attention is Not All You Need: –∫–∞–∫ –º–µ–Ω—è–ª–∞—Å—å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞](https://habr.com/ru/articles/804119/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**–ö–∞–∫–∏–µ –µ—â—ë –µ—Å—Ç—å –ë–Ø–ú?**\n",
    "\n",
    "Hugging Face [–ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –ø–æ–∏—Å–∫–æ–≤–∏–∫ üõ†Ô∏è[doc]](https://huggingface.co/models), –ø–æ–∑–≤–æ–ª—è—é—â–∏–π –≤—ã–±—Ä–∞—Ç—å –ë–Ø–ú –ø–æ–¥ –∑–∞–¥–∞—á—É –∏ —è–∑—ã–∫, –≤–∫–ª—é—á–∞—è –º–æ–¥–µ–ª–∏ —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è —Ç–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–Ω–∏–º –∏–∑ –≥–ª–∞–≤–Ω—ã—Ö –ø–ª—é—Å–æ–≤ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —è–≤–ª—è–µ—Ç—Å—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏—Ö –±–µ–∑ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –ó–∞—á–∞—Å—Ç—É—é —Ä–µ—à–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—É—é –∑–∞–¥–∞—á—É –º–æ–∂–Ω–æ –ø—Ä–æ—Å—Ç–æ —Å –ø–æ–º–æ—â—å—é —Ö–æ—Ä–æ—à–æ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏. –ü—Ä–∏ –Ω–∞–ª–∏—á–∏–∏ 10‚Äì50 –ø—Ä–∏–º–µ—Ä–æ–≤ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∏—Ö –≤ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é, —á—Ç–æ–±—ã –ª—É—á—à–µ \"–æ–±—ä—è—Å–Ω–∏—Ç—å\", –≤ —á–µ–º —Å–æ—Å—Ç–æ–∏—Ç –∑–∞–¥–∞—á–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/prompt-engineering.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://fourweekmba.com/prompt-engineering/\"> Prompt Engineering</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–¥–Ω–∞–∫–æ –º–æ–∂–µ—Ç —Å–ª—É—á–∏—Ç—å—Å—è, —á—Ç–æ –∑–∞–¥–∞—á–∞ —Å–ª–∏—à–∫–æ–º —Å–ª–æ–∂–Ω–∞—è –∏ —Ç—Ä–µ–±—É–µ—Ç \"–∑–Ω–∞–Ω–∏–π\", –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –≤—Å—Ç—Ä–µ—á–∞–ª–∏—Å—å –ø—Ä–∏ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–∏–∏ LLM. –î—Ä—É–≥–æ–π –ø—Ä–∏–º–µ—Ä ‚Äî –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫ —è–∑—ã–∫—É, –¥–∞–Ω–Ω—ã–µ –Ω–∞ –∫–æ—Ç–æ—Ä–æ–º –æ—Ç—Å—É—Ç—Å—Ç–≤–æ–≤–∞–ª–∏ –≤ –æ–±—É—á–∞—é—â–µ–º –¥–∞—Ç–∞—Å–µ—Ç–µ.\n",
    "\n",
    "–¢–æ–≥–¥–∞ –º–æ–∂–Ω–æ –æ—Å—É—â–µ—Å—Ç–≤–∏—Ç—å —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –±–æ–ª—å—à–æ–π —è–∑—ã–∫–æ–≤–æ–π –º–æ–¥–µ–ª–∏ (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ —ç–Ω–∫–æ–¥–µ—Ä–Ω–æ–π –º–æ–¥–µ–ª–∏). –í–∞–∂–Ω–æ, —á—Ç–æ –¥–ª—è —ç—Ç–æ–≥–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–º–µ—Ä–æ–≤.\n",
    "\n",
    "–ü—Ä–æ–±–ª–µ–º–∞ —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ –¥–æ–æ–±—É—á–µ–Ω–∏–µ –≤—Å–µ–π LLM —Ç—Ä–µ–±—É–µ—Ç —Å–ª–∏—à–∫–æ–º –º–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –∏ —Ä–µ—Å—É—Ä—Å–æ–≤. –°—É—â–µ—Å—Ç–≤—É—é—Ç —Ä–∞–∑–ª–∏—á–Ω—ã–µ –º–µ—Ç–æ–¥—ã, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç –æ—Å—É—â–µ—Å—Ç–≤–ª—è—Ç—å —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –±–æ–ª–µ–µ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ –∏ –º–µ–Ω—è—Ç—å —Ç–æ–ª—å–∫–æ —á–∞—Å—Ç—å –≤–µ—Å–æ–≤ –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/Parameter-efficient-Fine-tuning.png\" width=\"800\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://kristiburn206.wordpress.com/2023/06/01/parameter-efficient-fine-tuning-peft/\">Parameter Efficient Fine-Tuning</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter-Efficient Fine-Tuning (PEFT) ‚Äî —ç—Ç–æ –º–µ—Ç–æ–¥—ã —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–∑–≤–æ–ª—è—é—Ç —É–ª—É—á—à–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–∞–±–æ—Ç—ã —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã—Ö –∑–∞–¥–∞—á. –ò—Ö –∏–¥–µ—è –∑–∞–∫–ª—é—á–∞–µ—Ç—Å—è –≤ —Ç–æ–º, —á—Ç–æ–±—ã –æ–±—É—á–∏—Ç—å –Ω–µ–±–æ–ª—å—à–æ–µ –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π LLM, –æ—Å—Ç–∞–≤–ª—è—è –±–æÃÅ–ª—å—à—É—é —á–∞—Å—Ç—å –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º–∏. –ë–ª–∞–≥–æ–¥–∞—Ä—è —ç—Ç–æ–º—É –º—ã —Ç–∞–∫–∂–µ –º–æ–∂–µ–º –∏–∑–±–µ–∂–∞—Ç—å –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏—è –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[paper] üéì The Power of Scale for Parameter-Efficient Prompt Tuning (2021)](https://arxiv.org/abs/2104.08691)\n",
    "\n",
    "–ü–µ—Ä–≤—ã–π –º–µ—Ç–æ–¥ PEFT –≤ –Ω–µ–∫–æ—Ç–æ—Ä–æ–º —Å–º—ã—Å–ª–µ —è–≤–ª—è–µ—Ç—Å—è —Ä–∞–∑–≤–∏—Ç–∏–µ–º –∏–¥–µ–∏ prompt engineering.\n",
    "\n",
    "–ü–æ–¥–±–æ—Ä –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ –≤—Ä—É—á–Ω—É—é —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ–±—ã —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –≤—Ö–æ–¥—è—â–∏—Ö –≤ –Ω–µ–µ —Å–ª–æ–≤ –ø—Ä–∏ –ø–æ–¥–∞—á–µ –≤ –º–æ–¥–µ–ª—å –ø—Ä–∏–≤–µ–ª–∏ –∫ –∂–µ–ª–∞–µ–º–æ–º—É —Ä–µ–∑—É–ª—å—Ç–∞—Ç—É –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏. –ò–¥–µ—è prompt tuning —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ–±—ã –∏–∑–±–∞–≤–∏—Ç—å—Å—è –æ—Ç —à–∞–≥–∞ —Å –ø–æ–¥–±–æ—Ä–æ–º —Å–ª–æ–≤ –∏ —Å—Ä–∞–∑—É –ø–æ–¥–±–∏—Ä–∞—Ç—å –Ω—É–∂–Ω—ã–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∏.\n",
    "\n",
    "–§–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ (hard prompt) –ø–æ–¥–±–∏—Ä–∞—é—Ç—Å—è —á–µ–ª–æ–≤–µ–∫–æ–º –∏ –≤–∫–ª—é—á–∞—é—Ç —Ç–æ–∫–µ–Ω—ã –∏–∑ —Å–ª–æ–≤–∞—Ä—è. –¢–æ–∫–µ–Ω—ã –Ω–µ—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ (soft prompt) —è–≤–ª—è—é—Ç—Å—è –æ–±—É—á–∞–µ–º—ã–º–∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/hard-soft.jpg\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://kristiburn206.wordpress.com/2023/06/01/parameter-efficient-fine-tuning-peft/\">Hard vs. Soft Prompting</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–µ–¥ –≤—Ö–æ–¥–æ–º –≤ —è–∑—ã–∫–æ–≤—É—é –º–æ–¥–µ–ª—å —Ä–∞–∑–º–µ—â–∞—é—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ –æ–±—É—á–∞–µ–º—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤.\n",
    "- –£ –º–æ–¥–µ–ª–∏ –µ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Ç–æ–∫–µ–Ω–æ–≤ (input text), –∫–æ—Ç–æ—Ä—ã–µ –ø—Ä–∏–≤—è–∑–∞–Ω—ã –∫ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã–º —Å–ª–æ–≤–∞–º.\n",
    "- –¢–∞–∫–∂–µ –µ—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –Ω–µ –∑–∞–≤–∏—Å—è—Ç –æ—Ç —Å–ª–æ–≤, –ø—Ä–æ—Å—Ç–æ –æ–±—É—á–∞–µ–º—ã–µ –≤–µ–∫—Ç–æ—Ä—ã, –ø—Ä–∏—á–µ–º –∫–∞–∂–¥—ã–π –∏–∑ –Ω–∏—Ö —É–Ω–∏–∫–∞–ª—å–Ω—ã–π."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/comparison.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://research.google/blog/guiding-frozen-language-models-with-learned-soft-prompts/\">Guiding Frozen Language Models with Learned Soft Prompts</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å soft prompt –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä–æ–π –∑–∞–¥–∞—á–∏, —Å–Ω–∞—á–∞–ª–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –ø—Ä–æ–º–ø—Ç –≤ –≤–∏–¥–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤–µ–∫—Ç–æ—Ä–æ–≤ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –¥–ª–∏–Ω—ã (–Ω–∞–ø—Ä–∏–º–µ—Ä, –¥–ª–∏–Ω–æ–π –≤ 20 —Ç–æ–∫–µ–Ω–æ–≤). –≠—Ç–∏ –≤–µ–∫—Ç–æ—Ä—ã –æ–±—ä–µ–¥–∏–Ω—è—é—Ç—Å—è —Å –≤—Ö–æ–¥–Ω—ã–º–∏ –ø—Ä–∏–º–µ—Ä–∞–º–∏ –∏ –ø–æ–¥–∞—é—Ç—Å—è –≤ –º–æ–¥–µ–ª—å.\n",
    "\n",
    "–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ —Å—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç—Å—è —Å —Ü–µ–ª–µ–≤—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ —Ñ—É–Ω–∫—Ü–∏–∏ –ø–æ—Ç–µ—Ä—å, –∏ –µ—ë –∑–Ω–∞—á–µ–Ω–∏–µ –ø–µ—Ä–µ–¥–∞–µ—Ç—Å—è –æ–±—Ä–∞—Ç–Ω–æ –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≥—Ä–∞–¥–∏–µ–Ω—Ç–æ–≤. –û–¥–Ω–∞–∫–æ –æ–±–Ω–æ–≤–ª—è—Ç—å—Å—è –±—É–¥—É—Ç —Ç–æ–ª—å–∫–æ –Ω–æ–≤—ã–µ –æ–±—É—á–∞–µ–º—ã–µ –≤–µ–∫—Ç–æ—Ä—ã, —Ç–æ–≥–¥–∞ –∫–∞–∫ –±–∞–∑–æ–≤–∞—è –º–æ–¥–µ–ª—å –æ—Å—Ç–∞–µ—Ç—Å—è –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω–æ–π.\n",
    "\n",
    "Soft prompts, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –Ω–µ –ø–æ–¥–¥–∞—é—Ç—Å—è —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–π –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–∏. –ù–∞ –∏–Ω—Ç—É–∏—Ç–∏–≤–Ω–æ–º —É—Ä–æ–≤–Ω–µ –æ–Ω–∏ —Å–æ–¥–µ—Ä–∂–∞—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–º, –∫–∞–∫ –Ω–∞–∏–ª—É—á—à–∏–º –æ–±—Ä–∞–∑–æ–º —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–¥–∞—á—É, –∏–º–µ—è —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–π –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö. –û–Ω–∏ –≤—ã–ø–æ–ª–Ω—è—é—Ç —Ç—É –∂–µ —Ä–æ–ª—å, —á—Ç–æ –∏ –Ω–∞–ø–∏—Å–∞–Ω–Ω—ã–µ –≤—Ä—É—á–Ω—É—é –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏, –Ω–æ –±–µ–∑ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏ —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º —Å–ª–æ–≤–∞ —á–µ–ª–æ–≤–µ—á–µ—Å–∫–æ–≥–æ —è–∑—ã–∫–∞.\n",
    "\n",
    "–ß–µ–º –±–æ–ª—å—à–µ —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏, —Ç–µ–º –ª—É—á—à–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–∞–Ω–Ω—ã–π –º–µ—Ç–æ–¥."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/superglue.png\" width=\"400\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/2104.08691\">The Power of Scale for Parameter-Efficient Prompt Tuning</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prefix tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[paper] üéì Prefix-Tuning: Optimizing Continuous Prompts for Generation (2021)](https://arxiv.org/abs/2101.00190)\n",
    "\n",
    "[[paper] üéì P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks (2022)](https://arxiv.org/abs/2110.07602)\n",
    "\n",
    "–†–∞–∑–≤–∏—Ç–∏–µ –∏–¥–µ–∏ prompt tuning: –≤–º–µ—Å—Ç–æ –æ–±—É—á–µ–Ω–∏—è –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –≤—Ö–æ–¥–Ω–æ–≥–æ —Å–ª–æ—è –æ–±—É—á–∞—Ç—å —Å–≤–æ–∏ –ø—Ä–æ–º–ø—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Å–ª–æ—è.\n",
    "\n",
    "–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç—Å—è –≤ N —Ä–∞–∑, –≥–¥–µ N ‚Äî –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–ª–æ–µ–≤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Prompt tuning</em>\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/prompt.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://jjaegii.tistory.com/34\">PEFT: Parameter-Efficient Fine-Tuning</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<em>Prefix tuning</em>\n",
    "\n",
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/prefix.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://jjaegii.tistory.com/34\">PEFT: Parameter-Efficient Fine-Tuning</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ê–¥–∞–ø—Ç–µ—Ä—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[paper] üéì Parameter-Efficient Transfer Learning for NLP (2019)](https://arxiv.org/abs/1902.00751)\n",
    "\n",
    "–í–º–µ—Å—Ç–æ —Ç–æ–≥–æ —á—Ç–æ–±—ã –æ–±—É—á–∞—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤, –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç—Å—è –¥–æ–±–∞–≤–∏—Ç—å –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –º–∞–ª–µ–Ω—å–∫–∏–µ –æ–±—É—á–∞–µ–º—ã–µ —Å–ª–æ–∏ ‚Äî –∞–¥–∞–ø—Ç–µ—Ä—ã.\n",
    "\n",
    "–î–æ–±–∞–≤–ª—è—è –∏—Ö –ø–æ—Å–ª–µ —Å–ª–æ–µ–≤ –≤–Ω–∏–º–∞–Ω–∏—è (multi-head attention) –∏ –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–ª–æ–µ–≤ (feed-forward) –≤ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–µ –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä, –º—ã –º–æ–∂–µ–º –æ–±–Ω–æ–≤–ª—è—Ç—å —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞ –≤ –∞–¥–∞–ø—Ç–µ—Ä–∞—Ö –≤–æ –≤—Ä–µ–º—è —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–∏ —ç—Ç–æ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏ –Ω–µ–∏–∑–º–µ–Ω–Ω—ã–º–∏.\n",
    "\n",
    "–ê–¥–∞–ø—Ç–µ—Ä —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–≤–∞ –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–ª–æ—è, –º–µ–∂–¥—É –∫–æ—Ç–æ—Ä—ã–º–∏ –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–µ–ª–∏–Ω–µ–π–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏. –í—Ö–æ–¥–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ –¥–ª—è —Å–ª–æ—è –∞–¥–∞–ø—Ç–µ—Ä–∞ –±—É–¥–µ—Ç —Å–∫—Ä—ã—Ç–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ $h$, –∫–æ—Ç–æ—Ä–æ–µ —è–≤–ª—è–µ—Ç—Å—è –≤—ã—Ö–æ–¥–æ–º —Å–ª–æ—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/adapter.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://jjaegii.tistory.com/34\">PEFT: Parameter-Efficient Fine-Tuning</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ –ø—Ä–æ—Ö–æ–¥–µ —á–µ—Ä–µ–∑ –ø–µ—Ä–≤—ã–π –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π –∞–¥–∞–ø—Ç–µ—Ä–∞ –≤–µ–∫—Ç–æ—Ä $h$ –ø—Ä–æ–µ—Ü–∏—Ä—É–µ—Ç—Å—è –≤ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ –º–∞–ª–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏. –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è —Ñ—É–Ω–∫—Ü–∏—è –∞–∫—Ç–∏–≤–∞—Ü–∏–∏. –í—ã—Ö–æ–¥ –≤—Ç–æ—Ä–æ–≥–æ –ª–∏–Ω–µ–π–Ω–æ–≥–æ —Å–ª–æ—è –∏–º–µ–µ—Ç —Ç—É –∂–µ —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å, –∫–∞–∫ —É –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ $h$. –í–µ–∫—Ç–æ—Ä $\\Delta h$, –ø–æ–ª—É—á–µ–Ω–Ω—ã–π –ø—Ä–∏ –ø—Ä–æ—Ö–æ–¥–µ —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–æ—Ä, —Å—É–º–º–∏—Ä—É–µ—Ç—Å—è —Å –∏—Å—Ö–æ–¥–Ω—ã–º –≤–µ–∫—Ç–æ—Ä–æ–º $h$ (skip-connection)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[paper] üéì LoRA: Low-Rank Adaptation of Large Language Models (2021)](https://arxiv.org/abs/2106.09685)\n",
    "\n",
    "–°—É—â–µ—Å—Ç–≤—É—é—Ç –∞–¥–∞–ø—Ç–µ—Ä—ã, –∫–æ—Ç–æ—Ä—ã–µ —Ä–∞–±–æ—Ç–∞—é—Ç –Ω–µ –Ω–∞ —É—Ä–æ–≤–Ω–µ —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–Ω–æ–≥–æ —Å–ª–æ—è, –∞ –Ω–∞ —É—Ä–æ–≤–Ω–µ –≤–µ—Å–æ–≤. –ò–¥–µ—è —Å–æ—Å—Ç–æ–∏—Ç –≤ —Ç–æ–º, —á—Ç–æ–±—ã –º–æ–¥–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∂–¥—É—é –º–∞—Ç—Ä–∏—Ü—É —Å–ª–æ—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤–Ω–∏–º–∞–Ω–∏—è: `q_proj` (query), `k_proj` (key), `v_proj` (value)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/lora.png\" width=\"700\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://arxiv.org/abs/2106.09685\">LoRA: Low-Rank Adaptation of Large Language Models</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ß—Ç–æ–±—ã –ø–æ–¥—Ä–æ–±–Ω–µ–µ —Ä–∞–∑–æ–±—Ä–∞—Ç—å –º–µ—Ç–æ–¥ LoRA, —Å–ø—É—Å—Ç–∏–º—Å—è –Ω–∞ –±–æ–ª–µ–µ –ø—Ä–æ—Å—Ç–æ–π —É—Ä–æ–≤–µ–Ω—å. –ü—É—Å—Ç—å —É –Ω–∞—Å –µ—Å—Ç—å –æ–¥–∏–Ω –ª–∏–Ω–µ–π–Ω—ã–π —Å–ª–æ–π –±–µ–∑ —Ñ—É–Ω–∫—Ü–∏–∏ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏.\n",
    "\n",
    "–ï—Å–ª–∏ –Ω–∞ –≤—Ö–æ–¥ –ø–æ–¥–∞–¥–∏–º $x$, –Ω–∞ –≤—ã—Ö–æ–¥–µ –ø–æ–ª—É—á–∏–º $y = Wx$, –≥–¥–µ $W$ ‚Äî –º–∞—Ç—Ä–∏—Ü–∞ –≤–µ—Å–æ–≤.\n",
    "\n",
    "–ú—ã —Ö–æ—Ç–∏–º –Ω–µ–º–Ω–æ–≥–æ –∏–∑–º–µ–Ω–∏—Ç—å –ø—Ä–∏–Ω—Ü–∏–ø —Ä–∞–±–æ—Ç—ã —ç—Ç–æ–≥–æ —Å–ª–æ—è, –¥–æ–æ–±—É—á–∏–≤ –º–æ–¥–µ–ª—å –∏ —Å–∫–æ—Ä—Ä–µ–∫—Ç–∏—Ä–æ–≤–∞–≤ –≤–µ—Å–∞ –Ω–∞ $\\Delta W$ (–∫–æ—Ç–æ—Ä—ã–µ –∏—â—É—Ç –æ–±—ã—á–Ω—ã–º –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–º —Å–ø—É—Å–∫–æ–º) —Ç–∞–∫, —á—Ç–æ–±—ã –Ω–æ–≤—ã–π –≤—ã—Ö–æ–¥ –±—ã–ª:\n",
    "\n",
    "$$y=W'x=(W+\\Delta W)x=y+\\Delta Wx$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/lora1.png\" width=\"300\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://habr.com/ru/articles/747534/\">LoRA</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –º—ã –º–æ–∂–µ–º –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞—Ç—å –≤–µ—Å–∞ –º–∞—Ç—Ä–∏—Ü—ã $W$, –∞ –≤–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ —É—á–∏—Ç—å $\\Delta W$ ‚Äî –º–∞—Ç—Ä–∏—Ü—É, –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—é—â—É—é –æ—Ç–ª–∏—á–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞ –æ–±—ã—á–Ω–æ–π –º–æ–¥–µ–ª–∏, –æ—Ç –¥–æ–æ–±—É—á–µ–Ω–æ–π.\n",
    "\n",
    "–°—Ä–∞–∑—É –≤–æ–∑–Ω–∏–∫–Ω–µ—Ç –≤–æ–ø—Ä–æ—Å ‚Äî –∞ –≥–¥–µ —Ç—É—Ç –≤—ã–∏–≥—Ä—ã—à? –í–µ–¥—å —Ä–∞–∑–º–µ—Ä—ã –º–∞—Ç—Ä–∏—Ü $W$ –∏ $\\Delta W$ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –æ–¥–∏–Ω–∞–∫–æ–≤—ã–º–∏, —Ç–∞–∫ —á—Ç–æ –≤ –Ω–∏—Ö –æ–¥–∏–Ω–∞–∫–æ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "\n",
    "–í–æ—Ç —Ç—É—Ç –∏ –≤–∫–ª—é—á–∞—é—Ç—Å—è –≤ –∏–≥—Ä—É —Å–ª–æ–≤–∞ Low Rank ‚Äî –º–∞—Ç—Ä–∏—Ü—É –º–∞–ª–µ–Ω—å–∫–æ–≥–æ —Ä–∞–Ω–≥–∞ –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –¥–≤—É—Ö –º–µ–Ω—å—à–µ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏. –ù–∞—à–∞ –º–∞—Ç—Ä–∏—Ü–∞ –º–æ–∂–µ—Ç –±—ã—Ç—å —Ä–∞–∑–º–µ—Ä–æ–º 100 –Ω–∞ 70, –Ω–æ —Ä–∞–Ω–≥, —Ç–æ –µ—Å—Ç—å –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏–Ω–µ–π–Ω–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö —Å—Ç—Ä–æ–∫ –∏–ª–∏ —Å—Ç–æ–ª–±—Ü–æ–≤ (—Ç–∞–∫–∏—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–π—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ —Å–æ–¥–µ—Ä–∂–∞—Ç –Ω–æ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –º–æ–¥–µ–ª–∏, –∞ –Ω–µ –¥–µ–π—Å—Ç–≤—É—é—Ç –Ω–∞ –≤–µ–∫—Ç–æ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ —Å–æ—Å–µ–¥—è–º) –º–æ–∂–µ—Ç –±—ã—Ç—å –º–µ–Ω—å—à–µ, —á–µ–º 70, ‚Äî –Ω–∞–ø—Ä–∏–º–µ—Ä 4 –∏–ª–∏ 20."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –Ω–µ–Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä  $\\vec a=(1, -1, 2)$. –ï–≥–æ —Ä–∞–Ω–≥ —Ä–∞–≤–µ–Ω 1.\n",
    "\n",
    "–†–∞—Å—Å–º–æ—Ç—Ä–∏–º –º–∞—Ç—Ä–∏—Ü—É, —Å—Ç—Ä–æ–∫–∏ –∫–æ—Ç–æ—Ä–æ–π –ª–∏–Ω–µ–π–Ω–æ –∑–∞–≤–∏—Å–∏–º—ã (–≤—ã—Ä–∞–∂–∞—é—Ç—Å—è –¥—Ä—É–≥ —á–µ—Ä–µ–∑ –¥—Ä—É–≥–∞).\n",
    "\n",
    "$$\\begin{pmatrix}\n",
    "1 & -1 & 2\\\\\n",
    "2 & -2 & 4\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "–° –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–æ–π —Ç–æ—á–∫–∏ –∑—Ä–µ–Ω–∏—è –≤–æ –≤—Ç–æ—Ä—É—é —Å—Ç—Ä–æ–∫—É –∑–∞–ø–∏—Å–∞–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ $2 \\vec a=(2, -2, 4)$. –¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —Ä–∞–Ω–≥ –¥–∞–Ω–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã —Ç–æ–∂–µ —Ä–∞–≤–µ–Ω 1.\n",
    "\n",
    "–ü–æ–∑–Ω–∞–∫–æ–º–∏–º—Å—è —Å –º–∞—Ç—Ä–∏—Ü–µ–π, —Å—Ç—Ä–æ–∫–∏ –∫–æ—Ç–æ—Ä–æ–π –ª–∏–Ω–µ–π–Ω–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã.\n",
    "\n",
    "$$\\begin{pmatrix}\n",
    "1 & -1 & 2\\\\\n",
    "0 & 1 & -1\n",
    "\\end{pmatrix}$$\n",
    "\n",
    "–ü–∞—Ä–∞ –≤–µ–∫—Ç–æ—Ä–æ–≤ $\\vec a=(1, -1, 2)$ –∏ $\\vec b=(0, 1, -1)$ –Ω–µ –∫–æ–ª–ª–∏–Ω–µ–∞—Ä–Ω—ã. –†–∞–Ω –º–∞—Ç—Ä–∏—Ü—ã —Ä–∞–≤–µ–Ω 2.\n",
    "\n",
    "–†–∞–Ω–≥ –º–∞—Ç—Ä–∏—Ü—ã ‚Äî —ç—Ç–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏–Ω–µ–π–Ω–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö —Å—Ç—Ä–æ–∫ –∏–ª–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ª–∏–Ω–µ–π–Ω–æ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤ (–∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤—Å–µ–≥–¥–∞ —Å–æ–≤–ø–∞–¥–∞–µ—Ç).\n",
    "\n",
    "–ò–∑ –≤—ã—à–µ—Å–∫–∞–∑–∞–Ω–Ω–æ–≥–æ —Ç–∞–∫–∂–µ —Å–ª–µ–¥—É–µ—Ç –≤–∞–∂–Ω—ã–π –ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –æ—Ä–∏–µ–Ω—Ç–∏—Ä: —Ä–∞–Ω–≥ –º–∞—Ç—Ä–∏—Ü—ã –Ω–µ –ø—Ä–µ–≤–æ—Å—Ö–æ–¥–∏—Ç –µ—ë –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –º–∞—Ç—Ä–∏—Ü—É $\\Delta W$ –∫–∞–∫ –ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –¥–≤—É—Ö –º–∞—Ç—Ä–∏—Ü $A$ –∏ $B$. –ü—Ä–∏ —ç—Ç–æ–º —Å–∏–ª—å–Ω–æ –≤—ã–∏–≥—Ä–∞–µ–º –≤ –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤.\n",
    "\n",
    "–î–ª—è –ø—Ä–∏–º–µ—Ä–∞ –Ω–∞ –∫–∞—Ä—Ç–∏–Ω–∫–µ –º–∞—Ç—Ä–∏—Ü–∞ 100 √ó 70 —Å–æ–¥–µ—Ä–∂–∏—Ç 7000 —á–∏—Å–µ–ª, –∞ –¥–≤–µ –≤ –ª–µ–≤–æ–π —á–∞—Å—Ç–∏ –Ω–µ—Ä–∞–≤–µ–Ω—Å—Ç–≤–∞ 140 + 200 = 340."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/lora2.png\" width=\"300\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://habr.com/ru/articles/747534/\">LoRA</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í –æ–±—â–µ–º —Å–ª—É—á–∞–µ –ø–æ—Ç—Ä–µ–±—É–µ—Ç—Å—è –æ–±—É—á–∏—Ç—å –≤ $\\dfrac{ nr + rn }{ n^2 } = \\dfrac{ 2r }{n}$ –º–µ–Ω—å—à–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤. $r$ –≤—ã–±–∏—Ä–∞–µ—Ç—Å—è –º–∞–ª–µ–Ω—å–∫–∏–º, –ø–æ—Ä—è–¥–∫–∞ 2‚Äì8, —á—Ç–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ –∑–Ω–∞—á–µ–Ω–∏–µ –æ—á–µ–Ω—å –º–∞–ª–µ–Ω—å–∫–∏–º: $\\approx 10^{-2}$.\n",
    "\n",
    "–ú—ã –Ω–µ–º–Ω–æ–≥–æ –ø–æ—Ç–µ—Ä—è–µ–º –≤ –æ–±—â–Ω–æ—Å—Ç–∏, —Ç–∞–∫ –∫–∞–∫ —Ç–µ–ø–µ—Ä—å  –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–æ—Å—Ç—É–ª–∏—Ä—É–µ–º, —á—Ç–æ —É $\\Delta W$ –Ω–∏–∑–∫–∏–π —Ä–∞–Ω–≥. –û–¥–Ω–∞–∫–æ –≤ —ç—Ç–æ–º –Ω–µ—Ç –Ω–∏—á–µ–≥–æ —Å—Ç—Ä–∞—à–Ω–æ–≥–æ: —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∏ LoRA —É—Ç–≤–µ—Ä–∂–¥–∞—é—Ç, —á—Ç–æ —Ö–æ—Ç—è LLM –∏–º–µ—é—Ç –º–∏–ª–ª–∏–æ–Ω—ã –∏–ª–∏ –¥–∞–∂–µ –º–∏–ª–ª–∏–∞—Ä–¥—ã –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, –æ–Ω–∏ –∏–º–µ—é—Ç –Ω–∏–∑–∫—É—é \"–≤–Ω—É—Ç—Ä–µ–Ω–Ω—é—é —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å\" (intrinsic dimension) –ø—Ä–∏ –∞–¥–∞–ø—Ç–∞—Ü–∏–∏ –∫ –Ω–æ–≤–æ–π –∑–∞–¥–∞—á–µ. –ü—Ä–æ—â–µ –≥–æ–≤–æ—Ä—è, –±–æ–ª—å—à–∏–Ω—Å—Ç–≤–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —è–≤–ª—è—é—Ç—Å—è –∏–∑–±—ã—Ç–æ—á–Ω—ã–º–∏. –ò–∑ —á–µ–≥–æ –º–æ–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –≤—ã–≤–æ–¥, —á—Ç–æ –º–∞—Ç—Ä–∏—Ü—ã –º–æ–∂–Ω–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–æ–º –º–µ–Ω—å—à–µ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏, —Å–æ—Ö—Ä–∞–Ω—è—è –ø—Ä–∏ —ç—Ç–æ–º –±–æ–ª—å—à—É—é —á–∞—Å—Ç—å –≤–∞–∂–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏.\n",
    "\n",
    "[[paper] üéì Intrinsic Dimensionality Explains the Effectiveness of Language Model Fine-Tuning (2020)](https://arxiv.org/abs/2012.13255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –Ω–∞–º –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —Ö—Ä–∞–Ω–∏—Ç—å –≤ –ø–∞–º—è—Ç–∏ –≤–µ—Å–∞ $W$ –∏—Å—Ö–æ–¥–Ω–æ–π –º–æ–¥–µ–ª–∏ –∏ $\\Delta W=B\\cdot A$ –¥–æ–æ–±—É—á–∞–µ–º–æ–π, –∞ —Å—á–∏—Ç–∞—Ç—å –≥—Ä–∞–¥–∏–µ–Ω—Ç—ã —Ç–æ–ª—å–∫–æ –¥–ª—è \"–Ω–æ–≤—ã—Ö\" –º–∞–ª–µ–Ω—å–∫–∏—Ö –º–∞—Ç—Ä–∏—Ü $A$ –∏ $B$.\n",
    "\n",
    "–ü—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ –º–æ–¥–µ–ª–∏ –º—ã —Å–æ–∑–¥–∞–µ–º –º–∞—Ç—Ä–∏—Ü—É $B$ —Å–ª—É—á–∞–π–Ω—ã–º –æ–±—Ä–∞–∑–æ–º, –∞ –º–∞—Ç—Ä–∏—Ü—É $A$ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –Ω—É–ª—è–º–∏, —á—Ç–æ–±—ã –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ $\\Delta W = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/lora3.png\" width=\"300\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://habr.com/ru/articles/747534/\">LoRA</a></em></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ LLM —Å –ø–æ–º–æ—â—å—é LoRA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã —Ä–∞—Å—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –æ—Å—É—â–µ—Å—Ç–≤–∏—Ç—å —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–∞ LoRa (Low-Rank Adaptation), –∫–æ—Ç–æ—Ä—ã–π:\n",
    "- –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ—Ç –∑–Ω–∞—á–µ–Ω–∏—è –≤–µ—Å–æ–≤ –¥–ª—è –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏\n",
    "- –î–æ–±–∞–≤–ª—è–µ—Ç –Ω–µ–±–æ–ª—å—à–∏–µ –æ–±—É—á–∞–µ–º—ã–µ –º–∞—Ç—Ä–∏—Ü—ã —Ä–∞–Ω–≥–æ–≤–æ–π –¥–µ–∫–æ–º–ø–æ–∑–∏—Ü–∏–∏ –∫ —Å–ª–æ—è–º –≤–Ω–∏–º–∞–Ω–∏—è\n",
    "- –û–±—ã—á–Ω–æ —É–º–µ–Ω—å—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –æ–±—É—á–∞–µ–º—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø—Ä–∏–º–µ—Ä–Ω–æ –Ω–∞ 90%\n",
    "- –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã —Å –ø–∞–º—è—Ç—å—é"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "!pip install -q transformers datasets trl\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–ª–∞—Å—Å `SFTTrainer` [üõ†Ô∏è[doc]](https://huggingface.co/docs/trl/sft_trainer) –∏–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ trl –æ–±–µ—Å–ø–µ—á–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å –∞–¥–∞–ø—Ç–µ—Ä–∞–º–∏ LoRa —á–µ—Ä–µ–∑ –±–∏–±–ª–∏–æ—Ç–µ–∫—É [PEFT üõ†Ô∏è[doc]](https://huggingface.co/docs/peft/en/index).\n",
    "\n",
    "–û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –≤–∫–ª—é—á–∞—é—Ç –≤ —Å–µ–±—è:\n",
    "\n",
    "**1. –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏:**\n",
    "- –í –ø–∞–º—è—Ç–∏ –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Ö—Ä–∞–Ω—è—Ç—Å—è —Ç–æ–ª—å–∫–æ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∞–¥–∞–ø—Ç–µ—Ä–∞\n",
    "- –í–µ—Å–∞ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –æ—Å—Ç–∞—é—Ç—Å—è –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω—ã–º–∏ –∏ –º–æ–≥—É—Ç –±—ã—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω—ã —Å –º–µ–Ω—å—à–µ–π —Ç–æ—á–Ω–æ—Å—Ç—å—é\n",
    "- –ü–æ–∑–≤–æ–ª—è–µ—Ç –≤—ã–ø–æ–ª–Ω—è—Ç—å —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –±–æ–ª—å—à–∏—Ö –º–æ–¥–µ–ª–µ–π –Ω–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏—Ö –≥—Ä–∞—Ñ–∏—á–µ—Å–∫–∏—Ö –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞—Ö\n",
    "\n",
    "**2. –û—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏ –æ–±—É—á–µ–Ω–∏—è:**\n",
    "- –í—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è PEFT/LoRa —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏\n",
    "- –ü–æ–¥–¥–µ—Ä–∂–∫–∞ QLoRA (Quantized LoRa) –¥–ª—è –µ—â–µ –±–æ–ª—å—à–µ–π —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏\n",
    "\n",
    "**3. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–µ—Ä–æ–º:**\n",
    "- –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–µ—Å–æ–≤ –∞–¥–∞–ø—Ç–µ—Ä–∞ –≤–æ –≤—Ä–µ–º—è –∫–æ–Ω—Ç—Ä–æ–ª—å–Ω—ã—Ö —Ç–æ—á–µ–∫ (checkpoints)\n",
    "- –§—É–Ω–∫—Ü–∏–∏ –¥–ª—è –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ –æ–±—Ä–∞—Ç–Ω–æ –∫ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏\n",
    "\n",
    "–î–ª—è —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Ç—Ä–µ–±—É–µ—Ç—Å—è –≤—Å–µ–≥–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à–∞–≥–æ–≤:\n",
    "- –û–ø—Ä–µ–¥–µ–ª–∏—Ç—å –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é LoRa (rank, alpha, dropout)\n",
    "- –°–æ–∑–¥–∞—Ç—å `SFTTrainer` —Å –ø–æ–º–æ—â—å—é `peft_config`\n",
    "- –û–±—É—á–∏—Ç—å –∏ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤–µ—Å–∞ –∞–¥–∞–ø—Ç–µ—Ä–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –¥–∞—Ç–∞—Å–µ—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥–ª—è —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(path=\"HuggingFaceTB/smoltalk\", name=\"everyday-conversations\")\n",
    "clear_output()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–ø—Ä–µ–¥–µ–ª–∏–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from trl import setup_chat_format\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load the model and tokenizer\n",
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_name_or_path=model_name)\n",
    "\n",
    "# Define the chat template\n",
    "model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)\n",
    "\n",
    "# Set the directory where adapter weights will be saved\n",
    "finetune_name = \"SmolLM2-FT-MyDataset\"\n",
    "\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompts = [\n",
    "    \"What is the capital of Germany? Explain why thats the case and if it was different in the past?\",\n",
    "    \"Write a Python function to calculate the factorial of a number.\",\n",
    "    \"A rectangular garden has a length of 25 feet and a width of 15 feet. If you want to build a fence around the entire garden, how many feet of fencing will you need?\",\n",
    "    \"What is the difference between a fruit and a vegetable? Give examples of each.\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_inference(prompt, pipe):\n",
    "    prompt = pipe.tokenizer.apply_chat_template(\n",
    "        [{\"role\": \"user\", \"content\": prompt}],\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    outputs = pipe(\n",
    "        prompt,\n",
    "    )\n",
    "    return outputs[0][\"generated_text\"][len(prompt) :].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in prompts:\n",
    "    print(f\"    prompt:\\n{prompt}\")\n",
    "    print(f\"    response:\\n{test_inference(prompt, pipe)}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –¢–æ–Ω–∫–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SFTTrainer` –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Å –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π PEFT, —á—Ç–æ —É–ø—Ä–æ—â–∞–µ—Ç —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É LLM, –Ω–∞–ø—Ä–∏–º–µ—Ä, —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LoRa. –ù–∞–º –Ω—É–∂–Ω–æ —Ç–æ–ª—å–∫–æ —Å–æ–∑–¥–∞—Ç—å `LoraConfig` –∏ –ø–µ—Ä–µ–¥–∞—Ç—å –µ–≥–æ –≤ `trainer`.\n",
    "\n",
    "–û–ø—Ä–µ–¥–µ–ª–∏–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig\n",
    "\n",
    "# LoRA configuration\n",
    "rank_dimension = 6  # Rank of LoRA update matrices (controls compression level)\n",
    "lora_alpha = (\n",
    "    8  # Scaling factor for LoRA updates (controls influence on original weights)\n",
    ")\n",
    "lora_dropout = (\n",
    "    0.05  # Dropout rate to regularize LoRA layers (helps prevent overfitting)\n",
    ")\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=rank_dimension,  # LoRA rank (e.g., 4‚Äì32)\n",
    "    lora_alpha=lora_alpha,  # LoRA scaling factor ‚Äî typically ~2√ó rank\n",
    "    lora_dropout=lora_dropout,  # dropout probability for LoRA layers\n",
    "    target_modules=\"all-linear\",  # apply to all linear layers\n",
    "    task_type=\"CAUSAL_LM\",  # task type: causal language modeling\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–µ–∂–¥–µ —á–µ–º –Ω–∞—á–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ, –Ω–∞–º –Ω—É–∂–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ã (`TrainingArguments`), –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTConfig\n",
    "\n",
    "\n",
    "args = SFTConfig(\n",
    "    # Output directory for fine-tuned model\n",
    "    output_dir=finetune_name,\n",
    "    # Training duration\n",
    "    num_train_epochs=1,\n",
    "    # Batch size settings\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=2,\n",
    "    # Memory optimization\n",
    "    gradient_checkpointing=True,\n",
    "    # Optimizer configuration\n",
    "    optim=\"adamw_torch_fused\",\n",
    "    learning_rate=2e-4,\n",
    "    max_grad_norm=0.3,\n",
    "    # Learning rate scheduler\n",
    "    warmup_ratio=0.03,\n",
    "    lr_scheduler_type=\"constant\",\n",
    "    # Logging and checkpointing\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\",\n",
    "    # Precision settings\n",
    "    bf16=True,\n",
    "    # Integration settings\n",
    "    push_to_hub=False,\n",
    "    report_to=\"none\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–¢–µ–ø–µ—Ä—å –µ—Å—Ç—å –≤—Å–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è `SFTTrainer`, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å —Ç–æ–Ω–∫—É—é –Ω–∞—Å—Ç—Ä–æ–π–∫—É –º–æ–¥–µ–ª–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "# Create an SFTTrainer with the LoRA configuration\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    peft_config=peft_config,\n",
    "    processing_class=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞—á–Ω–µ–º –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏, –≤—ã–∑–≤–∞–≤ –º–µ—Ç–æ–¥ `train()` –¥–ª—è —ç–∫–∑–µ–º–ø–ª—è—Ä–∞ –∫–ª–∞—Å—Å–∞ `SFTTrainer`. –ü–æ—Å–∫–æ–ª—å–∫—É –º—ã –∏—Å–ø–æ–ª—å–∑—É–µ–º –º–µ—Ç–æ–¥ PEFT, —Å–æ—Ö—Ä–∞–Ω—è—Ç—Å—è —Ç–æ–ª—å–∫–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –≤–µ—Å–∞ –º–æ–¥–µ–ª–∏, –∞ –Ω–µ –ø–æ–ª–Ω–∞—è –º–æ–¥–µ–ª—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training starts, the model will be saved to the output directory\n",
    "trainer.train()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –∞–¥–∞–ø—Ç–æ—Ä–∞ LoRA —Å –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª—å—é"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–∏ LoRa –º—ã –æ–±—É—á–∞–µ–º —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞ –∞–¥–∞–ø—Ç–µ—Ä–æ–≤, —Å–æ—Ö—Ä–∞–Ω—è—è –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å –∑–∞–º–æ—Ä–æ–∂–µ–Ω–Ω–æ–π. –í–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è –º—ã —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —ç—Ç–∏ –≤–µ—Å–∞ –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ (~2‚Äì10 –ú–ë), –∞ –Ω–µ –ø–æ–ª–Ω—É—é –∫–æ–ø–∏—é –º–æ–¥–µ–ª–∏. –û–¥–Ω–∞–∫–æ –¥–ª—è —Ä–∞–∑–≤–µ—Ä—Ç—ã–≤–∞–Ω–∏—è –º–æ–∂–µ—Ç –ø–æ—Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å –∞–¥–∞–ø—Ç–µ—Ä—ã –æ–±—Ä–∞—Ç–Ω–æ –≤ –±–∞–∑–æ–≤—É—é –º–æ–¥–µ–ª—å."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, AutoPeftModelForCausalLM\n",
    "\n",
    "# Loading adapter weights on CPU\n",
    "lora_model = AutoPeftModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=args.output_dir,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "# Merging LoRA with the base model and saving it\n",
    "merged_model = lora_model.merge_and_unload()\n",
    "merged_model.save_pretrained(\n",
    "    args.output_dir, safe_serialization=True, max_shard_size=\"2GB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º –Ω–µ—Å–∫–æ–ª—å–∫–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –∏ –ø–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ —Ä–∞–±–æ—Ç–∞–µ—Ç –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_pipe = pipeline(\n",
    "    \"text-generation\", model=merged_model, tokenizer=tokenizer, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for prompt in prompts:\n",
    "    print(f\"    prompt:\\n{prompt}\")\n",
    "    print(f\"    response:\\n{test_inference(prompt, merged_pipe)}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### –ê–Ω–∞–ª–∏–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ —Å–ª–æ—è"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò—Å—Ö–æ–¥–Ω–∞—è –º–æ–¥–µ–ª—å –∏–º–µ–µ—Ç —Å–ª–µ–¥—É—é—â—É—é –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"HuggingFaceTB/SmolLM2-135M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    pretrained_model_name_or_path=model_name\n",
    ").to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ–∑—å–º–µ–º –º–∞—Ç—Ä–∏—Ü—É –≤–µ—Å–æ–≤ Q (query) –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Å–ª–æ—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.model.layers[0].self_attn.q_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = model.model.layers[0].self_attn.q_proj.weight.data\n",
    "base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –∏–º–µ–µ—Ç –∞–Ω–∞–ª–æ–≥–∏—á–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–í–æ–∑—å–º–µ–º —Ç—É –∂–µ —Å–∞–º—É—é –º–∞—Ç—Ä–∏—Ü—É –≤–µ—Å–æ–≤ –∏ —É–±–µ–¥–∏–º—Å—è, —á—Ç–æ –æ–Ω–∞ –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_model.model.layers[0].self_attn.q_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = merged_model.model.layers[0].self_attn.q_proj.weight.data\n",
    "merged"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–ø–∏—à–µ–º –≤ –æ—Ç–¥–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –Ω–∏–∑–∫–æ—Ä–∞–Ω–≥–æ–≤—ã–µ –º–∞—Ç—Ä–∏—Ü—ã A –∏ B, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—É—á–∞–ª–∏—Å—å —Å –ø–æ–º–æ—â—å—é –º–µ—Ç–æ–¥–∞ LoRA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.base_model.model.model.layers[0].self_attn.q_proj.lora_A.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = trainer.model.base_model.model.model.layers[\n",
    "    0\n",
    "].self_attn.q_proj.lora_A.default.weight.data\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.base_model.model.model.layers[0].self_attn.q_proj.lora_B.default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = trainer.model.base_model.model.model.layers[\n",
    "    0\n",
    "].self_attn.q_proj.lora_B.default.weight.data\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –ø—Ä–∏ –∏—Ö –ø–µ—Ä–µ–º–Ω–æ–∂–µ–Ω–∏–∏ –∏ –ø—Ä–∏–±–∞–≤–ª–µ–Ω–∏–∏ –∫ –º–∞—Ç—Ä–∏—Ü–µ –±–∞–∑–æ–≤–æ–π –º–æ–¥–µ–ª–∏ –ø–æ–ª—É—á–∏–º —Ç–∞–∫—É—é –∂–µ –º–∞—Ç—Ä–∏—Ü—É, –∫–∞–∫ –≤ –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ —Ç–æ–Ω–∫–æ–π –Ω–∞—Å—Ç—Ä–æ–π–∫–∏."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src =\"https://edunet.kea.su/repo/EduNet_NLP-web_dependencies/L07/lora.gif\" width=\"600\"></center>\n",
    "\n",
    "<center><em>–ò—Å—Ç–æ—á–Ω–∏–∫: <a href=\"https://habr.com/ru/articles/791966/\">PEFT</a></em></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base + lora_alpha / rank_dimension * (b @ a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
