{"cells":[{"cell_type":"markdown","source":["<font size=\"6\">Языковое моделирование</font>"],"metadata":{"id":"MUI379KICFyB"}},{"cell_type":"markdown","source":["Языковые модели — важнейшая часть современного NLP. Практически во всех задачах, связанных с обработкой текста, напрямую или косвенно используются языковые модели. А наиболее известные недавние прорывы в области — это по большей части новые подходы к языковому моделированию. ELMO, BERT, GPT — это языковые модели."],"metadata":{"id":"xyC9J2Kg79eK"}},{"cell_type":"markdown","source":["## Что такое языковая модель?"],"metadata":{"id":"gxnSOnl7A-bC"}},{"cell_type":"markdown","source":["Предположим, у нас есть модель поезда. Чем она отличается от настоящего поезда?\n","- обладает некоторыми свойствами поезда (выглядит как он)\n","- может вести себя аналогично поезду\n","- хорошие модели обладают большим количеством вышеперечисленных качеств"],"metadata":{"id":"JbRXbOvyB9Dy"}},{"cell_type":"markdown","source":["<div align=\"center\">\n","    <table >\n","     <tr>\n","       <td>\n","       \n","<center><img src =\"https://i.postimg.cc/R0VNtBMc/train1.jpg\" width=\"250\"></center>\n","\n","<em>Нереалистичная модель</em>\n","\n","</td>\n","\n","<td>\n","\n","<center><img src =\"https://i.ibb.co/HgM1VcB/train2.jpg\" width=\"450\"></center>\n","\n","<em>Реалистичная модель</em>\n","\n","\n","</td>\n","     </tr>\n","    </table>\n","    </div>"],"metadata":{"id":"aV_M_qwXEEmo"}},{"cell_type":"markdown","source":["Аналогично — модель физического мира: построить некоторую конструкцию и понять, упадет ли она, какая будет траектория падения.\n","- позволяет понять, какие события лучше согласуются с окружающим миром, какие более вероятны\n","- может предсказать, что произойдет, учитывая некоторый \"контекст\""],"metadata":{"id":"TtK84DTID5k3"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.ibb.co/hWLWzJH/physical-model.jpg\" width=\"700\"></center>"],"metadata":{"id":"d-4VDi0pKgNz"}},{"cell_type":"markdown","source":["То же самое с языком. Языковая модель должна обладать какими-то свойствами языка и предсказывать вероятность события (текста, предложения, токена, символа) в некотором контексте."],"metadata":{"id":"eM_BBCJ0LO8I"}},{"cell_type":"markdown","source":["<div align=\"center\">\n","    <table >\n","     <tr>\n","       <td>\n","       \n","<center><img src =\"https://i.ibb.co/d4hGRhY/keyboard.png\" width=\"400\"></center>\n","\n","<em>Клавиатура смартфона</em>\n","\n","</td>\n","\n","<td>\n","\n","<center><img src =\"https://i.ibb.co/TwD1Ryb/search.png\" width=\"600\"></center>\n","\n","<em>Поисковый запрос</em>\n","\n","\n","</td>\n","     </tr>\n","    </table>\n","    </div>"],"metadata":{"id":"eOQ0jpHlNptO"}},{"cell_type":"markdown","source":["Если модель способна предсказать вероятность следующего слова, то она уже достаточно много знает о языке.\n","\n","*Я люблю вкусную ...*\n","\n","На месте пропуска должно стоять неодушевленное существительное женского рода в винительном падеже, которое обозначает нечто съедобное (*еду, колбасу, рыбу* и т.д.)."],"metadata":{"id":"sDuVcdKmOAOV"}},{"cell_type":"markdown","source":["## Как вычислить вероятность предложения?"],"metadata":{"id":"XTcBh9iJO5OL"}},{"cell_type":"markdown","source":["Пусть у нас есть несколько цветных шаров. Как подсчитать вероятность вытащить зеленый шар?\n","\n"],"metadata":{"id":"8UfCmfhDQDVJ"}},{"cell_type":"markdown","source":["<div align=\"center\">\n","    <table >\n","     <tr>\n","       <td>\n","       \n","<center><img src =\"https://i.ibb.co/bB27GRc/balls.jpg\" width=\"350\"></center>\n","\n","<em>$$ \\frac {5}{5+5+5+5}= \\frac {1}{4}$$</em>\n","\n","</td>\n","\n","</tr>\n","</table>\n","</div>"],"metadata":{"id":"vzzgDsueQpHL"}},{"cell_type":"markdown","source":["Попробуем сделать то же самое для подсчета вероятности предложений.\n","\n","$$ 1.\\,P(\\text {Colorless green ideas sleep furiously}) = \\frac {0}{|\\text{corpus}|} = 0$$\n","\n","$$ 2.\\,P(\\text {Furiously sleep ideas green colorless}) = \\frac {0}{|\\text{corpus}|} = 0$$\n","\n","При таком подходе предложения, которые никогда не встречались в корпусе, будут иметь нулевую вероятность. Однако языковая интуиция подсказывает, что предложение 1 должно быть более вероятным, чем предложение 2.\n","\n","Мы не сможем надежно оценить вероятности предложений, если будем рассматривать их как неделимые сущности. Можно оценивать вероятность не всего предложения целиком, а каждого из входящих в него слов в определенном контексте."],"metadata":{"id":"cEfEvPp0Q51S"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.ibb.co/XL48yhW/sentence.png\" width=\"700\"></center>"],"metadata":{"id":"nKd030fgTdHN"}},{"cell_type":"markdown","source":["Языковая модель оценивает вероятность встретить предложение $S$ — последовательность слов $(w_1,\\cdots ,w_n)$. Вероятность предложения можно определить как произведение вероятности каждого слова с учетом предыдущих слов:\n","$$P(w_1,w_2, \\dots, w_n) = P(w_1)P(w_2|w_1)P(w_3|w_1,w_2)\\dots P(w_n|w_1,w_2,\\dots,w_{n-1})= \\prod\\limits_{i = 1}^n P(w_i|w_1, \\dots, w_{i-1})$$\n","Для каждого слова последовательности предсказывается вероятность встретить его в тексте при условии, что известно предыдущее слово: $w_2$ при условии $w_1$, $w_3$ при условии $w_1$ и $w_2$, и т.д."],"metadata":{"id":"6PmMowSTUnOZ"}},{"cell_type":"markdown","source":["### N-граммные языковые модели"],"metadata":{"id":"UK5kR0oNU2Ps"}},{"cell_type":"markdown","source":["Истинные вероятности предложений неизвестны → можно обучить языковую модель оценивать эти вероятности. Вероятность рассчитывается на основе частоты встречаемости слов в корпусе текстов:\n","$$P (w_i|w_1, w_2, \\dots, w_{i-1}) = \\frac{count(w_1, w_2, \\dots, w_i)}{count(w_1, w_2, \\dots, w_{i-1})}$$"],"metadata":{"id":"QvwA_9vyfxf6"}},{"cell_type":"markdown","source":["Однако снова возникнет проблема, что большинство последовательностей $w_1, \\dots, w_i$ не встречаются в корпусе.\n","\n","Можно воспользоваться [марковским свойством](https://en.wikipedia.org/wiki/Markov_property):\n","\n","- Вероятность слова зависит только от конечного количества предыдущих слов."],"metadata":{"id":"m2QIaxs8f08X"}},{"cell_type":"markdown","source":["Такие языковые модели называются *n-граммными*:\n","\n","$$P (w_i|w_1, w_2, \\dots, w_{i-1}) = P (w_i|w_{i-(n-1)}, \\dots, w_{i-1}) = \\frac{count(w_{i-(n-1)}, \\dots, w_{i-1}, w_{i})}{count(w_{i-(n-1)}, \\dots, w_{i-1})}$$\n","\n","*Биграммные* языковые модели — $n = 2$:\n","$$ P (w_i|w_1, w_2, \\dots, w_{i-1}) = P (w_i|w_{i-1}) = \\frac{count(w_{i-1}, w_{i})}{count(w_{i-1})}$$\n","\n","$$ P(\\text {Where are we going}) = P(\\text {where}) \\times P(\\text {are|where}) \\times P(\\text {we|are}) \\times P(\\text{going|we})$$\n","\n","*Триграммные* языковые модели — $n = 3$:\n","$$ P (w_i|w_1, w_2, \\dots, w_{i-1}) = P (w_i|w_{i-2}, w_{i-1}) = \\frac{count(w_{i-2}, w_{i-1}, w_{i})}{count(w_{i-2}, w_{i-1})}$$\n","$$ P(\\text {Where are we going}) = P(\\text {where}) \\times P(\\text {are|where}) \\times P(\\text {we|where are}) \\times P(\\text{going|are we})$$"],"metadata":{"id":"N6FOVeU_U_gi"}},{"cell_type":"markdown","source":["Тем не менее, последовательность $w_{i-2}, w_{i-1}, w_i$ тоже может отсутствовать в корпусе. Чтобы не допустить зануления вероятности всего предложения, применяется сглаживание.\n","\n","Основная идея заключается в том, чтобы изменить количество вхождений таким образом, чтобы вероятность не становилась нулевой. Один из простый и эффективных алгоритмов — *сглаживание Лапласа* или *аддитивное сглаживание*. Представим, что мы видели каждую *n*-грамму хотя бы один раз (или $\\delta$ раз, $\\delta \\ge 0$).\n","\n","\n","$$ P(w_i|w_{i-(n-1)}, \\dots, w_{i-1}) = \\frac{count(w_{i-(n-1)}, \\dots, w_{i-1}, w_{i}) + \\delta}{count(w_{i-(n-1)}, \\dots, w_{i-1}) + \\delta \\times |V|} $$"],"metadata":{"id":"m2VWv0GreTKV"}},{"cell_type":"markdown","source":["### Генерация текста"],"metadata":{"id":"8PSiPIMSlfzI"}},{"cell_type":"markdown","source":["Как только у нас будет языковая модель, мы сможем использовать ее для генерации текста. Мы делаем это по одному токену за раз: предсказываем распределение вероятности следующего токена с учетом предыдущего контекста и делаем выборку (sampling) из этого распределения."],"metadata":{"id":"sP0nSDWaiWkC"}},{"cell_type":"markdown","source":["<div align=\"center\">\n","    <table >\n","     <tr>\n","       <td>\n","       \n","<center><img src =\"https://i.ibb.co/LCv7Rrr/2.png\" width=\"400\"></center>\n","<em>1</em>\n","</td>\n","\n","<td>\n","<center><img src =\"https://i.ibb.co/RyfR9Dx/3.png\" width=\"400\"></center>\n","<em>2</em>\n","</td>\n","\n","<td>\n","<center><img src =\"https://i.postimg.cc/gJxjMHLj/4.png\" width=\"400\"></center>\n","<em>3</em>\n","</td>\n","     </tr>\n","     \n","<div align=\"center\">\n","    <table >\n","  <tr>\n","     <td>\n","<center><img src =\"https://i.postimg.cc/jqJCPvrk/6.png\" width=\"400\"></center>\n","<em>4</em>\n","</td>\n","\n","<td>\n","<center><img src =\"https://i.postimg.cc/BQT6w6bT/7.png\" width=\"400\"></center>\n","<em>5</em>\n","</td>\n","\n","<td>\n","<center><img src =\"https://i.ibb.co/2g2DxPt/8.png\" width=\"400\"></center>\n","<em>6</em>\n","</td>\n","     </tr>"],"metadata":{"id":"TKJ7U_3tljIe"}},{"cell_type":"markdown","source":["В качестве альтернативы можно применить жадный поиск (greedy decoding): на каждом шаге выбирается токен с наибольшей вероятностью. Однако обычно это работает не очень хорошо."],"metadata":{"id":"j8xCINl-tH6R"}},{"cell_type":"markdown","source":["## Генерация научных статей с помощью n-граммной модели"],"metadata":{"id":"VQ0r0rxqtpZp"}},{"cell_type":"markdown","metadata":{"cellId":"k1gpzj4guo8e1riwj3om1k","id":"yUUTv4PteCXH"},"source":["Обучим языковую модель на [базе статей arXiv](https://www.kaggle.com/datasets/neelshah18/arxivdataset) и посмотрим, сможем ли мы создать новую статью.\n","\n","<center><img src =\"https://i.ibb.co/CW0DwSQ/ai.jpg\" width=\"600\"></center>"]},{"cell_type":"markdown","source":["### Подготовка данных"],"metadata":{"id":"GByqOAZbzBSU"}},{"cell_type":"markdown","source":["Загрузим набор данных и запишем в переменную `data`."],"metadata":{"id":"MNLe6ThuwK2O"}},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/Xeanst/NLP_course_FBB/main/data/arxivData.json"],"metadata":{"id":"FHPWxSbRwBfz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730470827022,"user_tz":-180,"elapsed":2840,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"5d5d48ae-0629-49cb-ca04-cf5e6bf5b6de"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-11-01 14:20:24--  https://raw.githubusercontent.com/Xeanst/NLP_course_FBB/main/data/arxivData.json\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 72422946 (69M) [text/plain]\n","Saving to: ‘arxivData.json’\n","\n","arxivData.json      100%[===================>]  69.07M  56.7MB/s    in 1.2s    \n","\n","2024-11-01 14:20:26 (56.7 MB/s) - ‘arxivData.json’ saved [72422946/72422946]\n","\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"0c76vnyl3zui9yhtkodgrlf","id":"W_KOl5xUeCXL","colab":{"base_uri":"https://localhost:8080/","height":293},"executionInfo":{"status":"ok","timestamp":1730470834114,"user_tz":-180,"elapsed":7094,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"6d0561cf-9b67-41ef-9abb-b7c18efacc0f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                  author  day            id  \\\n","10438                      [{'name': 'XuanLong Nguyen'}]    4   1001.0597v2   \n","38508                     [{'name': 'Preda Mihailescu'}]   22   0708.2974v1   \n","7462   [{'name': 'Hongfu Liu'}, {'name': 'Jun Li'}, {...    5  1801.01899v1   \n","27255  [{'name': 'Masaharu Sakamoto'}, {'name': 'Hiro...    1  1703.00311v3   \n","28432     [{'name': 'Bo Jiang'}, {'name': 'Chris Ding'}]   20  1706.06409v1   \n","\n","                                                    link  month  \\\n","10438  [{'rel': 'alternate', 'href': 'http://arxiv.or...      1   \n","38508  [{'rel': 'alternate', 'href': 'http://arxiv.or...      8   \n","7462   [{'rel': 'alternate', 'href': 'http://arxiv.or...      1   \n","27255  [{'rel': 'alternate', 'href': 'http://arxiv.or...      3   \n","28432  [{'rel': 'alternate', 'href': 'http://arxiv.or...      6   \n","\n","                                                 summary  \\\n","10438  We consider the problem of analyzing the heter...   \n","38508  The \\textit{fuzzy vault} approach is one of th...   \n","7462   Cluster analysis and outlier detection are str...   \n","27255  Lung nodule classification is a class imbalanc...   \n","28432  In many real-world applications, data usually ...   \n","\n","                                                     tag  \\\n","10438  [{'term': 'stat.ME', 'scheme': 'http://arxiv.o...   \n","38508  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n","7462   [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...   \n","27255  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n","28432  [{'term': 'cs.CV', 'scheme': 'http://arxiv.org...   \n","\n","                                                   title  year  \n","10438  Inference of global clusters from locally dist...  2010  \n","38508  The Fuzzy Vault for fingerprints is Vulnerable...  2007  \n","7462                     Clustering with Outlier Removal  2018  \n","27255  Multi-stage Neural Networks with Single-sided ...  2017  \n","28432  Outlier Regularization for Vector Data and L21...  2017  "],"text/html":["\n","  <div id=\"df-437c0b2f-0aad-43de-8bbe-fea11069462f\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>author</th>\n","      <th>day</th>\n","      <th>id</th>\n","      <th>link</th>\n","      <th>month</th>\n","      <th>summary</th>\n","      <th>tag</th>\n","      <th>title</th>\n","      <th>year</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>10438</th>\n","      <td>[{'name': 'XuanLong Nguyen'}]</td>\n","      <td>4</td>\n","      <td>1001.0597v2</td>\n","      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n","      <td>1</td>\n","      <td>We consider the problem of analyzing the heter...</td>\n","      <td>[{'term': 'stat.ME', 'scheme': 'http://arxiv.o...</td>\n","      <td>Inference of global clusters from locally dist...</td>\n","      <td>2010</td>\n","    </tr>\n","    <tr>\n","      <th>38508</th>\n","      <td>[{'name': 'Preda Mihailescu'}]</td>\n","      <td>22</td>\n","      <td>0708.2974v1</td>\n","      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n","      <td>8</td>\n","      <td>The \\textit{fuzzy vault} approach is one of th...</td>\n","      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n","      <td>The Fuzzy Vault for fingerprints is Vulnerable...</td>\n","      <td>2007</td>\n","    </tr>\n","    <tr>\n","      <th>7462</th>\n","      <td>[{'name': 'Hongfu Liu'}, {'name': 'Jun Li'}, {...</td>\n","      <td>5</td>\n","      <td>1801.01899v1</td>\n","      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n","      <td>1</td>\n","      <td>Cluster analysis and outlier detection are str...</td>\n","      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n","      <td>Clustering with Outlier Removal</td>\n","      <td>2018</td>\n","    </tr>\n","    <tr>\n","      <th>27255</th>\n","      <td>[{'name': 'Masaharu Sakamoto'}, {'name': 'Hiro...</td>\n","      <td>1</td>\n","      <td>1703.00311v3</td>\n","      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n","      <td>3</td>\n","      <td>Lung nodule classification is a class imbalanc...</td>\n","      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n","      <td>Multi-stage Neural Networks with Single-sided ...</td>\n","      <td>2017</td>\n","    </tr>\n","    <tr>\n","      <th>28432</th>\n","      <td>[{'name': 'Bo Jiang'}, {'name': 'Chris Ding'}]</td>\n","      <td>20</td>\n","      <td>1706.06409v1</td>\n","      <td>[{'rel': 'alternate', 'href': 'http://arxiv.or...</td>\n","      <td>6</td>\n","      <td>In many real-world applications, data usually ...</td>\n","      <td>[{'term': 'cs.CV', 'scheme': 'http://arxiv.org...</td>\n","      <td>Outlier Regularization for Vector Data and L21...</td>\n","      <td>2017</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-437c0b2f-0aad-43de-8bbe-fea11069462f')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-437c0b2f-0aad-43de-8bbe-fea11069462f button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-437c0b2f-0aad-43de-8bbe-fea11069462f');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b5ac7cab-aa33-4cc6-9a4a-91aed0aae171\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b5ac7cab-aa33-4cc6-9a4a-91aed0aae171')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b5ac7cab-aa33-4cc6-9a4a-91aed0aae171 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"data\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"author\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[{'name': 'Preda Mihailescu'}]\",\n          \"[{'name': 'Bo Jiang'}, {'name': 'Chris Ding'}]\",\n          \"[{'name': 'Hongfu Liu'}, {'name': 'Jun Li'}, {'name': 'Yue Wu'}, {'name': 'Yun Fu'}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 9,\n        \"min\": 1,\n        \"max\": 22,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          22,\n          20,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"0708.2974v1\",\n          \"1706.06409v1\",\n          \"1801.01899v1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"link\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/0708.2974v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/0708.2974v1', 'type': 'application/pdf', 'title': 'pdf'}]\",\n          \"[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1706.06409v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1706.06409v1', 'type': 'application/pdf', 'title': 'pdf'}]\",\n          \"[{'rel': 'alternate', 'href': 'http://arxiv.org/abs/1801.01899v1', 'type': 'text/html'}, {'rel': 'related', 'href': 'http://arxiv.org/pdf/1801.01899v1', 'type': 'application/pdf', 'title': 'pdf'}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 8,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          8,\n          6,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The \\\\textit{fuzzy vault} approach is one of the best studied and well\\naccepted ideas for binding cryptographic security into biometric\\nauthentication. The vault has been implemented in connection with fingerprint\\ndata by Uludag and Jain. We show that this instance of the vault is vulnerable\\nto brute force attack. An interceptor of the vault data can recover both secret\\nand template data using only generally affordable computational resources. Some\\npossible alternatives are then discussed and it is suggested that cryptographic\\nsecurity may be preferable to the one - way function approach to biometric\\nsecurity.\",\n          \"In many real-world applications, data usually contain outliers. One popular\\napproach is to use L2,1 norm function as a robust error/loss function. However,\\nthe robustness of L2,1 norm function is not well understood so far. In this\\npaper, we propose a new Vector Outlier Regularization (VOR) framework to\\nunderstand and analyze the robustness of L2,1 norm function. Our VOR function\\ndefines a data point to be outlier if it is outside a threshold with respect to\\na theoretical prediction, and regularize it-pull it back to the threshold line.\\nWe then prove that L2,1 function is the limiting case of this VOR with the\\nusual least square/L2 error function as the threshold shrinks to zero. One\\ninteresting property of VOR is that how far an outlier lies away from its\\ntheoretically predicted value does not affect the final regularization and\\nanalysis results. This VOR property unmasks one of the most peculiar property\\nof L2,1 norm function: The effects of outliers seem to be independent of how\\noutlying they are-if an outlier is moved further away from the intrinsic\\nmanifold/subspace, the final analysis results do not change. VOR provides a new\\nway to understand and analyze the robustness of L2,1 norm function. Applying\\nVOR to matrix factorization leads to a new VORPCA model. We give a\\ncomprehensive comparison with trace-norm based L21-norm PCA to demonstrate the\\nadvantages of VORPCA.\",\n          \"Cluster analysis and outlier detection are strongly coupled tasks in data\\nmining area. Cluster structure can be easily destroyed by few outliers; on the\\ncontrary, the outliers are defined by the concept of cluster, which are\\nrecognized as the points belonging to none of the clusters. However, most\\nexisting studies handle them separately. In light of this, we consider the\\njoint cluster analysis and outlier detection problem, and propose the\\nClustering with Outlier Removal (COR) algorithm. Generally speaking, the\\noriginal space is transformed into the binary space via generating basic\\npartitions in order to define clusters. Then an objective function based\\nHoloentropy is designed to enhance the compactness of each cluster with a few\\noutliers removed. With further analyses on the objective function, only partial\\nof the problem can be handled by K-means optimization. To provide an integrated\\nsolution, an auxiliary binary matrix is nontrivally introduced so that COR\\ncompletely and efficiently solves the challenging problem via a unified\\nK-means- - with theoretical supports. Extensive experimental results on\\nnumerous data sets in various domains demonstrate the effectiveness and\\nefficiency of COR significantly over the rivals including K-means- - and other\\nstate-of-the-art outlier detection methods in terms of cluster validity and\\noutlier detection. Some key factors in COR are further analyzed for practical\\nuse. Finally, an application on flight trajectory is provided to demonstrate\\nthe effectiveness of COR in the real-world scenario.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tag\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.CR', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'D.4.6', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]\",\n          \"[{'term': 'cs.CV', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]\",\n          \"[{'term': 'stat.ME', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'cs.LG', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}, {'term': 'stat.ML', 'scheme': 'http://arxiv.org/schemas/atom', 'label': None}]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The Fuzzy Vault for fingerprints is Vulnerable to Brute Force Attack\",\n          \"Outlier Regularization for Vector Data and L21 Norm Robustness\",\n          \"Clustering with Outlier Removal\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4,\n        \"min\": 2007,\n        \"max\": 2018,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2007,\n          2017,\n          2010\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":2}],"source":["import pandas as pd\n","\n","data = pd.read_json(\"arxivData.json\")\n","data.sample(n=5)"]},{"cell_type":"markdown","source":["Запишем название и краткое содержание статьи в отдельную переменную `lines`."],"metadata":{"id":"nfKfBie-yKBs"}},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"lbyqb5rx7j8jpo591r06ak","id":"VRAxswHgeCXM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730470837096,"user_tz":-180,"elapsed":2984,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"f48fde9e-3b71-433d-8b55-3dbb89a25851"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Differential Contrastive Divergence ; This paper has been retracted.',\n"," 'What Does Artificial Life Tell Us About Death? ; Short philosophical essay',\n"," 'P=NP ; We claim to resolve the P=?NP problem via a formal argument for P=NP.']"]},"metadata":{},"execution_count":3}],"source":["lines = data.apply(lambda row: row['title'] + ' ; ' + row['summary'].replace(\"\\n\", ' '), axis=1).tolist()\n","\n","sorted(lines, key=len)[:3]"]},{"cell_type":"markdown","metadata":{"cellId":"7u97m5s8ekl5zd5a43a1yc","id":"2rjAwyCXeCXM"},"source":["Токенизируем данные с помощью метода WordPunctTokenizer из библиотеки NLTK. Обратите внимание, что для обучения языковой модели не нужно удалять стоп-слова и применять лемматизацию. Мы хотим, чтобы модель \"выучила\", как выглядят естественные тексты."]},{"cell_type":"code","source":["import nltk\n","nltk.download('punkt')\n","from nltk.tokenize import word_tokenize\n","\n","lines = [' '.join(word_tokenize(l.lower())) for l in lines]\n","\n","sorted(lines, key=len)[:3]"],"metadata":{"id":"bn_5JX4Q07WH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730470937782,"user_tz":-180,"elapsed":100688,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"bf2900c1-1294-4a96-8aad-dd9c9c6dabc8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"execute_result","data":{"text/plain":["['differential contrastive divergence ; this paper has been retracted .',\n"," 'what does artificial life tell us about death ? ; short philosophical essay',\n"," 'p=np ; we claim to resolve the p= ? np problem via a formal argument for p=np .']"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["### Построение и обучение модели"],"metadata":{"id":"fPG8mR1XzFnI"}},{"cell_type":"markdown","metadata":{"cellId":"u68wydbiioqlp5gl96mhd","id":"7YrNeimxeCXP"},"source":["На первом этапе построения *n*-раммной языковой модели необходимо посчитать, сколько раз каждое слово встречалось после $(n - 1)$ предыдущих слов. Результатом должен быть словарь вида `{ tuple(prefix_tokens): {next_token_1: count_1, next_token_2: count_2}}`, где `prefix_tokens` — предшествующие токены.\n","\n","Так, при `n=3` для последовательности *differential contrastive divergence ;* получим:\n","\n","- `('differential', 'contrastive'): ({'divergence': 1})`,\n","- `('contrastive', 'divergence'): ({';': 1})`\n","\n","Если количество предшествующих токенов меньше, чем (n - 1), требуется добавить паддинг `UNK` (unknown word):\n","- первое слово в предложении (пустой префикс): \"\" -> `(UNK, UNK)`\n","  - `('UNK','UNK'): ({'differential': 1})`\n","- второе слово в предложении (короткий префикс): \"word\" -> `(UNK, word)`\n","  - `('UNK', 'differential'): ({'contrastive': 1})`\n","\n","Также требуется добавить специальный токен `EOS` (end of sentence) в конце каждой последовательности\n","- *this paper has been retracted .* -> `(this, paper, has, been, retracted, ., EOS)`\n","  - `('retracted', '.'): Counter({'_EOS_': 1})`\n","  - `('.', '_EOS_'): Counter({'_EOS_': 1})`"]},{"cell_type":"code","source":["from collections import defaultdict, Counter, deque\n","\n","# `UNK` — отсутствующие токены, `EOS` — окончание последовательности\n","UNK, EOS = \"_UNK_\", \"_EOS_\"\n","n = 3\n","\n","counts = defaultdict(Counter)\n","# counts[(word1, word2)][word3] = сколько раз слово word3 встретилось после слов (word1, word2)\n","print(f'counts: {counts}')\n","\n","l = sorted(lines, key=len)[0]\n","tok = l.split() # деление по пробелам\n","tok.append(EOS) # добавление токена конца предложения\n","print(f'tok: {tok}\\n')\n","prefix = deque([UNK] * (n-1), maxlen=n-1) # двусторонняя очередь, поддерживает операции добавления и извлечения элементов, имеет фиксированную длину\n","for t in tok:\n","  counts[tuple(prefix)][t] += 1 # +1 вхождение слова word3 после (word1, word2)\n","  print(f'prefix: {prefix}')\n","  print(f't: {t}')\n","  print(f'last key from counts: {list(counts.keys())[-1]}')\n","  print(f'last value from counts: {list(counts.values())[-1]}\\n')\n","  prefix.append(t) # меняем префикс\n","counts[tuple(prefix)][t] += 1\n","print(f'prefix: {prefix}')\n","print(f't: {t}')\n","print(f'last key from counts: {list(counts.keys())[-1]}')\n","print(f'last value from counts: {list(counts.values())[-1]}\\n')\n","print('counts:', *counts.items(), sep='\\n')"],"metadata":{"id":"Uh3H1m_H9HFS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730470937782,"user_tz":-180,"elapsed":17,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"3ad6fb4e-bfbe-44d0-e46e-489ca334c4f6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["counts: defaultdict(<class 'collections.Counter'>, {})\n","tok: ['differential', 'contrastive', 'divergence', ';', 'this', 'paper', 'has', 'been', 'retracted', '.', '_EOS_']\n","\n","prefix: deque(['_UNK_', '_UNK_'], maxlen=2)\n","t: differential\n","last key from counts: ('_UNK_', '_UNK_')\n","last value from counts: Counter({'differential': 1})\n","\n","prefix: deque(['_UNK_', 'differential'], maxlen=2)\n","t: contrastive\n","last key from counts: ('_UNK_', 'differential')\n","last value from counts: Counter({'contrastive': 1})\n","\n","prefix: deque(['differential', 'contrastive'], maxlen=2)\n","t: divergence\n","last key from counts: ('differential', 'contrastive')\n","last value from counts: Counter({'divergence': 1})\n","\n","prefix: deque(['contrastive', 'divergence'], maxlen=2)\n","t: ;\n","last key from counts: ('contrastive', 'divergence')\n","last value from counts: Counter({';': 1})\n","\n","prefix: deque(['divergence', ';'], maxlen=2)\n","t: this\n","last key from counts: ('divergence', ';')\n","last value from counts: Counter({'this': 1})\n","\n","prefix: deque([';', 'this'], maxlen=2)\n","t: paper\n","last key from counts: (';', 'this')\n","last value from counts: Counter({'paper': 1})\n","\n","prefix: deque(['this', 'paper'], maxlen=2)\n","t: has\n","last key from counts: ('this', 'paper')\n","last value from counts: Counter({'has': 1})\n","\n","prefix: deque(['paper', 'has'], maxlen=2)\n","t: been\n","last key from counts: ('paper', 'has')\n","last value from counts: Counter({'been': 1})\n","\n","prefix: deque(['has', 'been'], maxlen=2)\n","t: retracted\n","last key from counts: ('has', 'been')\n","last value from counts: Counter({'retracted': 1})\n","\n","prefix: deque(['been', 'retracted'], maxlen=2)\n","t: .\n","last key from counts: ('been', 'retracted')\n","last value from counts: Counter({'.': 1})\n","\n","prefix: deque(['retracted', '.'], maxlen=2)\n","t: _EOS_\n","last key from counts: ('retracted', '.')\n","last value from counts: Counter({'_EOS_': 1})\n","\n","prefix: deque(['.', '_EOS_'], maxlen=2)\n","t: _EOS_\n","last key from counts: ('.', '_EOS_')\n","last value from counts: Counter({'_EOS_': 1})\n","\n","counts:\n","(('_UNK_', '_UNK_'), Counter({'differential': 1}))\n","(('_UNK_', 'differential'), Counter({'contrastive': 1}))\n","(('differential', 'contrastive'), Counter({'divergence': 1}))\n","(('contrastive', 'divergence'), Counter({';': 1}))\n","(('divergence', ';'), Counter({'this': 1}))\n","((';', 'this'), Counter({'paper': 1}))\n","(('this', 'paper'), Counter({'has': 1}))\n","(('paper', 'has'), Counter({'been': 1}))\n","(('has', 'been'), Counter({'retracted': 1}))\n","(('been', 'retracted'), Counter({'.': 1}))\n","(('retracted', '.'), Counter({'_EOS_': 1}))\n","(('.', '_EOS_'), Counter({'_EOS_': 1}))\n"]}]},{"cell_type":"markdown","source":["Запишем алгоритм подсчета n-грамм в виде функции `count_ngrams`. Она должна принимать на вход последовательность строк с токенами, разделенными пробелами (`lines`), и значение `n`, а возвращать словарь `counts`. Протестируем работу функции."],"metadata":{"id":"6yMNz0VcVY2s"}},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"og84gjipnumsakhiiu9ap","id":"H1_iwsUUeCXP"},"outputs":[],"source":["def count_ngrams(lines, n):\n","\n","    counts = defaultdict(Counter)\n","\n","    for l in lines:\n","        tok = l.split()\n","        tok.append(EOS)\n","        prefix = deque([UNK] * (n-1), maxlen=n-1)\n","        for t in tok:\n","            counts[tuple(prefix)][t] += 1\n","            prefix.append(t)\n","        counts[tuple(prefix)][t] += 1\n","\n","    return counts"]},{"cell_type":"markdown","source":["На 100 самых коротких текстах `example_lines` протестируем работу функции (`n=3`) и запишем результат в переменную `example_counts`."],"metadata":{"id":"FhQC0RRg6uJ8"}},{"cell_type":"code","source":["example_lines = sorted(lines, key=len)[:100]\n","example_counts = count_ngrams(example_lines, n=3)\n","assert len(example_counts[('_UNK_', '_UNK_')]) == 78\n","assert example_counts['_UNK_', 'a']['note'] == 3\n","assert example_counts['author', '.']['_EOS_'] == 1"],"metadata":{"id":"31H__FM96ZBE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["list(example_counts.items())[:10]"],"metadata":{"id":"JWMYNOd3XIxD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730470937782,"user_tz":-180,"elapsed":13,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"06a14256-b669-420e-8370-7429ed78bc83"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(('_UNK_', '_UNK_'),\n","  Counter({'differential': 1,\n","           'what': 1,\n","           'p=np': 1,\n","           'computational': 1,\n","           'weak': 1,\n","           'creating': 1,\n","           'defeasible': 1,\n","           'essence': 1,\n","           'deep': 1,\n","           'statistical': 1,\n","           'complex': 1,\n","           'serious': 1,\n","           'mining': 1,\n","           'preprocessing': 1,\n","           'liquid': 1,\n","           'towards': 1,\n","           'a': 13,\n","           'icon': 1,\n","           'recognition': 1,\n","           'glottochronologic': 1,\n","           'utility-probability': 1,\n","           'the': 3,\n","           'temporized': 1,\n","           'backpropagation': 1,\n","           'random': 1,\n","           'network': 1,\n","           'glottochronology': 1,\n","           'using': 2,\n","           'time': 1,\n","           'convolutional': 1,\n","           'fitness': 1,\n","           'flip-flop': 1,\n","           'autonomous': 1,\n","           'activitynet': 1,\n","           'text': 1,\n","           'decision': 1,\n","           'learning': 2,\n","           'discrimination': 1,\n","           'extraction': 1,\n","           'are': 1,\n","           'comments': 1,\n","           'automatic': 2,\n","           'resource': 1,\n","           'advances': 1,\n","           'quantified': 1,\n","           'norm-based': 1,\n","           'exploration': 1,\n","           'about': 1,\n","           'in': 1,\n","           'convex': 1,\n","           'introduction': 1,\n","           'some': 1,\n","           'unary': 1,\n","           'beyond': 1,\n","           'why': 2,\n","           'neurocontrol': 1,\n","           'on': 3,\n","           'philosophy': 1,\n","           'parallels': 1,\n","           'an': 1,\n","           'calculate': 1,\n","           'word': 1,\n","           'group': 1,\n","           'entropy': 1,\n","           'semistability-based': 1,\n","           'guarded': 1,\n","           'proceedings': 2,\n","           'cornell': 1,\n","           'attack': 1,\n","           'standardization': 1,\n","           'defensive': 1,\n","           'how': 1,\n","           'piecewise': 2,\n","           'approximated': 1,\n","           'technical': 1,\n","           'sat': 1,\n","           'solving': 1,\n","           'agent': 1})),\n"," (('_UNK_', 'differential'), Counter({'contrastive': 1})),\n"," (('differential', 'contrastive'), Counter({'divergence': 1})),\n"," (('contrastive', 'divergence'), Counter({';': 1})),\n"," (('divergence', ';'), Counter({'this': 1})),\n"," ((';', 'this'),\n","  Counter({'paper': 19,\n","           'is': 5,\n","           'article': 3,\n","           'preprint': 1,\n","           'abstract': 1,\n","           'submission': 2,\n","           'essay': 1,\n","           'short': 1,\n","           'chapter': 1,\n","           'sequential': 1,\n","           'manuscripts': 1})),\n"," (('this', 'paper'),\n","  Counter({'has': 14,\n","           'specifies': 1,\n","           'presents': 3,\n","           ',': 1,\n","           'we': 3,\n","           'describes': 1})),\n"," (('paper', 'has'), Counter({'been': 14})),\n"," (('has', 'been'), Counter({'retracted': 1, 'withdrawn': 16})),\n"," (('been', 'retracted'), Counter({'.': 1}))]"]},"metadata":{},"execution_count":8}]},{"cell_type":"markdown","metadata":{"cellId":"4j620npeqvj0k8ak8xqx8xk","id":"rMKNYhLteCXQ"},"source":["Как только мы научились считать $n$-граммы, можно построить вероятностную языковую модель. Самый простой способ вычисления вероятностей — пропорционально количеству:\n","\n","$$ P(w_t | prefix) = { count(prefix, w_t) \\over \\sum_{\\hat w} count(prefix, \\hat w) } $$\n","\n","Создадим класс `NGramLanguageModel`\n","\n","Конструктор класса `__init__`:\n","- принимает на вход `n` (количество рассматриваемых токенов в контексте) и `lines` (последовательность строк с токенами, разделенными пробелами)\n","- устанавливает атрибуты `n` и `probs` (словарь со структурой, аналогичной counts, но заполненный значениями вероятностей, а не количеством вхождений)\n","- при создании словаря `probs` в числителе должно быть количество вхождений для текущего слова `[word]` после заданного префикса `[words]`, а знаменателе — сумма `sum()` возможных значений `.values()` после заданного префикса `[words]`\n","\n","Метод `get_possible_next_tokens`:\n","- принимает на вход строку `prefix` с предшествующими (префиксными) токенами, разделенными пробелами\n","- возвращает словарь, где ключи — токены, значения — их вероятности\n","\n","Метод `get_next_token_prob`:\n","- принимает на вход строку `prefix` с предшествующими (префиксными) токенами, разделенными пробелами и следующий токен `next_token` для предсказания вероятности\n","- возвращает вероятность `P(next_token|prefix)`, $0 \\le  P \\le 1$"]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"c7cm76wmzlaa12bctznzei","id":"UcYWGiNteCXQ"},"outputs":[],"source":["class NGramLanguageModel:\n","    def __init__(self, lines, n):\n","\n","        assert n >= 1\n","        self.n = n\n","\n","        counts = count_ngrams(lines, self.n)\n","\n","        # probs[(word1, word2)][word3] = P(word3 | word1, word2)\n","        self.probs = defaultdict(Counter)\n","\n","        # self.probs заполняется вероятностями в диапазоне от 0 до 1\n","        for words in counts.keys():\n","            for word in counts[words].keys():\n","                self.probs[words][word] = counts[words][word]/sum(counts[words].values())\n","\n","    def get_possible_next_tokens(self, prefix):\n","\n","        prefix = prefix.split() # делим строку по пробелам\n","\n","        \"\"\"\n","        Оставляем только (n-1) последних токенов.\n","\n","        Пусть n = 3:\n","        prefix = [ w_0, w_1, w_2, w_3 ], len(prefix) = 4\n","        len(prefix) - n + 1 = 4 - 3 + 1 = 2 --> оставляем токены начиная с w_2\n","        prefix = [ w_0, w_1, w_2 ], len(prefix) = 3\n","        len(prefix) - n + 1 = 3 - 3 + 1 = 1 --> оставляем токены начиная с w_1\n","        prefix = [ w_0, w_1 ], len(prefix) = 2\n","        len(prefix) - n + 1 = 2 - 3 + 1 = 0 --> оставляем токены начиная с w_0\n","        prefix = [ w_0 ], len(prefix) = 1\n","        len(prefix) - n + 1 = 1 - 3 + 1 = -1 --> оставляем также токены начиная с w_0\n","        prefix = [ ], len(prefix) = 0\n","        len(prefix) - n + 1 = 0 - 3 + 1 = -2 --> оставляем пустой список\n","\n","        Если len(prefix) > (n-1), то len(prefix) - n + 1 > 0 --> берется (n-1) токенов\n","        Если len(prefix) <= (n-1), то len(prefix) - n + 1 <= 0 --> берутся все токены\n","\n","        Необходимо взять срез от prefix, нижняя граница — максимум из 0 и len(prefix) - n + 1\n","        \"\"\"\n","        prefix = prefix[max(0, len(prefix) - self.n + 1):]\n","\n","        \"\"\"\n","        Добавляем паддинг при необходимости. На этом этапе уже осталось (n-1) токенов.\n","\n","        Пусть n = 3:\n","        prefix = [], len(prefix) = 0\n","        [ UNK ] * (n - 1 - len(prefix)) + prefix = [ UNK ] * (3 - 1 - 0) + [] = [ UNK , UNK ]\n","        prefix = [ w_0 ], len(prefix) = 1\n","        [ UNK ] * (n - 1 - len(prefix)) + prefix = [ UNK ] * (3 - 1 - 1) + [ w_0 ] = [ UNK , w_0 ]\n","        prefix = [ w_0, w_1 ], len(prefix) = 2\n","        [ UNK ] * (n - 1 - len(prefix)) + prefix = [ UNK ] * (3 - 1 - 2) + [ w_0, w_1 ] = [ w_0, w_1 ]\n","        Если len(prefix) == 2, то 3 - 1 - 2 = 0 --> паддинг не добавляется\n","\n","        Необходимо умножить токен [ UNK ] на (n - 1 - len(prefix)) и прибавить префикс\n","        \"\"\"\n","        prefix = [ UNK ] * (self.n - 1 - len(prefix)) + prefix\n","\n","        return self.probs[tuple(prefix)]\n","\n","    def get_next_token_prob(self, prefix, next_token):\n","        return self.get_possible_next_tokens(prefix).get(next_token, 0)"]},{"cell_type":"markdown","metadata":{"cellId":"0ftnn4nmuzrup6c0vvhb8q","id":"dJDSRmD4eCXQ"},"source":["Создадим триграммную модель на основе 100 самых коротких текстов и протестируйте ее."]},{"cell_type":"code","source":["example_lm = NGramLanguageModel(example_lines, n=3)\n","assert example_lm.get_possible_next_tokens('')['a'] == 0.13\n","assert example_lm.get_possible_next_tokens('')['using'] == 0.02\n","assert round(sum(example_lm.get_possible_next_tokens('').values())) == 1"],"metadata":{"id":"lVR50lAqfzwW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_lm.get_possible_next_tokens('a')"],"metadata":{"id":"Cu-1xq6HodNI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730470938259,"user_tz":-180,"elapsed":7,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"369bdc78-1e72-4e1a-ea67-3e87c1c0dcab"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Counter({'notation': 0.07692307692307693,\n","         'note': 0.23076923076923078,\n","         'comment': 0.07692307692307693,\n","         'machine-learning': 0.07692307692307693,\n","         'theory': 0.07692307692307693,\n","         'survey': 0.07692307692307693,\n","         'history': 0.07692307692307693,\n","         'new': 0.07692307692307693,\n","         'machine': 0.07692307692307693,\n","         'remark': 0.07692307692307693,\n","         'primer': 0.07692307692307693})"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["assert round(example_lm.get_next_token_prob('a', 'note'), 2) == 0.23\n","assert round(example_lm.get_next_token_prob('a', 'study'), 2) == 0"],"metadata":{"id":"F-22CxhupZcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["example_lm.get_next_token_prob('a', 'note')"],"metadata":{"id":"dFkKJ6eVpq9S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730470938259,"user_tz":-180,"elapsed":5,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"6f74400f-c9c6-40bc-9696-34174245ef45"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.23076923076923078"]},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","metadata":{"cellId":"oh8r9a41kuk4r51wra9","id":"MRCDzpSNeCXR"},"source":["Обучим языковую модель на всем наборе данных и посмотрим, какие последовательности она может генерировать."]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"f17xoejjppmooo2nopw4xo","id":"POQdpQxGeCXR"},"outputs":[],"source":["lm = NGramLanguageModel(lines, n=3)"]},{"cell_type":"markdown","source":["Генерация осуществляется последовательно. Каждый следующий токен добавляется путем сэмплирования по вероятностям.\n","\n","$ X = [] $\n","\n","- $w_{next} \\sim P(w_{next} | X)$\n","- $X = concat(X, w_{next})$\n","\n","Вместо выборки с вероятностями можно также попробовать всегда брать наиболее вероятный токен, выборку из $K$ наиболее вероятных токенов или выборку с температурой. При сэмплировании с температурой выполняется выборка из\n","\n","$$w_{next} \\sim {P(w_{next} | X) ^ {1 / \\tau} \\over \\sum_{\\hat w} P(\\hat w | X) ^ {1 / \\tau}}$$\n","\n","где $τ>0$ — температура модели.\n","\n","Функция `get_next_token` принимает на вход префикс и значение температуры, возвращает следующий токен после префикса.\n","- если температура равна нулю:\n","  - сортируем возможные продолжения последовательности по возрастанию\n","  - берем последний элемент — наиболее вероятное продолжение\n","- если температура больше нуля:\n","  - создаем список `tokens` из всех возможных продолжений последовательности и список `probs` из их вероятностей\n","  - значения вероятностей возводятся в степень $1 / \\tau$ с помощью `np.power`, при этом в числителе вероятность конкретного токена, в знаменателе — сумма вероятностей всех токенов"],"metadata":{"id":"fQjj9JHz_nBM"}},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"sgbatlm9vzb4z889fho7","id":"3z52JlyReCXR"},"outputs":[],"source":["import numpy as np\n","\n","def get_next_token(lm, prefix, temperature=1.0):\n","\n","    if temperature == 0.:\n","        ptk = sorted (lm.get_possible_next_tokens(prefix), key = lm.get_possible_next_tokens(prefix).get)\n","        return ptk[-1]\n","    else:\n","        tokens = list(lm.get_possible_next_tokens(prefix).keys())\n","        probs = [ lm.get_next_token_prob(prefix, token) for token in tokens ]\n","        probs = np.power(probs, 1.0/temperature) / sum(np.power(probs, 1.0/temperature))\n","        return np.random.choice(np.array(tokens), p=probs)"]},{"cell_type":"markdown","source":["Сгенерируем 10000 продолжений для префикса *there have* и проверим, какие будут самыми частотными."],"metadata":{"id":"rlkMIdGft25h"}},{"cell_type":"code","source":["from collections import Counter\n","test_freqs = Counter([get_next_token(lm, 'there have') for _ in range(10000)])\n","print(test_freqs)\n","assert 250 < test_freqs['not'] < 450\n","assert 8500 < test_freqs['been'] < 9500\n","assert 1 < test_freqs['lately'] < 200"],"metadata":{"id":"AJTiIY0zA86a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730470994902,"user_tz":-180,"elapsed":1433,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"3ffd60e7-2fee-41a3-c1f8-67860eb1222f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Counter({'been': 9000, 'not': 396, 'only': 153, 'also': 153, 'very': 82, 'lately': 79, \"n't\": 71, 'occurred': 66})\n"]}]},{"cell_type":"markdown","source":["Сгенерируем 10000 продолжений для префикса *deep* и протестируем, какое продолжение предложит модель при разных значениях температуры: 1.0, 0.5, 0.0."],"metadata":{"id":"80gxi30Huhba"}},{"cell_type":"code","source":["test_freqs_t_1 = Counter([get_next_token(lm, 'deep', temperature=1.0) for _ in range(10000)])\n","assert 1500 < test_freqs_t_1['learning'] < 3000\n","print(f't=1.0: {test_freqs_t_1}')\n","\n","test_freqs_t_0_5 = Counter([get_next_token(lm, 'deep', temperature=0.5) for _ in range(10000)])\n","assert 8000 < test_freqs_t_0_5['learning'] < 9000\n","print(f't=0.5: {test_freqs_t_0_5}')\n","\n","test_freqs_t_0 = Counter([get_next_token(lm, 'deep', temperature=0.0) for _ in range(10000)])\n","assert test_freqs_t_0['learning'] == 10000\n","print(f't=0.0: {test_freqs_t_0}')"],"metadata":{"id":"Fu9uVAjjtpCz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730471013316,"user_tz":-180,"elapsed":18416,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"1fbcc815-6f0b-4706-86a3-d8b742556071"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["t=1.0: Counter({'learning': 2244, 'reinforcement': 515, 'convolutional': 435, 'neural': 387, 'feature': 120, 'residual': 120, 'image': 118, 'metric': 105, 'recurrent': 104, 'generative': 95, 'unsupervised': 92, 'semantic': 79, 'gaussian': 79, 'multimodal': 71, 'structured': 69, 'networks': 68, 'architectures': 61, 'spatial': 59, 'belief': 57, 'learning-based': 55, 'speaker': 54, 'predictive': 54, 'hashing': 53, 'self-taught': 52, 'network': 52, 'transform': 52, 'multi-view': 51, 'adaptive': 49, 'supervision': 48, 'tracking': 44, 'joint': 42, 'bayesian': 42, 'active': 42, 'supervised': 41, 'transfer': 41, 'video': 39, 'cnn': 38, 'models': 38, 'visual': 38, 'speech': 36, 'clustering': 36, 'matching': 35, 'cross': 33, 'multi-instance': 33, 'interactive': 33, 'exploration': 33, 'depth': 32, 'voice': 32, 'linear': 31, 'multi-scale': 31, 'episodic': 31, 'representation': 30, 'directed': 30, 'local': 30, 'spatio-temporal': 30, 'embedding': 29, 'sparse': 29, 'domain': 29, 'blind': 28, 'api': 28, 'echo': 27, 'multi-task': 26, 'multitask': 25, 'structure': 24, 'collaborative': 24, 'face': 23, 'online': 23, 'and': 23, 'temporal': 22, 'information': 22, ',': 22, 'fruit': 22, 'tensor': 22, 'regionlets': 20, 'component': 20, 'lstm': 20, 'forward': 20, 'variational': 20, 'rewiring': 20, 'investigation': 19, 'motion': 19, 'epitomic': 19, 'inside': 19, 'koalarization': 19, 'edge-aware': 19, 'attention': 19, 'thermal': 19, 'layer': 18, 'style': 18, 'reflectance': 18, 'generalized': 18, 'manta': 18, 'affordance-grounded': 18, 'attribute': 18, 'back-projection': 18, 'burst': 18, 'primal-dual': 18, 'adversarial': 18, 'interest': 18, 'end2end': 18, 'fishernet': 17, 'action': 17, 'extreme': 17, 'fragment': 17, 'scattering': 17, 'bidirectional': 17, 'pyramidal': 17, 'coral': 17, 'driven': 17, 'regression': 17, 'multi-frame': 17, 'character-level': 17, 'motif': 17, 'reservoir': 17, 'karaoke': 17, 'multi-modal': 17, 'alignment': 17, 'bilateral': 16, 'semi-random': 16, 'anticipation': 16, 'multi-camera': 16, 'chain': 16, 'kernel': 16, 'stereo': 16, 'keyphrase': 16, 'frame': 16, 'roto-translation': 16, 'memory': 16, 'action-': 16, 'multi-fidelity': 15, 'hidden': 15, 'haar': 15, 'deformable': 15, 'binaries': 15, 'retinal': 15, 'lesion': 15, 'lda-pruned': 15, 'scene': 15, 'within-class': 15, 'label': 15, 'perceptual': 15, 'sliding': 15, 'endovo': 15, 'poincare': 15, 'value': 15, 'cocktail': 15, 'detection': 15, 'super': 15, 'de-aliasing': 15, 'cnns': 15, 'person': 15, 'direct': 14, 'contextual': 14, 'disentangled': 14, 'stacked': 14, 'uq': 14, 'inception-residual': 14, '3d': 14, 'robust': 14, 'lattice': 14, 'epitome': 14, 'boltzmann': 14, 'contextualized': 14, 'trans-layer': 14, '&': 14, 'functional': 14, 'discrete': 14, 'quality': 14, 'fried': 14, 'lambertian': 14, 'rotation': 14, 'exemplar': 14, 'fusion': 14, 'view': 14, 'k-nearest': 14, 'long': 14, 'cropping': 14, 'grabcut': 14, 'co-space': 14, 'canonically': 13, 'fault': 13, 'multiple': 13, 'multi-species': 13, 'identity-aware': 13, 'kernelized': 13, 'binary': 13, 'view-sensitive': 13, 'mean-shift': 13, 'steering': 13, 'over-sampling': 13, 'spiking': 13, 'aesthetic': 13, 'kinematic': 13, 'encoding': 13, 'projective': 13, 'in-gpu': 13, 'boosting': 13, 'double': 13, 'biaffine': 13, 'pose': 13, 'incremental': 13, 'inference': 13, 'autoencoders': 13, 'triphone': 13, 'mimo': 12, 'logismos': 12, 'unfolding': 12, 'private-feature': 12, 'transductive': 12, 'd-bar': 12, 'optical': 12, 'successor': 12, 'impression': 12, 'asymmetric': 12, 'feelings': 12, 'meta-learning': 12, '6-dof': 12, 'sentence': 12, 'galaxy': 12, 'mr': 12, 'representations': 12, 'amortized': 12, 'forest': 12, 'head': 12, 'watershed': 12, 'learning-guided': 12, 'ctr': 12, 'function': 12, 'feed-forward': 12, 'q-learning': 12, 'roots': 12, 'haptic': 12, 'manifold': 12, 'patch': 12, 'co-training': 11, 'poisson': 11, 'sets': 11, 'object-centric': 11, 'saliency': 11, 'fishing': 11, 'deterministic': 11, 'variation-structured': 11, 'diagnostics': 11, 'bcd-net': 11, 'broad': 11, 'artifact': 11, 'laplacian': 11, 'visual-semantic': 11, 'prior': 11, 'gradient': 11, 'fisher': 11, 'expander': 11, 'poselets': 11, 'semi-supervised': 11, 'mixture': 11, 'spectral': 11, 'versus': 11, 'temporal-recurrent-replicated-softmax': 11, 'relative': 11, 'abstract': 11, 'outdoor': 11, 'hybrid': 11, 'manifold-to-manifold': 11, 'choice': 10, 'vs.': 10, 'automated': 10, 'semantics-aware': 10, 'deconvolutional': 10, 'multi-spectral': 10, 'tamer': 10, 'word': 10, 'sketch': 10, 'descriptor': 10, 'narrow': 10, 'filter': 10, 'crisp': 10, 'decentralized': 10, 'attributes': 10, 'heterogeneous': 10, 'control': 10, 'health': 10, 'knowledge': 10, 'nearest': 10, 'activity': 10, 'captioning': 10, 'self-paced': 10, 'net': 10, 'stacking': 10, 'survival': 10, 'probabilistic': 9, 'cuboid': 9, 'continuous': 9, 'nonparametric': 9, 'secure': 9, 'class': 9, 'meta': 9, 'hyperspherical': 9, 'reconstruction-classification': 9, 'ranking': 8, 'latent': 8, 'dictionary': 8, 'mixtures': 8, 'fully-connected': 8, 'photo': 8, 'ehr': 8, 'generative-contrastive': 8, 'gate': 8, 'counterfactual': 8, 'ten': 7, 'mutual': 7, 'class-wise': 7, 'quantization': 7, 'optimization': 7, 'hyperalignment': 7, 'graph': 7, 'region': 6, 'subspace': 6, 'convolution': 6, 'competitive': 6, 'occlusion': 6, 'factorization': 6, 'markov': 5, 'ordinal': 5, 'mean': 4})\n","t=0.5: Counter({'learning': 8680, 'reinforcement': 406, 'convolutional': 318, 'neural': 246, 'residual': 29, 'image': 28, 'feature': 28, 'recurrent': 15, 'semantic': 13, 'generative': 12, 'unsupervised': 11, 'metric': 10, 'networks': 10, 'structured': 9, 'multimodal': 8, 'gaussian': 8, 'speaker': 6, 'transfer': 6, 'joint': 5, 'cnn': 4, 'network': 4, 'predictive': 4, 'spatial': 4, 'transform': 4, 'belief': 4, 'models': 4, 'video': 4, 'online': 4, 'multitask': 3, 'linear': 3, 'voice': 3, 'architectures': 3, 'multi-view': 3, 'face': 2, 'learning-based': 2, 'tracking': 2, 'multi-scale': 2, 'clustering': 2, 'galaxy': 2, 'matching': 2, 'and': 2, 'directed': 2, 'visual': 2, 'generative-contrastive': 2, 'asymmetric': 2, 'temporal': 2, 'echo': 2, 'supervision': 2, 'view-sensitive': 2, 'boltzmann': 1, 'over-sampling': 1, 'api': 1, 'reservoir': 1, 'exploration': 1, '6-dof': 1, 'feed-forward': 1, 'investigation': 1, 'latent': 1, 'view': 1, 'semantics-aware': 1, 'spatio-temporal': 1, 'value': 1, 'occlusion': 1, 'supervised': 1, 'kernel': 1, 'canonically': 1, 'transductive': 1, 'contextualized': 1, 'long': 1, 'discrete': 1, 'multi-spectral': 1, 'lesion': 1, 'cocktail': 1, 'retinal': 1, 'embedding': 1, 'epitomic': 1, 'mr': 1, 'speech': 1, 'lstm': 1, 'adversarial': 1, 'edge-aware': 1, 'dictionary': 1, 'lattice': 1, 'deformable': 1, 'fishing': 1, 'blind': 1, 'karaoke': 1, 'interactive': 1, 'decentralized': 1, 'representation': 1, 'hashing': 1, 'information': 1, 'd-bar': 1, 'bayesian': 1, 'automated': 1, 'roto-translation': 1, 'stereo': 1, 'within-class': 1, 'local': 1, 'abstract': 1, 'control': 1, 'exemplar': 1, 'burst': 1, 'logismos': 1, 'kinematic': 1, 'fisher': 1, 'multiple': 1, 'alignment': 1, 'domain': 1, 'variational': 1, 'depth': 1, 'crisp': 1, 'cross': 1, 'deterministic': 1, 'robust': 1, 'nearest': 1, 'net': 1, 'perceptual': 1})\n","t=0.0: Counter({'learning': 10000})\n"]}]},{"cell_type":"markdown","metadata":{"cellId":"ux4n8iq523n4s3ftrelhxj","id":"pwcsKFCheCXR"},"source":["Протестируем, что сгенерирует модель при различных префиксах."]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"1nnnycga61rijt6nd8zai","id":"WMv8UCvqeCXR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730471013679,"user_tz":-180,"elapsed":365,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"59ebbc11-9664-437d-aeff-5884a2d6f1f0"},"outputs":[{"output_type":"stream","name":"stdout","text":["artificial intelligence should build cognitive-level and neural- level models . in addition , we leverage the recent introduction of the proposed approach is effective in offline handwriting competitions , the following two consecutive frames . during training and generates the target risk in deep learning based detection pipeline for automated person re-identification is the data , with a survey ; computational results for qualitative decision making , essentially , this noise while preserving the validity and potential overfitting while cost-sensitive methods aimed at determining the network . we consider two types of region predictions and more versatile policy that is able\n"]}],"source":["prefix = 'artificial'\n","\n","for i in range(100):\n","    prefix += ' ' + get_next_token(lm, prefix)\n","    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n","        break\n","\n","print(prefix)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"pxyjsv3b7r8thdfxlgitl","id":"D9Z7-g4peCXR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730471014043,"user_tz":-180,"elapsed":365,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"844c57d7-7206-427d-ccf6-292d532c19c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["bridging the gap between the two domains . our approach is that it is the most commonly used in the number of filter parameters . we show that the proposed method is based on the manifold structure of the time complexity of the proposed method is a challenging problem . in this paper , we show that the proposed method is proposed to solve the proposed method is based on the basis of the proposed approach is based on the mnist dataset . _EOS_\n"]}],"source":["prefix = 'bridging the'\n","\n","for i in range(100):\n","    prefix += ' ' + get_next_token(lm, prefix, temperature=0.5)\n","    if prefix.endswith(EOS) or len(lm.get_possible_next_tokens(prefix)) == 0:\n","        break\n","\n","print(prefix)"]},{"cell_type":"markdown","source":["### Оценка языковой модели"],"metadata":{"id":"8P7pDDlDBmeI"}},{"cell_type":"markdown","source":["Для оценки языковых моделей используется перплексия. Она показывает, насколько хорошо модель аппроксимирует истинное распределение вероятностей, лежащее в основе данных. Чем меньше перплексия, тем лучше модель.\n","\n","Расчет перплексии для предложения:\n","$$\n","    {\\mathbb{P}}(w_1 \\dots w_N) = P(w_1, \\dots, w_N)^{-\\frac1N} = \\left( \\prod_t P(w_t \\mid w_{t - n}, \\dots, w_{t - 1})\\right)^{-\\frac1N},\n","$$\n"],"metadata":{"id":"ApJsIhBUBqe5"}},{"cell_type":"markdown","source":["На уровне корпуса, перплексия — это произведение вероятностей всех токенов во всех предложениях в степени $1/N$ , где $N$ — общая длина (в токенах) всех предложений в корпусе.\n","\n","Получившееся число может быстро стать слишком маленьким, поэтому сначала вычисляется логарифмическая перплексия (на основе логарифмических вероятностей), а затем берется экспонента."],"metadata":{"id":"OmXEkHwZCC3P"}},{"cell_type":"markdown","source":["Функция `perplexity` принимает на вход список строк с токенами, разделенными пробелами (`lines`) и минимальную логарифмическую вероятность (`min_logprob`): если $log(P(w | ...))$ меньше, чем `min_logprop`, логариф вероятности приравнивается к `min_logprob`. Функция возвращает значение перплексии на уровне корпуса."],"metadata":{"id":"bCDrW_sZChTc"}},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"5hp010xyzzb4vqewo1bhny","id":"9Jv8M0U3eCXS"},"outputs":[],"source":["def perplexity(lm, lines, min_logprob=np.log(10 ** -50.)):\n","    perplexity = 0.0\n","    n = 0\n","    for line in lines:\n","        l_line = line.split()\n","\n","        for k, tok_pref in enumerate(l_line):\n","            # Пусть lm.n = 3, l_line = [ w_0, w_1, w_2, w_3, w_4]\n","            if k == 0:\n","                \"\"\"\n","                Первый токен : префикс пуст\n","                k = 0 --> вероятность w_0 в начале предложения\n","                \"\"\"\n","                perplexity += np.maximum(np.log(lm.get_next_token_prob('', tok_pref)), min_logprob)\n","                n += 1\n","            elif (k > 0) and (k < lm.n):\n","                \"\"\"\n","                k = 1 --> вероятность w_1 после [ w_0 ]\n","                k = 2 --> вероятность w_2 после [ w_0, w_1 ]\n","                \"\"\"\n","                perplexity += np.maximum(np.log(lm.get_next_token_prob(' '.join(l_line[:k]), tok_pref)), min_logprob)\n","                n += 1\n","            else:\n","                \"\"\"\n","                k = 3 --> вероятность w_3 после [ w_1, w_2 ]\n","                k = 4 --> вероятность w_4 после [ w_2, w_3 ]\n","                \"\"\"\n","                perplexity += np.maximum(np.log(lm.get_next_token_prob(' '.join(l_line[k-lm.n+1:k]), tok_pref)), min_logprob)\n","                n += 1\n","\n","            \"\"\"\n","            Для последнего токена в строке добавляется логарифмическая вероятность токена EOS\n","            Вероятность EOS после [ w_3, w_4 ]\n","            \"\"\"\n","            if k == (len(l_line) - 1) :\n","                perplexity += np.maximum(np.log(lm.get_next_token_prob(' '.join(l_line[k-lm.n+2:k+1]), EOS)), min_logprob)\n","                n += 1\n","    # делим сумму логарифмических вероятностей на количество токенов\n","    perplexity = perplexity/n\n","    return np.exp(-perplexity)"]},{"cell_type":"markdown","source":["Создадим языковые модели из предложений в `example_lines` при `n=1`, `n=3`, `n=10`. Посчитаем перплексию для них."],"metadata":{"id":"k_I6WyJ_hkg7"}},{"cell_type":"code","source":["import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","lm1 = NGramLanguageModel(example_lines, n=1)\n","lm3 = NGramLanguageModel(example_lines, n=3)\n","lm10 = NGramLanguageModel(example_lines, n=10)\n","\n","ppx1 = perplexity(lm1, example_lines)\n","ppx3 = perplexity(lm3, example_lines)\n","ppx10 = perplexity(lm10, example_lines)\n","\n","print(f\"Perplexities: ppx1={round(ppx1,2)} ppx3={round(ppx3,2)} ppx10={round(ppx10,2)}\")\n","\n","assert all(0 < ppx < 500 for ppx in (ppx1, ppx3, ppx10))\n","assert ppx1 > ppx3 > ppx10"],"metadata":{"id":"gohbmm9Ob8zh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730471014420,"user_tz":-180,"elapsed":380,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"a5babba4-d6d4-4b01-93b5-517eb6190659"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Perplexities: ppx1=314.13 ppx3=1.53 ppx10=1.19\n"]}]},{"cell_type":"markdown","metadata":{"cellId":"ypc4lks4vs1li908fqi8","id":"CyZPxNi1eCXS"},"source":["Разделим все данные на обучающую и тестовую выборку, оценим модель только на тестовых данных."]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"tjnehsem2lmijkg2lto4w","id":"aEEjjTT2eCXS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730471238967,"user_tz":-180,"elapsed":224549,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"0e3a3a08-2865-4b4b-ece8-8aa3c809b29b"},"outputs":[{"output_type":"stream","name":"stdout","text":["N = 1, Perplexity = 3554\n","N = 2, Perplexity = 705747101\n","N = 3, Perplexity = 1093822849646206375690240\n"]}],"source":["from sklearn.model_selection import train_test_split\n","train_lines, test_lines = train_test_split(lines, test_size=0.25, random_state=42)\n","\n","for n in (1, 2, 3):\n","    lm = NGramLanguageModel(n=n, lines=train_lines)\n","    ppx = perplexity(lm, test_lines)\n","    print(f\"N = {n}, Perplexity = {round(ppx)}\")"]},{"cell_type":"markdown","source":["### Cглаживание"],"metadata":{"id":"FQP98_fKD48R"}},{"cell_type":"markdown","source":["Проблема с нашей простой языковой моделью заключается в том, что всякий раз, когда она сталкивается с *n*-граммой, которую она никогда раньше не видела, она присваивает ей вероятность, равную 0. Каждый раз, когда это происходит, значение преплексии сильно возрастает.\n","\n","Реализуем аддитивное сглаживание или сглаживание Лапласа. Если значения для префикса невелики, сглаживание приведет к более равномерному распределению вероятностей.\n","\n","$$ P(w_t | prefix) = { Count(prefix, w_t) + \\delta \\over \\sum_{\\hat w} (Count(prefix, \\hat w) + \\delta) } $$"],"metadata":{"id":"JAO4-1glD9Ls"}},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"ioh26rlov6g8l2ssj1c8pm","id":"duTdn6O4eCXT"},"outputs":[],"source":["class LaplaceLanguageModel(NGramLanguageModel):\n","    def __init__(self, lines, n, delta=1.0):\n","        self.n = n\n","        counts = count_ngrams(lines, self.n)\n","        self.vocab = set(token for token_counts in counts.values() for token in token_counts)\n","        self.probs = defaultdict(Counter)\n","\n","        for prefix in counts:\n","            token_counts = counts[prefix]\n","            total_count = sum(token_counts.values()) + delta * len(self.vocab)\n","            self.probs[prefix] = {token: (token_counts[token] + delta) / total_count\n","                                          for token in token_counts}\n","    def get_possible_next_tokens(self, prefix):\n","        token_probs = super().get_possible_next_tokens(prefix)\n","        print(f'sum: {sum(token_probs.values())}')\n","        print(f'len: {len(token_probs)}')\n","        missing_prob_total = 1.0 - sum(token_probs.values())\n","        missing_prob = missing_prob_total / max(1, len(self.vocab) - len(token_probs))\n","        return {token: token_probs.get(token, missing_prob) for token in self.vocab}\n","\n","    def get_next_token_prob(self, prefix, next_token):\n","        token_probs = super().get_possible_next_tokens(prefix)\n","        if next_token in token_probs:\n","            return token_probs[next_token]\n","        else:\n","            missing_prob_total = 1.0 - sum(token_probs.values())\n","            missing_prob_total = max(0, missing_prob_total)\n","            return missing_prob_total / max(1, len(self.vocab) - len(token_probs))"]},{"cell_type":"code","execution_count":null,"metadata":{"cellId":"j6zqa50koitjjri9ipd8ec","id":"BTE-QrJweCXU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1730471420045,"user_tz":-180,"elapsed":181081,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"f7655cf8-dee8-4103-ec34-8b2087cc5dae"},"outputs":[{"output_type":"stream","name":"stdout","text":["N = 1, Perplexity = 3556.523568890437\n","N = 2, Perplexity = 672.6773023801779\n","N = 3, Perplexity = 6501.226166225803\n"]}],"source":["for n in (1, 2, 3):\n","    lm = LaplaceLanguageModel(train_lines, n=n, delta=0.1)\n","    ppx = perplexity(lm, test_lines)\n","    print(f\"N = {n}, Perplexity = {ppx}\")"]},{"cell_type":"markdown","source":["## Нейросетевые языковые модели"],"metadata":{"id":"yXETL_wE70G1"}},{"cell_type":"markdown","source":["Мы рассмотрели, как можно построить счетные (*n*-граммные) языковые модели. Их основной недостаток в том, что они не способны учитывать длинный контекст предложения и генерировать связный текст.\n","\n","С этими проблемами справляются языковые модели на основе нейронных сетей. Мы рассмотрим архитектуру рекуррентных нейронных сетей и построим с помощью них языковую модель."],"metadata":{"id":"-TyIhU5W76RE"}},{"cell_type":"markdown","source":["### Рекуррентные нейронные сети"],"metadata":{"id":"bcA1N4Iz8t5b"}},{"cell_type":"markdown","source":["**Рекуррентные нейронные сети (recurrent neural networks, RNN)** — это класс нейронных сетей, которые применяются для обработки последовательных данных."],"metadata":{"id":"oKEP6URL897M"}},{"cell_type":"markdown","source":["Каждое слово $x_t$ в предложении последовательно обрабатывается с помощью **ячейки RNN**."],"metadata":{"id":"S29ikHkIm7X2"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.ibb.co/f0hvFdv/RNN-cell.png\" width=\"850\"></center>"],"metadata":{"id":"y7SKJNLMBc7P"}},{"cell_type":"markdown","source":["1. На вход ячейки поступает входной вектор $x_t$ —  эмбеддинг слова с индексом $t$. Он имеет фиксированный размер $k$.\n","\n","2. Ячейка принимает еще один параметр $h_{t-1}$ — **скрытое состояние** или **память** (hidden state). Это вектор, хранящий информацию о предшествующем контексте. Он тоже имеет фиксированный размер $n$.\n","\n","3. Вектор $x_t$ умножается на матрицу $W^{nk}$ (размер $n \\times k$), которая содержит обучаемые веса: $W^{nk} \\cdot x_t$. Получаем новый вектор размера $n$.\n","\n","4. Вектор $h_{t-1}$ умножается на другую матрицу весов $W^{nn}$ (размер $n \\times n$): $ W^{nn} \\cdot h_{t-1} $. Получаем новый вектор размера $n$.\n","\n","5. Получившиеся векторы имеют одинаковый размер, их можно сложить: $W^{nk} \\cdot x_t + W^{nn} \\cdot h_{t-1}$.\n","\n","6. К получившемуся вектору применим функцию активации — гиперболический тангенс: $tanh(W^{nk} \\cdot x_t + W^{nn} \\cdot h_{t-1})$. Это и будет новым скрытым состоянием $h_t$. Оно зависит от предыдущего состояния $h_{t-1}$ и текущего элемента последовательности $x_t$.\n","\n","7. Рассчитанное скрытое состояние $h_t$ является представлением текущего слова $x_t$ с учетом предшествующего контекста и передается в качестве старого скрытого состояния для следующего слова $x_{t+1}$."],"metadata":{"id":"_f-tGBizKKqS"}},{"cell_type":"markdown","source":["Воспользуемся реализацией ячейки [RNNCell](https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html) из pytorch."],"metadata":{"id":"BSEmtO4jl9Rs"}},{"cell_type":"code","source":["import torch\n","x = torch.randn(5) # вектор 1 слова из 5 признаков\n","print(f\"Входные данные: {x}\")\n","print(f\"Размер входных данных: {x.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AAgxpENQ9s-V","executionInfo":{"status":"ok","timestamp":1730819474701,"user_tz":-180,"elapsed":8902,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"bf6f4b67-12f3-4b5d-92c1-5c85ad11426d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Входные данные: tensor([-0.0253, -0.3711,  0.3109,  0.7286, -0.0361])\n","Размер входных данных: torch.Size([5])\n"]}]},{"cell_type":"code","source":["from torch import nn\n","torch_rnn_cell = nn.RNNCell(input_size=5, hidden_size=3)\n","h = torch_rnn_cell(x)\n","print(f\"Выходные данные {h}\")\n","print(f\"Размер выходных данных: {h.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oosh6SQ-k6MM","executionInfo":{"status":"ok","timestamp":1730819474702,"user_tz":-180,"elapsed":9,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"618a944a-71e1-4a82-c256-d31156750e74"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Выходные данные tensor([ 0.3273, -0.0566,  0.2092], grad_fn=<SqueezeBackward1>)\n","Размер выходных данных: torch.Size([3])\n"]}]},{"cell_type":"markdown","source":["Для обработки всей последовательности слов используется **слой RNN**, где ячейка применяется ко всем словам в цикле."],"metadata":{"id":"Dfhx0soPnGgm"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.ibb.co/GdjZth0/RNN-layer.png\" width=\"700\"></center>"],"metadata":{"id":"0f9bmrarBfgF"}},{"cell_type":"markdown","source":["Когда первый токен $x_0$ подается в ячейку, вектор памяти $h$ инициализируется нулями.\n","\n","Вектор памяти $h_0$ для первого токена $x_0$ передается в следующую ячейку, обрабатывающую второй токен $x_1$. Вектор $h_0$ также является контекстуализированным представлением токена $x_0$ — $y_0$.\n","\n","Для каждого последующего токена вектор памяти учитывает контекст из предыдущих токенов.\n","\n","Вектор $y_t$ является не только контекстуализированным представлением для последнего токена $x_t$, но и вектором всего предложения, т.к. содержит информацию обо всех токенах.\n","\n","В зависимости от типа задачи, можно использовать контекстуализированные векторы для каждого слова или только вектор всего предложения (последнего слова)."],"metadata":{"id":"q8vDA64YohLe"}},{"cell_type":"markdown","source":["Воспользуемся реализацией слоя [RNN](https://pytorch.org/docs/stable/generated/torch.nn.RNN.html) из pytorch."],"metadata":{"id":"sTq5ZC6gB2h1"}},{"cell_type":"code","source":["sequence = torch.randn(7, 5) # предложение из 7 токенов, у каждого 5 признаков\n","print(f\"Входные данные:\\n{sequence}\")\n","print(f\"Размер входных данных: {sequence.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0j4jPrFj-Jit","executionInfo":{"status":"ok","timestamp":1730819474702,"user_tz":-180,"elapsed":8,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"c495f0e0-73fc-4edc-e30e-22a24f17d98c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Входные данные:\n","tensor([[ 0.5785,  1.4128,  0.3468,  1.1992,  1.7979],\n","        [-0.1982,  0.3873,  1.1349,  1.6403,  0.1491],\n","        [-0.0102,  0.3961, -0.6132, -0.9026, -0.8193],\n","        [-0.9428,  0.2935,  0.4956, -1.8031,  0.1023],\n","        [ 0.5312,  0.6822,  0.5978,  0.1030, -1.4203],\n","        [ 0.6724, -0.3372, -0.2183,  0.9684, -0.4364],\n","        [-1.4367,  0.6834, -0.1960,  1.2008, -0.0628]])\n","Размер входных данных: torch.Size([7, 5])\n"]}]},{"cell_type":"code","source":["rnn = nn.RNN(input_size=5, hidden_size=3)\n","out, h = rnn(sequence)\n","\n","print(f\"Выходные данные:\\n{out}\")\n","print(f\"Размер выходных данных: {out.shape}\\n\")\n","\n","print(f\"Вектор предложения: {h}\")\n","print(f\"Размер вектора предложения: {h.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZGRpFTyJAaFW","executionInfo":{"status":"ok","timestamp":1730819474702,"user_tz":-180,"elapsed":7,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"943bd1db-1b95-4a12-d2d4-b16ef9f2ebbd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Выходные данные:\n","tensor([[-0.7030, -0.7894,  0.9831],\n","        [-0.6431, -0.9292,  0.8754],\n","        [-0.0469,  0.0788, -0.3941],\n","        [ 0.9064, -0.6591, -0.3592],\n","        [ 0.4910, -0.9191, -0.4067],\n","        [-0.6784, -0.9573,  0.2473],\n","        [-0.7664, -0.8460,  0.9340]], grad_fn=<SqueezeBackward1>)\n","Размер выходных данных: torch.Size([7, 3])\n","\n","Вектор предложения: tensor([[-0.7664, -0.8460,  0.9340]], grad_fn=<SqueezeBackward1>)\n","Размер вектора предложения: torch.Size([1, 3])\n"]}]},{"cell_type":"markdown","source":["### Алгоритм обратного распространения ошибки сквозь время"],"metadata":{"id":"hOAX39T6aF9C"}},{"cell_type":"markdown","source":["Обучение RNN аналогично обучению обычной нейронной сети. Мы также используем алгоритм обратного распространения ошибки (backpropagation), но с небольшим изменением.\n","\n","Градиент на каждом выходе зависит не только от расчетов текущего шага, но и от предыдущих временных шагов. Вектор памяти для $h_3$ зависит от вектора памяти $h_2$, $h_1$ и $h_0$. Следовательно, чтобы вычислить градиент для $h_3$, нужно распространить ошибку на 3 шага и суммировать градиенты.\n","\n","Этот алгоритм называется «алгоритмом обратного распространения ошибки сквозь время» (Backpropagation Through Time, BPTT)."],"metadata":{"id":"j90M1rdfaPoY"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.postimg.cc/RV29LpvM/bptt.png\" width=\"400\"></center>"],"metadata":{"id":"NDCcIVfwmYaJ"}},{"cell_type":"markdown","source":["$$\\frac{\\partial L}{\\partial W} = \\sum\\limits_{i=0}^t\\frac{\\partial L_i}{\\partial W}$$\n","$$\\frac{\\partial L_t}{\\partial W} = \\frac{\\partial L_t}{\\partial \\hat y} \\frac{\\partial \\hat y}{\\partial h_t} \\frac{\\partial h_t}{\\partial W} $$\n","\n","$$h_t = tanh(Vx_t + Wh_{t-1})$$\n","\n","$$\\frac{\\partial L_t}{\\partial W} = \\frac{\\partial L_t}{\\partial \\hat y_t} \\frac{\\partial \\hat y_t}{\\partial h_t} (\\frac{\\partial h_t}{\\partial W} + \\frac{\\partial h_t}{\\partial h_{t-1}} \\frac{\\partial h_{t-1}}{\\partial W} + \\cdots)  = \\frac{\\partial L_t}{\\partial \\hat y_t} \\frac{\\partial \\hat y_t}{\\partial h_t}\\sum\\limits_{k=0}^t (\\prod\\limits_{i = k+1}^t \\frac{\\partial h_i}{\\partial h_{i-1}}) \\frac{\\partial h_k}{\\partial W}$$"],"metadata":{"id":"UaW4R7ROxxOK"}},{"cell_type":"markdown","source":["$\\large \\| \\frac{\\partial h_i}{\\partial h_{i-1}} \\| \\lt 1 $ — затухающий градиент (vanishing gradient)\n","\n","$\\large \\| \\frac{\\partial h_i}{\\partial h_{i-1}} \\| \\gt 1 $ — взрывающийся градиент (exploding gradient)"],"metadata":{"id":"jiPKRNCl2Ouq"}},{"cell_type":"markdown","source":["Борьба с взрывающимся градиентом — **градиентное отсечение** (gradient clipping) — метод, который ограничивает максимально допустимое значение градиента, позволяя избежать градиентного взрыва."],"metadata":{"id":"bBK8FUgjwbKi"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.postimg.cc/zvD4qK52/gradient-clipping.png\" width=\"600\"></center>"],"metadata":{"id":"ru0n0Qj9mBgL"}},{"cell_type":"markdown","source":["От затухания и взрыва градиента может помочь **пропускание градиента по частям** (truncated gradient) на сколько-то шагов по времени назад, а не через всю нейросеть."],"metadata":{"id":"7IbvCMAb49od"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.postimg.cc/J7dps9Qz/truncated-gradient.png\" width=\"800\"></center>"],"metadata":{"id":"ueZoyufYmQ1Z"}},{"cell_type":"markdown","source":["Минусы классических рекуррентных сетей:\n","- информация о начальных словах затухает к концу предложения\n","- затухающие и взрывающиеся градиенты\n"],"metadata":{"id":"0OeSMKGGbsCg"}},{"cell_type":"markdown","source":["### Сети долгой краткосрочной памяти"],"metadata":{"id":"w7i8MIQAaIit"}},{"cell_type":"markdown","source":["В обычной RNN в ячейке был только один путь передачи информации. На каждом шаге мы складывали информацию, накопленную с предыдущих шагов, с текущей. При этом информация о предыдущих токенах быстро затухает, и теряется общая информация о предложении.\n","\n","Эта проблема были решена в сети долгой краткосрочной памяти (Long short-term memory, LSTM). Структура ячейки LSTM намного сложнее. Здесь есть целых 4 линейных слоя, каждый из которых выполняет разные задачи.\n","\n","Главное нововведение: в LSTM добавлено состояние $c_t$, которое должно сохранять общий контекст. Помогает нейросети сохранять важную информацию, встретившуюся в какой-то момент в предложении, все время, пока эта информация требуется."],"metadata":{"id":"D0bL_DlP4gzH"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.ibb.co/hfxC7SF/RNN-LSTM.png\" width=\"650\"></center>"],"metadata":{"id":"L2s6QzxKBioP"}},{"cell_type":"markdown","source":["Рассмотрим подробно структуру ячейки LSTM."],"metadata":{"id":"G9_NaJrBlAy-"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.ibb.co/tDmV7X3/LSTM1.png\" width=\"700\"></center>\n","<center><img src =\"https://i.ibb.co/b3H19Kp/LSTM2.png\" width=\"500\"></center>"],"metadata":{"id":"MWC57NMNBjeI"}},{"cell_type":"markdown","source":["$h_{t-1}$ — вектор краткосрочной памяти для предшествующего контекста;\n","\n","$c_{t-1}$ — вектор долгой памяти для предшествующего контекста;\n","\n","$x_t$ — вектор текущего токена;\n","\n","$h_t$ — вектор краткосрочной памяти для контекста с учетом текущего токена;\n","\n","$c_t$ — вектор долгой памяти для контекста с учетом текущего токена;\n","\n","$W_f, W_i, W_c, W_o$ — матрицы параметров;\n","\n","$σ,\\;tanh$ — функции активации."],"metadata":{"id":"KwdmU1udjcjt"}},{"cell_type":"markdown","source":["$ f_t = σ(W_f \\cdot [h_{t-1}, x_t])$ — вентиль забывания (forget gate), вес забывания старой информации."],"metadata":{"id":"SMHNf3gClRBs"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.ibb.co/7tsb68R/LSTM3.png\" width=\"350\"></center>"],"metadata":{"id":"GkbfQ_tjBlpm"}},{"cell_type":"markdown","source":["$ i_t = σ(W_i \\cdot [h_{t-1}, x_t])$ — входной вентиль (input gate), вес запоминания новой информации;\n","\n","$ \\tilde c_t = \\tanh(W_c \\cdot [h_{t-1}, x_t])$ — предварительный вектор долгой памяти (candidate cell state), содержание новой информации."],"metadata":{"id":"i46CEXt6nWjN"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.postimg.cc/5NV9vVg6/LSTM4.png\" width=\"350\"></center>"],"metadata":{"id":"43HRU2XGBmrn"}},{"cell_type":"markdown","source":["$ c_t = f_t\\otimes c_{t-1} + i_t \\otimes \\tilde c_t$ — обновленный вектор долгой памяти."],"metadata":{"id":"PnKMEFi7oowO"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.ibb.co/6ZsZgp9/LSTM5.png\" width=\"350\"></center>"],"metadata":{"id":"GJGiVxCwBn0G"}},{"cell_type":"markdown","source":["$ o_t = σ(W_o \\cdot [h_{t-1}, x_t])$ — выходной вентиль для текущего токена (output gate);\n","\n","$ h_t = o_t\\otimes \\tanh(c_t)$ — обновленный вектор краткосрочной памяти."],"metadata":{"id":"0jTxhs69pm2-"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.ibb.co/F7DX5T3/LSTM6.png\" width=\"350\"></center>"],"metadata":{"id":"5rPpuqFIBotn"}},{"cell_type":"markdown","source":["Воспользуемся реализацией слоя [LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html) из pytorch."],"metadata":{"id":"AbneGruR5Qfu"}},{"cell_type":"code","source":["sequence = torch.randn(4, 6) # предложение из 4 токенов, у каждого 6 признаков\n","print(f\"Входные данные:\\n{sequence}\")\n","print(f\"Размер входных данных: {sequence.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R244dCX_5aFe","executionInfo":{"status":"ok","timestamp":1730819474702,"user_tz":-180,"elapsed":5,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"b19b6481-00dc-4099-c5f6-98ea1dee6a62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Входные данные:\n","tensor([[-0.2971,  0.2693,  0.2476, -1.3948,  1.4756,  0.6472],\n","        [ 0.0180,  0.2207,  0.4844, -0.0856,  1.5223, -0.6368],\n","        [ 0.2754,  1.3945, -0.6895,  0.1023,  0.3436, -0.4708],\n","        [ 0.1314, -0.5894,  0.0868,  1.0439, -0.3932,  1.3949]])\n","Размер входных данных: torch.Size([4, 6])\n"]}]},{"cell_type":"code","source":["lstm = nn.LSTM(input_size=6, hidden_size=5)\n","out, (h, c) = lstm(sequence)\n","\n","print(f\"Выходные данные (краткосрочная память):\\n{out}\")\n","print(f\"Размер выходных данных: {out.shape}\\n\")\n","\n","print(f\"Вектор краткосрочной памяти всего предложения:\\n{h}\")\n","print(f\"Размер вектора краткосрочной памяти: {h.shape}\\n\")\n","\n","print(f\"Вектор долгой памяти всего предложения:\\n{c}\")\n","print(f\"Размер вектора долгой памяти: {c.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_aJseDacuBiZ","executionInfo":{"status":"ok","timestamp":1730819475232,"user_tz":-180,"elapsed":533,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"3429c4ef-13e2-4aff-860f-3d8c8785f3b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Выходные данные (краткосрочная память):\n","tensor([[-0.0525, -0.0478, -0.1882,  0.1043,  0.0033],\n","        [ 0.0332, -0.1135, -0.0939,  0.0767,  0.0877],\n","        [-0.0532, -0.0285, -0.1432,  0.1465,  0.0683],\n","        [-0.3562,  0.2054,  0.0263,  0.0908, -0.2472]],\n","       grad_fn=<SqueezeBackward1>)\n","Размер выходных данных: torch.Size([4, 5])\n","\n","Вектор краткосрочной памяти всего предложения:\n","tensor([[-0.3562,  0.2054,  0.0263,  0.0908, -0.2472]],\n","       grad_fn=<SqueezeBackward1>)\n","Размер вектора краткосрочной памяти: torch.Size([1, 5])\n","\n","Вектор долгой памяти всего предложения:\n","tensor([[-0.4916,  0.4214,  0.0452,  0.1644, -0.5568]],\n","       grad_fn=<SqueezeBackward1>)\n","Размер вектора долгой памяти: torch.Size([1, 5])\n"]}]},{"cell_type":"markdown","source":["### Типы задач"],"metadata":{"id":"M_dqIxd17pdl"}},{"cell_type":"markdown","source":["- Один к одному: на вход подается один элемент, на выходе получаем вероятность класса — классификация изображений.\n","\n","- Один ко многим: на вход приходит один элемент, а на выходе получаем целую последовательность — генерация текста по слову, текстовой подписи по изображению.\n","\n","- Многие к одному: на вход сети подается последовательность, а в качестве выхода получаем один вектор вероятностей для классов — классификация текстов (анализ тональности, определение языка).\n","\n","- Многие ко многим: преобразовать последовательность в последовательность\n","  - количество выходов равно количеству входов — тегирование (именованные сущности, части речи).\n","  - количество выходов сети не обязательно равно количеству входов — машинный перевод, суммаризация."],"metadata":{"id":"VYc2i7aY1P8b"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.postimg.cc/SRp4W6Ww/RNN-tasks.png\" width=\"800\"></center>"],"metadata":{"id":"MDTlNYa1BpbW"}},{"cell_type":"markdown","source":["### Применение для языкового моделирования"],"metadata":{"id":"vFyy1_dK-J4h"}},{"cell_type":"markdown","source":["Мы рассмотрим языковые модели на основе рекуррентных нейронных сетей. Они должны хорошо подходить для этой задачи, поскольку они проходят по последовательности и запоминают порядок элементов."],"metadata":{"id":"6m9p0zgufxN3"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.ibb.co/RN1mHF6/LSTM-lm.png\" width=\"700\"></center>"],"metadata":{"id":"XcN4HDa8BqON"}},{"cell_type":"markdown","source":["- Embedding\n","\n","Есть входная последовательность из $n$ элементов. Мы пропускаем ее через слой эмбеддингов, который каждому элементу последовательности сопоставляет векторное представление.\n","\n","- LSTM1, LSTM2\n","\n","На вход ячейки LSTM поступает вектор заданной длины. Скрытое состояние (краткосрочная память, hidden state) элемента $w_i$ передается на следующую ячейку того же слоя вместе с элементом $w_{i+1}$. На рисунке представлено 2 слоя LSTM. Следовательно, скрытое состояние элемента $w_i$ на слое LSTM1 передается также на следующий слой LSTM2.\n","\n","- Softmax\n","\n","Выход каждого слоя — контекстуализированный эмбеддинг элемента последовательности. Однако в задаче языкового моделирования мы должны получать распределение  вероятностей для следующего элемента при условии текущей последовательности. Это должен быть вектор вероятностей, длина которого равна количеству элементов в словаре. Необходимо пропустить векторы элементов через линейный слой и применить функцию активации softmax.\n","\n","Для элемента $w_i$ предсказывается вероятность элемента $w_{i+1}$ с учетом предшествующей последовательности $w_1, \\cdots, w_i$ (по прошлому предсказываем будущее)."],"metadata":{"id":"2oAFuX-5neE7"}},{"cell_type":"markdown","source":["После предсказания вероятностей необходимо оценить качество и посчитать размер ошибки. В качестве правильных ответов мы используем те же обучающие данные, но сдвинутые на 1 шаг. Это достигается за счет добавления тегов начала START и конца END последовательности.\n","\n","Для элемента START правильным ответом будет элемент R, для R — I, для I — G, и т.д."],"metadata":{"id":"ZCIMlC7E3Isp"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.ibb.co/KGZ554x/rnn-generation.png\" width=\"600\"></center>"],"metadata":{"id":"dvNzXUWqBI4P"}},{"cell_type":"markdown","source":["📌 В чем особенность обучающих данных для языкового моделирования по сравнению с задачей классификации?"],"metadata":{"id":"NxkhwZEf3G6J"}},{"cell_type":"markdown","source":["После обучения рекуррентной сети для задачи языкового моделирования, она способна генерировать текст. Чем больше объем обучающих данных, тем более естественным будет сгенерированный текст.\n","\n","Этап генерации (inference) можно сравнить с тестированием при классификации. Если при обучении всегда есть правильные ответы, то при генерации их нет. Мы подаем какой-то символ (например, начало строки), по нему модель предсказывает следующий символ. Далее этот предсказанный символ снова подается на вход, по нему модель предсказывает следующий.\n","\n","Модель каждый раз вызывается заново, поэтому скрытые состояния не передаются автоматически. Их нужно сохранять и передавать в модель вручную."],"metadata":{"id":"7H_huxNQ9gmw"}},{"cell_type":"markdown","source":["📌 Когда останавливается процесс генерации?"],"metadata":{"id":"Ot3ZnTceQYdG"}},{"cell_type":"markdown","source":["Если все время подавать модели на вход символ начала строки, то она будет предсказывать одну и ту же наиболее вероятную последовательность. Чтобы разнообразить генерацию, элементы последовательности берутся в соответствии с установленным распределением вероятностей."],"metadata":{"id":"yCEO-u7a75p0"}},{"cell_type":"markdown","source":["## Генерация названий динозавров с помощью LSTM"],"metadata":{"id":"pV5XiAsC-q02"}},{"cell_type":"markdown","source":["Мы обучим языковую модель на уровне символов.\n","\n","В качестве обучающих данных будем использовать [корпус названий динозавров](https://www.kaggle.com/datasets/swimmingwhale/dinosaur-island).\n","\n","После обучения эта модель будет способна порождать новые имена динозавров, похожие на существующие."],"metadata":{"id":"i1DMm1oK6fhI"}},{"cell_type":"markdown","source":["<center><img src =\"https://i.ibb.co/TrtMyVH/dinos.png\" width=\"800\"></center>"],"metadata":{"id":"pkizajOSBruG"}},{"cell_type":"markdown","source":["### Загрузка и подготовка данных"],"metadata":{"id":"RzMYIDrIE5zX"}},{"cell_type":"markdown","source":["Загрузим данных и посмотрим на содержание файла."],"metadata":{"id":"1YaA-J8T3cbW"}},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/Xeanst/NLP_course_FBB/main/data/dinos.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2XO_DoIJ9OrQ","executionInfo":{"status":"ok","timestamp":1730819475233,"user_tz":-180,"elapsed":8,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"68165a73-d376-4651-d627-9878ecde95cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-11-05 15:11:15--  https://raw.githubusercontent.com/Xeanst/NLP_course_FBB/main/data/dinos.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 19909 (19K) [text/plain]\n","Saving to: ‘dinos.txt’\n","\n","dinos.txt           100%[===================>]  19.44K  --.-KB/s    in 0s      \n","\n","2024-11-05 15:11:15 (77.1 MB/s) - ‘dinos.txt’ saved [19909/19909]\n","\n"]}]},{"cell_type":"code","source":["!head dinos.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xEiUgcLk94jh","executionInfo":{"status":"ok","timestamp":1730819475233,"user_tz":-180,"elapsed":5,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"7b3c697b-7879-42a4-c86f-7a9afeb9ed9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Aachenosaurus\n","Aardonyx\n","Abdallahsaurus\n","Abelisaurus\n","Abrictosaurus\n","Abrosaurus\n","Abydosaurus\n","Acanthopholis\n","Achelousaurus\n","Acheroraptor\n"]}]},{"cell_type":"code","source":["!tail dinos.txt"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gGZZ6HmA11aJ","executionInfo":{"status":"ok","timestamp":1730819475793,"user_tz":-180,"elapsed":562,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"c69ed0c1-ee90-4319-daeb-8a8cb2087a25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Zhuchengtyrannus\n","Ziapelta\n","Zigongosaurus\n","Zizhongosaurus\n","Zuniceratops\n","Zunityrannus\n","Zuolong\n","Zuoyunlong\n","Zupaysaurus\n","Zuul"]}]},{"cell_type":"markdown","source":["Чтобы дальнейший код воспроизводился, зафиксируем случайные состояния:"],"metadata":{"id":"kmP24OODzaa2"}},{"cell_type":"code","source":["import torch\n","import random\n","import numpy as np\n","\n","\n","def set_random_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","\n","set_random_seed(42)"],"metadata":{"id":"-cr7GKzPzZw3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Мы бы хотели иметь возможность обучать модель на аппаратном ускорителе, таком как GPU, если он доступен. Проверим, доступен ли нам ускоритель `torch.cuda`, иначе продолжим вычисления на CPU."],"metadata":{"id":"dKjKGHAihFAp"}},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(f\"Using {device} device\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QZDIRZOXm-zm","executionInfo":{"status":"ok","timestamp":1730820504330,"user_tz":-180,"elapsed":590,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"818faadb-8c3a-4e95-e5b2-40be2c168699"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using cuda device\n"]}]},{"cell_type":"markdown","source":["Создадим класс `DinoDataset`, наследник класса `Dataset`."],"metadata":{"id":"NsYNA29I3JbW"}},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","class DinosDataset(Dataset):\n","  def __init__(self):\n","    super().__init__()\n","    with open('dinos.txt') as f:\n","      content = f.read().lower()\n","      self.vocab = sorted(set(content)) + ['<','>'] # добавляем в словарь все буквы, а также спецсимволы начала и конца\n","      self.vocab_size = len(self.vocab) # определяем размер словаря\n","      self.lines = content.splitlines() # разбиваем по строкам\n","    self.char2id = {char:id for id,char in enumerate(self.vocab)} # создаем словарь, каждому символу присваиваем индекс\n","    self.id2char = {id:char for id,char in enumerate(self.vocab)}\n","\n","  def __getitem__(self, index):\n","    line = self.lines[index]\n","    \"\"\"\n","    Входные данные x_str: символ начала + последовательность\n","    Выходные данные y_str: последовательность + символ конца\n","    \"\"\"\n","    x_str = '<' + line\n","    y_str = line + '>'\n","    x = torch.empty(len(x_str), dtype=torch.long, device=device) # создаем пустой тензор для входных данных\n","    y = torch.empty(len(y_str), dtype=torch.long, device=device) # создаем пустой тензор для выходных данных\n","    for i, (x_ch, y_ch) in enumerate(zip(x_str, y_str)): # переводим символы в индексы по словарю char2id\n","      x[i] = self.char2id[x_ch]\n","      y[i] = self.char2id[y_ch]\n","    return x,y\n","\n","  def __len__(self):\n","    return len(self.lines) # определяем размер датасета"],"metadata":{"id":"uZF-rqVR-aBo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["dinos_dataset = DinosDataset()\n","dinos_dataloader = DataLoader(dinos_dataset, shuffle=True)"],"metadata":{"id":"2IWIlztUBc_R"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Убедимся, что входные и выходные данные различаются сдвигом на один шаг."],"metadata":{"id":"CceJSrp14Rr1"}},{"cell_type":"code","source":["x,y = next(iter(dinos_dataloader))\n","print(x.shape)\n","print(x)\n","print([dinos_dataset.id2char[int(i)] for i in x[0]])\n","print(y.shape)\n","print(y)\n","print([dinos_dataset.id2char[int(i)] for i in y[0]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eL7kwnSSDxLQ","executionInfo":{"status":"ok","timestamp":1730820507651,"user_tz":-180,"elapsed":352,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"18fe7d6b-9b17-4df0-d61e-d11260b9b153"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 12])\n","tensor([[27, 19, 25, 18, 13, 15, 19,  1, 21, 18, 21, 19]], device='cuda:0')\n","['<', 's', 'y', 'r', 'm', 'o', 's', 'a', 'u', 'r', 'u', 's']\n","torch.Size([1, 12])\n","tensor([[19, 25, 18, 13, 15, 19,  1, 21, 18, 21, 19, 28]], device='cuda:0')\n","['s', 'y', 'r', 'm', 'o', 's', 'a', 'u', 'r', 'u', 's', '>']\n"]}]},{"cell_type":"markdown","source":["Посмотрим на размер обучающих данных и количество уникальных символов."],"metadata":{"id":"iIJSgkgp4Ik8"}},{"cell_type":"code","source":["print(len(dinos_dataset.lines))\n","print(dinos_dataset.vocab_size)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lJ44a9KJN3G_","executionInfo":{"status":"ok","timestamp":1730820508405,"user_tz":-180,"elapsed":2,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"336626ea-52d8-42d5-cd8b-d7d9385e065c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["1536\n","29\n"]}]},{"cell_type":"markdown","source":["### Создание модели"],"metadata":{"id":"wzhyLlNeE8pe"}},{"cell_type":"markdown","source":["Перейдем к построению модели. Она включает эмбеддинг слой, два слоя LSTM и линейный слой."],"metadata":{"id":"nWFop0PT4weA"}},{"cell_type":"code","source":["from torch import nn\n","\n","class LM(nn.Module):\n","  def __init__(self, vocab_size):\n","    super(LM, self).__init__()\n","    self.lstm_size = 15 # размер скрытых состояний h и c (краткосрочная и долгая память)\n","    self.embedding_dim = 10 # размер входных данных (длина эмбеддингов)\n","    self.num_layers = 2 # количество слоев LSTM\n","\n","    # слой эмбеддингов\n","    self.embedding = nn.Embedding(\n","        num_embeddings=vocab_size,\n","        embedding_dim=self.embedding_dim\n","        )\n","    # слой LSTM\n","    self.lstm = nn.LSTM(\n","        input_size=self.embedding_dim,\n","        hidden_size=self.lstm_size,\n","        num_layers=self.num_layers\n","    )\n","    # линейный слой\n","    self.hid2out = nn.Linear(\n","        in_features=self.lstm_size,\n","        out_features=vocab_size\n","        )\n","\n","  def forward(self, x, prev_state=None):\n","    embedding = self.embedding(x)\n","    if prev_state:\n","      output, state = self.lstm(embedding)\n","    else:\n","      output, state = self.lstm(embedding, prev_state)\n","    logits = self.hid2out(output)\n","\n","    return logits, state"],"metadata":{"id":"fD2pXvj9pE3h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = LM(len(dinos_dataset.char2id)).to(device)"],"metadata":{"id":"VlPKO7HJJeFA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Применим модель к одному батчу и посмотрим размер получившихся данных.\n","\n","📌 Почему он именно такой?"],"metadata":{"id":"Af5E7qG86MiG"}},{"cell_type":"code","source":["y_pred, (state_h, state_c) = model(x)\n","print(y_pred.shape)\n","print(state_h.shape)\n","print(state_c.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CfDzSSbRKHnf","executionInfo":{"status":"ok","timestamp":1730820514276,"user_tz":-180,"elapsed":926,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"9afcaae9-6329-4f13-b6f4-eb1344442d58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 12, 29])\n","torch.Size([2, 12, 15])\n","torch.Size([2, 12, 15])\n"]}]},{"cell_type":"markdown","source":["### Случайная выборка из элементов массива `np.random.choice`"],"metadata":{"id":"fKlrITPX7Vll"}},{"cell_type":"markdown","source":["Метод `np.random.choice` выбирает из списка элемент случайным образом. Если мы не задаем распределение вероятностей, то каждый элемент будет выбран примерно одинаковое количество раз."],"metadata":{"id":"3ghi1CrN8MVD"}},{"cell_type":"code","source":["import numpy as np\n","\n","for i in range(20):\n","  print(np.random.choice([1,2,3]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ef4BNen7e3FJ","executionInfo":{"status":"ok","timestamp":1730820514276,"user_tz":-180,"elapsed":2,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"7a8365db-c68d-4f6b-aeec-266c02aa77cb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["3\n","1\n","3\n","3\n","1\n","1\n","3\n","2\n","3\n","3\n","3\n","3\n","1\n","3\n","2\n","1\n","2\n","2\n","2\n","2\n"]}]},{"cell_type":"markdown","source":["Распределение вероятностей может быть задано эксплицитно. Если это ohe-hot вектор, то всегда будет выбираться номер позиции, на которой стоит 1."],"metadata":{"id":"oFgvM1er8qRL"}},{"cell_type":"code","source":["p1 = torch.nn.functional.one_hot(torch.tensor(2), 29)\n","print(p1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MRFhy-J7fIPh","executionInfo":{"status":"ok","timestamp":1730820516672,"user_tz":-180,"elapsed":375,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"7f7cc4ed-c7dc-44ff-8469-d774f8fce544"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","        0, 0, 0, 0, 0])\n"]}]},{"cell_type":"code","source":["for i in range(20):\n","  pred_id = np.random.choice(np.arange(len(dinos_dataset.char2id)), p=p1)\n","  print(pred_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kha53Ke-f1qw","executionInfo":{"status":"ok","timestamp":1730820516672,"user_tz":-180,"elapsed":4,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"766e7c06-dc2b-41de-af33-0fa1f639ebc9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n","2\n"]}]},{"cell_type":"markdown","source":["Можно использовать распределение вероятностей, которое было получено при обучении сети. Для этого необходимо к выходным данным применить функцию активации softmax."],"metadata":{"id":"mVV8jHtl9DOE"}},{"cell_type":"code","source":["logits = y_pred[:, -1, :].unsqueeze(1)\n","print(logits.shape)\n","print(logits)\n","y_softmax_scores = torch.softmax(logits, dim=2)\n","print(y_softmax_scores.shape)\n","print(y_softmax_scores)\n","torch.sum(y_softmax_scores)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HN_hKFq2dnbJ","executionInfo":{"status":"ok","timestamp":1730820519571,"user_tz":-180,"elapsed":1114,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"04a95d9f-cc98-44e0-aa65-3b8ac09080c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 1, 29])\n","tensor([[[-0.0232,  0.0097,  0.2555,  0.0540,  0.1060, -0.0343,  0.1300,\n","           0.0313, -0.0489,  0.0143, -0.1940,  0.0451,  0.1569, -0.2126,\n","          -0.1407,  0.1162,  0.0049,  0.0596,  0.0142, -0.0973,  0.1916,\n","          -0.0417, -0.0682,  0.0962, -0.1518, -0.0636,  0.0772, -0.0899,\n","           0.0964]]], device='cuda:0', grad_fn=<UnsqueezeBackward0>)\n","torch.Size([1, 1, 29])\n","tensor([[[0.0332, 0.0343, 0.0438, 0.0358, 0.0377, 0.0328, 0.0386, 0.0350,\n","          0.0323, 0.0344, 0.0279, 0.0355, 0.0397, 0.0274, 0.0295, 0.0381,\n","          0.0341, 0.0360, 0.0344, 0.0308, 0.0411, 0.0325, 0.0317, 0.0374,\n","          0.0291, 0.0318, 0.0366, 0.0310, 0.0374]]], device='cuda:0',\n","       grad_fn=<SoftmaxBackward0>)\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor(1.0000, device='cuda:0', grad_fn=<SumBackward0>)"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["p2 = y_softmax_scores.detach().cpu().numpy().ravel()\n","print(p2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gVUCR9A0eKI7","executionInfo":{"status":"ok","timestamp":1730820519571,"user_tz":-180,"elapsed":3,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"3ebd4030-c17d-4655-f248-d8e478d21ed0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.03315033 0.03425797 0.04380174 0.03580767 0.03772096 0.03278182\n"," 0.0386377  0.03500416 0.03230903 0.03441449 0.02794334 0.03549327\n"," 0.03969232 0.02743049 0.02947283 0.03810751 0.03409497 0.03600864\n"," 0.03441101 0.03078127 0.04108977 0.03254106 0.03169063 0.03735206\n"," 0.02914833 0.03183691 0.03664972 0.03101017 0.03735979]\n"]}]},{"cell_type":"code","source":["for i in range(20):\n","  pred_id = np.random.choice(np.arange(len(dinos_dataset.char2id)), p=p2)\n","  print(pred_id)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HZsqarh0eeZ5","executionInfo":{"status":"ok","timestamp":1730820522093,"user_tz":-180,"elapsed":349,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"a14a6670-7864-48b6-a2e0-211e2a1fb7f7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["28\n","23\n","8\n","2\n","19\n","12\n","3\n","14\n","1\n","26\n","7\n","19\n","8\n","15\n","15\n","5\n","28\n","22\n","27\n","25\n"]}]},{"cell_type":"markdown","source":["### Тестирование модели"],"metadata":{"id":"_P4V9PSTQ4Je"}},{"cell_type":"markdown","source":["Напишем функцию для генерации названий динозавров."],"metadata":{"id":"6qbikrOB-OrN"}},{"cell_type":"code","source":["def inference(dataset, model):\n","  model.eval() # переводим модель в состояние тестирования\n","  newline_id = dataset.char2id['>'] # записываем индекс символа конца последовательности\n","  word_size = 0 # будем контролировать длину порождаемой последовательности\n","  with torch.no_grad():\n","    state_h, state_c = (None, None) # скрытые состояния будут передаваться вручную, поэтому их надо хранить\n","    start_id = dataset.char2id['<'] # генерация начинается с символа начала последовательности\n","    indices = [start_id] # создаем список, где будем хранить предсказания\n","    word_size += 1 # увеличиваем длину последовательности\n","    pred_id = start_id # записываем символ начала последовательности как первое предсказание\n","    x = torch.tensor([[pred_id]]).to(device) # преобразуем в тензор\n","\n","    \"\"\"\n","    Будем использовать два условия для продолжения генерации в цикле while:\n","    1) сгенерированный символ не является символом конца последовательности '>'\n","    и\n","    2) длина сгенерированной последовательности меньше 20\n","    \"\"\"\n","    while pred_id != newline_id and word_size < 20:\n","      logits, (state_h, state_c) = model(x, (state_h, state_c)) # передаем в модель тензор с текущим символом x, предыдущие состояния h и c\n","      y_softmax_scores = torch.softmax(logits, dim=2)\n","      pred_id = np.random.choice( # осуществляем случайную выборку значений из заданного массива\n","          np.arange(len(dinos_dataset.char2id)), # с некоторой вероятностью получим один из 29 индексов\n","          p=y_softmax_scores.detach().cpu().numpy().ravel() # вероятность определяется в зависимости от обучающих данных\n","          )\n","      indices.append(pred_id) # добавляем предсказанный индекс в список предсказаний\n","      x = torch.tensor([[pred_id]]).to(device) # преобразуем в тензор\n","      word_size += 1 # увеличиваем длину последовательности\n","\n","      if word_size == 20 and indices[-1] != newline_id:\n","        indices.append(newline_id)\n","\n","    model.train()\n","\n","    return ''.join([dinos_dataset.id2char[i] for i in indices]) # возвращаем индексы, переведенные в символы"],"metadata":{"id":"RBU6fhxQQ7UF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Обучение модели"],"metadata":{"id":"x7HutTATh0TP"}},{"cell_type":"code","source":["def train(dataset, dataloader, model, criterion, optimizer, max_epochs):\n","  model.train() # переводим модель в состояние обучения\n","  losses = []\n","  for epoch in range(max_epochs):\n","    print(f'\\nEpoch {epoch+1}')\n","    epoch_loss = 0\n","    for batch, (x,y) in enumerate(dataloader):\n","      optimizer.zero_grad()\n","      y_pred, (state_h, state_c) = model(x) # передаем данные в модель, записываем предсказание\n","      loss = criterion(y_pred.transpose(1,2), y) # считаем ошибку\n","      epoch_loss += loss.item()\n","      loss.backward()\n","      optimizer.step()\n","      if (batch+1) % 100 == 0:\n","        print(inference(dataset, model))\n","\n","    print(f'Loss {epoch_loss/(batch+1)}')\n","    losses.append(epoch_loss/(batch+1))\n","  return losses"],"metadata":{"id":"zymkKTtSiF3h"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import optim\n","\n","model = LM(len(dinos_dataset.char2id)).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","max_epochs = 15"],"metadata":{"id":"i7N7shjWi3Fw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["losses = train(dinos_dataset,dinos_dataloader, model, criterion, optimizer, max_epochs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j0gsVIQVngqd","executionInfo":{"status":"ok","timestamp":1730820604695,"user_tz":-180,"elapsed":73756,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"ce22fa33-f78c-4507-c6ec-f34e072b9b82"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Epoch 1\n","<q<beaikgxjgocwa>\n","<ue\n","vstuajbyriahits>\n","<nasurupooaaasioygnu>\n","<faic>\n","<us>\n","<uiyos>\n","<iahnusaoreci>\n","<iosi>\n","<<gopiasoceupdoygs>\n","<esirppauraarsapfrat>\n","<kychausas>\n","<ponaus>\n","<ils>\n","<wusaiusaesaios>\n","<esantos>\n","Loss 2.585582373508563\n","\n","Epoch 2\n","<panel>\n","<lus>\n","<noresaatdyxuraur>\n","<zurosccous>\n","<at>\n","<clus>\n","<seltrustnus>\n","<turodocionocaurdosa>\n","<pacnos>\n","<<nhteoda>\n","<toncceprur>\n","<sxopentagactorartap>\n","<kosanorusacocousert>\n","<n>\n","<iyuraeadodhuauraus>\n","Loss 2.29606219738101\n","\n","Epoch 3\n","<s>\n","<fes>\n","<>\n","<jesbuskrunzmteuraul>\n","<gyxmophgos>\n","<sasasoseehtodauitoc>\n","<a>\n","<his>\n","<<sadorosasaragaus>\n","<yletewa>\n","<aus>\n","<atyos>\n","<los>\n","<an>\n","<tipeliiodyyrurusaus>\n","Loss 2.256419741703818\n","\n","Epoch 4\n","<xs>\n","<kusabis>\n","<cmexustiedru>\n","<>\n","<mousarcxomorodoruru>\n","<mitiacos>\n","<caanonkurushos>\n","<ctonl>\n","<lhonaialaten>\n","<loleceldagomeosausa>\n","<tuelprggimonjocerus>\n","<marurilanenaus>\n","<sycinthanipon>\n","<ngaleibekulliydiwto>\n","<eiryorisaningaururt>\n","Loss 2.237435588690763\n","\n","Epoch 5\n","<manba>\n","<gurus>\n","<liius>\n","<bryfaus>\n","<comalrusetisopherrh>\n","<tin>\n","<odusbaus>\n","<tohelocis>\n","<gunyenuris>\n","<os>\n","<dics>\n","<imyerusaus>\n","<qusatopr>\n","<vehytavtmilanuanin>\n","<gisonlalilurusaur>\n","Loss 2.224393251662453\n","\n","Epoch 6\n","<cha>\n","<locomurias>\n","<aururordeturiphalos>\n","<angocaururantosirgh>\n","<taelamiluselingopni>\n","<eusaurusiannonbs>\n","<manavaterusaalus>\n","<noluroralodonigisat>\n","<lotomanochontadorur>\n","<drusathayevelos>\n","<s>\n","<psasa>\n","<wausattauryyxitrosa>\n","<ngadontanosatruraua>\n","<toto>\n","Loss 2.2152109425514936\n","\n","Epoch 7\n","<gurrus>\n","<srosagidicabynirius>\n","<arustol>\n","<dus>\n","<lelelona>\n","<ttyentojurinoraurau>\n","<x>\n","<s>\n","<mapheroderaurorurus>\n","<drus>\n","<tos>\n","<posausauphtes>\n","<lanoxterusaus>\n","<gota>\n","<pansathocr>\n","Loss 2.209184097669398\n","\n","Epoch 8\n","<x>\n","<braceos>\n","<ke>\n","<imausaerur>\n","<biururkymuriaurur>\n","<crus>\n","<s>\n","<bavistakopeochescha>\n","<arusaus>\n","<asan>\n","<bios>\n","<anodiaenbos>\n","<cegosa>\n","<atos>\n","<scods>\n","Loss 2.2043563569895923\n","\n","Epoch 9\n","<sosusadgbur>\n","<gdostlon>\n","<yriracen>\n","<ruron>\n","<ausistrurin>\n","<dos>\n","<brvan>\n","<copetininen>\n","<ernupuriallhuriosal>\n","<ausus>\n","<n>\n","<canattaimuruccyya>\n","<ptinosacerer>\n","<aururus>\n","<pos>\n","Loss 2.2007296018612883\n","\n","Epoch 10\n","<nayrururulo>\n","<a>\n","<hus>\n","<ruros>\n","<s>\n","<isatanilonjapeeruso>\n","<huruchilorus>\n","<qualausa>\n","<aylasangusausaramol>\n","<modon>\n","<lpocius>\n","<telonyuresaurulopqa>\n","<ruraciorenor>\n","<brops>\n","<zahormagygichatauru>\n","Loss 2.1981235252072415\n","\n","Epoch 11\n","<torono>\n","<ppspatururumesaus>\n","<dla>\n","<ururulofus>\n","<angiazhenmin>\n","<l>\n","<teunvetos>\n","<fapaur>\n","<ptaustosasiaodakus>\n","<igopaurusadopa>\n","<auteianaueo>\n","<s>\n","<eruraurenis>\n","<saplantasabeys>\n","<latisasansshintr>\n","Loss 2.195813642737145\n","\n","Epoch 12\n","<saurisaverus>\n","<ochaurucaugabuscent>\n","<pelausaca>\n","<es>\n","<haios>\n","<ma>\n","<sa>\n","<orus>\n","<beuropioteibusaus>\n","<ururus>\n","<pepywalausas>\n","<rusurus>\n","<psarantychurus>\n","<chusaucolvenditylir>\n","<tonipatesatiochorus>\n","Loss 2.1936532467758902\n","\n","Epoch 13\n","<sausadis>\n","<stianianos>\n","<vilosarurusaphacono>\n","<eurtrururuqaurus>\n","<boes>\n","<xaceleurlopsasadsat>\n","<hitaus>\n","<waris>\n","<domin>\n","<onaleltorausausarta>\n","<wrurorueospaurianto>\n","<crusar>\n","<sadotkiaushr>\n","<ches>\n","<osotogrurusa>\n","Loss 2.1920615115668625\n","\n","Epoch 14\n","<bekusas>\n","<austur>\n","<pretiabinosaurus>\n","<phosseosalosandimos>\n","<onyn>\n","<odonpaltesausurecer>\n","<wus>\n","<phus>\n","<binzhivarausaurus>\n","<a>\n","<rnvetausanasatentau>\n","<torurantatytocoragy>\n","<ptrusmentosprus>\n","<dodinotostodhinaley>\n","<fiatellaamahes>\n","Loss 2.1903516214030483\n","\n","Epoch 15\n","<leuraunin>\n","<lozanilitornyx>\n","<audhatodimeilodan>\n","<proraus>\n","<todsatabheorakiis>\n","<topsantis>\n","<tsierorusdencrojaus>\n","<eengrure>\n","<kohmas>\n","<hachacophun>\n","<etos>\n","<exlilmatos>\n","<keldang>\n","<merdostiztorurpas>\n","<cus>\n","Loss 2.1891275478216508\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","plt.plot(losses)\n","plt.title('Cross Entropy Loss value')\n","plt.ylabel('Cross Entropy Loss')\n","plt.xlabel('epoch')\n","plt.show()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uc0Xa1PNrJOC","executionInfo":{"status":"ok","timestamp":1730820605189,"user_tz":-180,"elapsed":496,"user":{"displayName":"Ксения Студеникина","userId":"14120476932752609005"}},"outputId":"91202485-c9ce-42c3-b445-9f3382cc9158"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"notebookId":"53997d2d-afb8-4477-8874-b6d46299f06c","notebookPath":"seminar.ipynb","colab":{"provenance":[{"file_id":"1xQhUWn_Qt5N9AxO1nQTl7WFZVnhE3uRn","timestamp":1730470659631},{"file_id":"1WBLV5QV9SRhRRyd4DqcN_ovszddB7J3e","timestamp":1730395294153}],"toc_visible":true}},"nbformat":4,"nbformat_minor":0}