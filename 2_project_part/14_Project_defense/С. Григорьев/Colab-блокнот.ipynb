{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "X0NdvrpNMldE"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6Sw65ydMLeP"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ссылка на датасет: https://huggingface.co/datasets/DGurgurov/azerbaijani_sa/viewer/default/test?views%5B%5D=test"
      ],
      "metadata": {
        "id": "8qKv31dZwzK9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"DGurgurov/azerbaijani_sa\")\n"
      ],
      "metadata": {
        "id": "vhrg7wB8t46v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Пример с азербайджанскими данными"
      ],
      "metadata": {
        "id": "c0ocZkunMiFW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данные для примера"
      ],
      "metadata": {
        "id": "n3tXdE3YSByQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выберем случайные 50 примеров из тестовой выборки. Также задаём переменную sentiment, соответствующую истинным меткам датасета"
      ],
      "metadata": {
        "id": "xIL5WsIO1c4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "samples = dataset[\"test\"].select(range(50))\n",
        "sentiment = samples[\"label\"]\n",
        "print(sentiment[1] )"
      ],
      "metadata": {
        "id": "RIOvQtexSEvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка токенизатора и модели"
      ],
      "metadata": {
        "id": "jhLhx8NASAPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "DEVICE = torch.device(\"cuda:0\")\n",
        "\n",
        "az_checkpoint = \"ai-forever/mGPT-1.3B-azerbaijan\"\n",
        "az_tokenizer = AutoTokenizer.from_pretrained(az_checkpoint)\n",
        "az_model = AutoModelForCausalLM.from_pretrained(az_checkpoint).to(DEVICE)"
      ],
      "metadata": {
        "id": "S9vXA1UDMewP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Рассмотрим бинарную классификацию по тональности без дообучения."
      ],
      "metadata": {
        "id": "RIRDp1UwRwHG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Метод 1: few-shot генерация"
      ],
      "metadata": {
        "id": "39A97IecR1C0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В ячейке инструкция переведена на азербайджанский. В комментариях я оставил инструкцию по-русски для лучшей ориентации.\n",
        "\n",
        "Тональность — это эмоциональное отношение автора высказывания к некоторому объекту, выраженное в тексте.\n",
        "  Она может быть положительной или отрицательной.\n",
        "  Положительная тональность выражается с помощью метки '1'.\n",
        "  Отрицательная тональность выражается с помощью метки '0'.\n",
        "\n",
        "  Ниже приведены примеры классификации текстов по тональности:\n",
        "  Текст: Этот фильм был ужасен.\n",
        "  Тональность: 0 (отрицательная)\n",
        "  Текст: Мне нравится эта книга.\n",
        "  Тональность: 1 (положительная)\n",
        "  Текст: Я ненавижу это место.\n",
        "  Тональность: 0 (отрицательная)\n",
        "  Текст: Сегодя замечательный день.\n",
        "  Тональность: 1 (положительная)\n",
        "  Текст: Я не могу поверить, насколько это здорово!\n",
        "  Тональность: 1 (положительная)\n",
        "  Текст: Это самый худший опыт, который у меня когда-либо был.\n",
        "  Тональность: 0 (отрицательная)\n",
        "  Текст: {text}\n",
        "  Тональность:"
      ],
      "metadata": {
        "id": "-N8DuDpe0eqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sentiment(text, model, tokenizer):\n",
        "\n",
        " # Задаем промпт\n",
        "  prompt = f\"\"\"Tonallıq, ifadə müəllifinin mətndə ifadə olunan bəzi obyektə emosional münasibətidir.\n",
        "  Müsbət və ya mənfi ola bilər.\n",
        "  Müsbət tonallıq ' 1 ' işarəsi ilə ifadə olunur.\n",
        "  Mənfi tonallıq ' 0 ' işarəsi ilə ifadə olunur.\n",
        "\n",
        "  Aşağıda mətnlərin tonallığa görə təsnif edilməsinə dair nümunələr verilmişdir:\n",
        "  Mətn: Təssüf ki, Finala qədər gələ bilmədi Finalda Messi Ronaldo görmək istiyərdim.\n",
        "  Tonallıq: 0 (mənfi)\n",
        "  Mətn: Və ictimai nəqliyyatdan istifadə etmək asan və rahatdı.\n",
        "  Tonallıq: 1 (müsbət)\n",
        "  Mətn: Rusiyanın düşmənlərinin izi ilə getmək, vəziyyəti içəridən sarsıtmaq, mitinqlər keçirmək və hava limanlarını dağıtmaq olmaz.\n",
        "  Tonallıq: 0 (mənfi)\n",
        "  Mətn: İlahi. Hər kəsin üzü gülür. Xoşbəxtlik budur.\n",
        "  Tonallıq: 1 (müsbət)\n",
        "  Mətn: Və bu sonsuz kainatda dünyamızın, bir toz dənəciyi boyda olduğuna baxmayaraq, insanlar mənasız şeylə görə bir-birini öldürür\n",
        "  Tonallıq: 0 (mənfi)\n",
        "  Mətn: Nə gözəl ! Maşallah əksəriyyəti də sağ salamatdırlar . Mənim də orta məktəb məzunu olmağımın 45 illiyi 2025ci ildə tamam olacaq . Kaş bizlər də belə bir şey təşkil edə bilsəydik .\n",
        "  Tonallıq: 1 (müsbət)\n",
        "  Mətn: {text}\n",
        "  Tonallıq:\"\"\"\n",
        "\n",
        "  # Токенизируем текст\n",
        "  input_ids = tokenizer.encode(prompt, return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "  # Осуществляем генерацию\n",
        "  out = model.generate(input_ids, do_sample=False, max_new_tokens=1)\n",
        "\n",
        "\n",
        "  # Декодируем токены\n",
        "  generated_sentiment = int(list(map(tokenizer.decode, out))[0].split()[-1])\n",
        "  return generated_sentiment"
      ],
      "metadata": {
        "id": "VOrdpPx2-60W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = []\n",
        "for text in samples:\n",
        "    pred1 = generate_sentiment(text[\"text\"], az_model, az_tokenizer)\n",
        "    #pred = generate_sentiment(text[\"text\"], pipe)\n",
        "    print(pred1)\n",
        "    print()\n",
        "    predictions.append(pred1)\n",
        "print(predictions)"
      ],
      "metadata": {
        "id": "lw-6wYkRAnUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подсчёт метрик:"
      ],
      "metadata": {
        "id": "6Qwj9HS1TNvD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точность"
      ],
      "metadata": {
        "id": "o_hNIOV3rDVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score\n",
        "precision_score( sentiment, predictions)"
      ],
      "metadata": {
        "id": "5s3GRKtITR6G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Полнота"
      ],
      "metadata": {
        "id": "bbzVwr_SrOCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_score(sentiment, predictions)"
      ],
      "metadata": {
        "id": "1VJ9cZx5rQHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "f1_мера"
      ],
      "metadata": {
        "id": "jslC1XvrrQoK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(sentiment,predictions)"
      ],
      "metadata": {
        "id": "UWajFXJirVxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Матрица ошибок:"
      ],
      "metadata": {
        "id": "dHVtxirYlTHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Создание матрицы ошибок\n",
        "cm = confusion_matrix(sentiment,predictions)\n",
        "\n",
        "# Визуализация с помощью Seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[1, 0])\n",
        "plt.xlabel('Предсказанные метки')\n",
        "plt.ylabel('Истинные метки')\n",
        "plt.title('Матрица ошибок (confusion matrix)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "vaYp3msRlV7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Метод 2: использование перплексии"
      ],
      "metadata": {
        "id": "hQTsHv-DRxht"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для определения тональности будем использовать меру перплексии. В теории информации, перплексия – мера того, насколько хорошо распределение вероятностей предсказывает выборку. Говоря простым языком, перплексия – мера \"удивлённости\" модели.\n",
        "\n",
        "На вход модели мы подаём затравку в формате <метка тональности> + <отзыв>. Далее мы считаем перплексию каждого из них. Выбираем наименьшую перплексию из двух и присваиваем метку отзыву."
      ],
      "metadata": {
        "id": "Nt8DPHv-h0_U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Müsbət tonallıq- положительная тональность\n",
        "\n",
        "Mənfi tonallıq- отрицательная тональность"
      ],
      "metadata": {
        "id": "VBP5btZ83H1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def calculate_perplexity(sentence, model, tokenizer):\n",
        "    # Добавляем к предложению метки тональности\n",
        "    sentence_positive = 'Müsbət tonallıq:'+sentence\n",
        "    sentence_negative = 'Mənfi tonallıq:'+sentence\n",
        "    list_sent = [sentence_positive, sentence_negative]\n",
        "    ppl_values = []\n",
        "\n",
        "    for sentence in list_sent:\n",
        "      # Токенизируем предложения\n",
        "      encodings = tokenizer(sentence, return_tensors='pt')\n",
        "      input_ids = encodings.input_ids.to(DEVICE)\n",
        "      # Применяем модель\n",
        "      with torch.no_grad():\n",
        "          outputs = model(input_ids=input_ids, labels=input_ids)\n",
        "      loss = outputs.loss\n",
        "      # Подсчитываем перплексию\n",
        "      ppl = math.exp(loss.item() * input_ids.size(1))\n",
        "      ppl_values.append(ppl)\n",
        "\n",
        "    # Выбираем предложение с меньшим значением перплексии\n",
        "    if ppl_values[0] > ppl_values[1]:\n",
        "      return 0 # отрицательная тональность\n",
        "    else:\n",
        "      return 1 # положительная тональность"
      ],
      "metadata": {
        "id": "fHX-eqs-NFtV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mətn-текст"
      ],
      "metadata": {
        "id": "91nPDBwF3uf1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred2 = []\n",
        "for text in samples:\n",
        "    ppl_value = calculate_perplexity(text[\"text\"], az_model, az_tokenizer)\n",
        "    print(ppl_value)\n",
        "    print()\n",
        "    pred2.append(ppl_value)\n",
        "print(pred2)\n",
        " # print(f'Mətn \"{text}\": {calculate_perplexity(text[\"text\"], az_model, az_tokenizer)}')"
      ],
      "metadata": {
        "id": "qPItegPCNHeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точность"
      ],
      "metadata": {
        "id": "6whxrJDwY22v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score\n",
        "precision_score( sentiment, pred2 )"
      ],
      "metadata": {
        "id": "9vSaXbxPXf-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "полнота:"
      ],
      "metadata": {
        "id": "OUM_ONIJY5U9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_score(sentiment, pred2 )"
      ],
      "metadata": {
        "id": "GjGj64PEY698"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "f1_мера"
      ],
      "metadata": {
        "id": "bMxTbzoMZDJD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(sentiment, pred2 )"
      ],
      "metadata": {
        "id": "aQxt745IZItg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Матрица Ошибок:"
      ],
      "metadata": {
        "id": "LHUGOtydlbWN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Создание матрицы ошибок\n",
        "cm = confusion_matrix(sentiment,pred2)\n",
        "\n",
        "# Визуализация с помощью Seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[1, 0])\n",
        "plt.xlabel('Предсказанные метки')\n",
        "plt.ylabel('Истинные метки')\n",
        "plt.title('Матрица ошибок (confusion matrix)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DyhbLBIDldog"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Применение предобучееной модели Bert к этим же 50 предложениям."
      ],
      "metadata": {
        "id": "8ycUZGjmvuYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ссылка на модель: https://huggingface.co/DGurgurov/xlm-r_azerbaijani_sentiment"
      ],
      "metadata": {
        "id": "615CYiYTbTdo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model_name = \"DGurgurov/xlm-r_azerbaijani_sentiment\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "7srnsv1gwBb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment(text):\n",
        "    # Токенизация входного текста\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Получение логитов\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs).logits\n",
        "\n",
        "    # Получение предсказаний\n",
        "    predicted_class = torch.argmax(logits, dim=-1).item()\n",
        "\n",
        "\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "wWHeOiyf1KGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred3 = []\n",
        "for text in samples:\n",
        "    predicted_class = analyze_sentiment(text[\"text\"])\n",
        "    print(predicted_class)\n",
        "    print()\n",
        "    pred3.append(predicted_class)\n",
        "print(pred3)"
      ],
      "metadata": {
        "id": "7GH0ZT60yqu_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подсчёт Метрик"
      ],
      "metadata": {
        "id": "0lLxtCCy6xE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точность"
      ],
      "metadata": {
        "id": "9-yLT1Gw602P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_score\n",
        "precision_score( sentiment, pred3 )"
      ],
      "metadata": {
        "id": "aaM94loL62CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Полнота"
      ],
      "metadata": {
        "id": "rIirGvjY62gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_score(sentiment, pred3 )"
      ],
      "metadata": {
        "id": "Xr-Z_LvJ64sZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "f1_мера"
      ],
      "metadata": {
        "id": "1L70HcJV65JT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(sentiment, pred3 )"
      ],
      "metadata": {
        "id": "cRx8DP1I67u0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Матрица ошибок:"
      ],
      "metadata": {
        "id": "ZvZfOu-b68Ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Создание матрицы ошибок\n",
        "cm = confusion_matrix(sentiment,pred3)\n",
        "\n",
        "# Визуализация с помощью Seaborn\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=[0, 1], yticklabels=[1, 0])\n",
        "plt.xlabel('Предсказанные метки')\n",
        "plt.ylabel('Истинные метки')\n",
        "plt.title('Матрица ошибок (confusion matrix)')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wmezTgTq7zSx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}