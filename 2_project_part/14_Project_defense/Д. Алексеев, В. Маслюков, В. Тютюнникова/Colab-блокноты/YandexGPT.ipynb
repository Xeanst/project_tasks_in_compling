{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Изначальное форматирование корпусов, использованное на первых этапах проекта:"
      ],
      "metadata": {
        "id": "Tjs5b5rNmml_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "qbbXO2V52quJ",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "vY34iAjzmgNr"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "arabic_stance = load_dataset(\"NoraAlt/Mawqif_Stance-Detection\")\n",
        "synt_english_stance = load_dataset(\"webimmunization/COVID-19-conspiracy-theories-tweets\")\n",
        "english_tweet_stance = load_dataset(\"Supakrit65/stance-general-json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Приведение корпусов к единому формату**"
      ],
      "metadata": {
        "id": "EEX2hd6Kq5K5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def label_format(stance):\n",
        "  if stance in ['Against', 'deny', 'AGAINST']:\n",
        "    answer = -1\n",
        "  elif stance in ['Favor', 'support', 'FAVOR']:\n",
        "    answer = 1\n",
        "  else:\n",
        "    answer = 0\n",
        "  return answer\n",
        "\n",
        "\n",
        "def stance_format(ds):\n",
        "  stance_f = {}\n",
        "  ID = 0\n",
        "  for x in ds:\n",
        "    if 'target' in x:\n",
        "      if x['target'] == 'Covid Vaccine':\n",
        "        stance_f[ID] =  (x['text'], label_format(x['stance']))\n",
        "        ID += 1\n",
        "    if 'tweet' in x:\n",
        "      stance_f[ID] = (x['tweet'], label_format(x['label']))\n",
        "      ID += 1\n",
        "    if 'input' in x:\n",
        "      stance_f[ID] = (re.search(r\"`(.*?)`\", x['input']).group(1), label_format(x['output']))\n",
        "      ID += 1\n",
        "\n",
        "  return stance_f"
      ],
      "metadata": {
        "id": "EpcHgvWPq4ox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arabic_stance_new = stance_format(arabic_stance['train'])\n",
        "print(arabic_stance_new[0])\n",
        "\n",
        "synt_english_stance_new = stance_format(synt_english_stance['train'])\n",
        "print(synt_english_stance_new[0])\n",
        "\n",
        "english_tweet_stance_new = stance_format(english_tweet_stance['train'])\n",
        "print(english_tweet_stance_new[0])"
      ],
      "metadata": {
        "id": "aF0gpIHjuPRu",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "with open('synt_english_stance.json', 'w') as f:\n",
        "    json.dump(synt_english_stance_new, f, indent=4)\n",
        "with open('english_tweet_stance.json', 'w') as f:\n",
        "    json.dump(english_tweet_stance_new, f, indent=4)"
      ],
      "metadata": {
        "id": "FmCxxbzP5nVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подгружаем RuArg. Отфильтровываем только те тексты, которые содержат позицию ровно по одной из тем, чтобы у нас не было неоднозначных данных."
      ],
      "metadata": {
        "id": "lUyBFVnkAyD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('train.tsv', sep='\\t')\n",
        "label_columns = ['text_id', 'text', 'masks_stance', 'masks_argument', 'quarantine_stance', 'quarantine_argument', 'vaccines_stance', 'vaccines_argument']\n",
        "def filter_texts(row):\n",
        "    return sum(1 for label in row[label_columns] if label == -1) == 4\n",
        "filtered_df = df[df.apply(filter_texts, axis=1)]"
      ],
      "metadata": {
        "id": "4T6Om1P6A-RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(filtered_df.head())"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9PhRuxzjB59c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ruarg_new = {}\n",
        "ID = 0\n",
        "for _, row in filtered_df.iterrows():\n",
        "  text = row['text']\n",
        "  for label_column in label_columns[2::]:\n",
        "        if row[label_column] == 2:\n",
        "            ruarg_new[ID] = (text, 1)\n",
        "            break\n",
        "        elif row[label_column] == 0:\n",
        "            ruarg_new[ID] = (text, -1)\n",
        "            break\n",
        "        elif row[label_column] == 1:\n",
        "            ruarg_new[ID] = (text, 0)\n",
        "            break\n",
        "  ID += 1\n",
        "\n",
        "print(ruarg_new)"
      ],
      "metadata": {
        "id": "I3s9XllmC5yG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('ruarg_cyr.json', 'w') as f:\n",
        "    json.dump(ruarg_new, f, indent=4, ensure_ascii=False)\n",
        "with open('arabic_stance_ar.json', 'w') as f:\n",
        "    json.dump(arabic_stance_new, f, indent=4, ensure_ascii=False)"
      ],
      "metadata": {
        "id": "VWYlinHFPGch"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Промптинг YandexGPT"
      ],
      "metadata": {
        "id": "QyWZv7Y-fnee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install yandex-chain"
      ],
      "metadata": {
        "collapsed": true,
        "id": "gVL2qy0YfuiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from yandex_chain import YandexLLM\n",
        "\n",
        "LLM = YandexLLM(folder_id=\"b1g697l3fh7u10rq35fd\", iam_token=\"\")\n",
        "print(LLM(\"How are you today?\"))"
      ],
      "metadata": {
        "id": "UUugbE55frDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_en = \"\"\"You are a knowledgeable AI model who is an expert on COVID-19.\n",
        "Please examine the statement in the context below after the word \"STATEMENT:\".\n",
        "Output \"STANCE: 2\" if the author of the statement has a positive stance towards measures put\n",
        "in place by governments to combat COVID-19, such as lockdowns, mask mandates, and vaccination campaigns.\n",
        "If this statement is neutral in sentiment, output \"STANCE: 1\". Output \"STANCE: 0\" if the statement is critical of these measures.\n",
        "Output only \"STANCE: \" and then a number. Do NOT output anything else.{suf}\n",
        "STATEMENT: {statement}\"\"\"\n",
        "\n",
        "ex_en = \"\"\"Some examples:\n",
        "STATEMENT: [USER], doctors work in masks all their lives and everything is fine, but we will have problems with our organs from wearing them for a short time. More problems will come from complications after covid, influenza and acute respiratory viral infections.\n",
        "STANCE: 2\n",
        "STATEMENT: [USER], who can argue, the mask is not even from infection, but from the stupid bureaucrats who ordered not to be allowed into the store without it.\n",
        "STANCE: 0\n",
        "STATEMENT: [USER], the vaccine contains only dead coronavirus cells and nothing else!!!\n",
        "STANCE: 1\"\"\"\n",
        "\n",
        "template_ru = \"\"\"Ты — модель ИИ, которая является экспертом по теме COVID-19.\n",
        "Пожалуйста, изучи утверждение в контексте ниже. Выведи \"ПОЗИЦИЯ: 2\", если автор утверждения положительно\n",
        "относится к мерам, принимаемым правительствами для борьбы с COVID-19, будь то карантин,\n",
        "требование к ношению масок и вакцинация. Если данное утверждение является нейтральным,\n",
        "выведи \"ПОЗИЦИЯ: 1\". Если же в утверждении содержится критическая по отношении к этом мерам позиция,\n",
        "выведи \"ПОЗИЦИЯ: 0\". Выводи только \"ПОЗИЦИЯ:\" и число. НЕ выводи ничего другого.{suf}\n",
        "УТВЕРЖДЕНИЕ: {statement}\"\"\"\n",
        "\n",
        "ex_ru = \"\"\"Некоторые примеры:\n",
        "УТВЕРЖДЕНИЕ: [USER], врачи всю жизнь в масках работают и все нормально, а у нас от кратковременного ношения, прямо, будут проблемы с органами  Больше проблем будет от осложнений после ковида, гриппа и ОРВ.\n",
        "ПОЗИЦИЯ: 2\n",
        "УТВЕРЖДЕНИЕ: [USER], кто спорит, маска очень даже  только не от инфекции, а от тупоголовых чинуш, которые приказали не пускать без неё в магазин.\n",
        "ПОЗИЦИЯ: 0\n",
        "УТВЕРЖДЕНИЕ: [USER], в вакцине только исключительно мертвые клетки короновируса и ничего другого там нет!!!\n",
        "ПОЗИЦИЯ: 1\"\"\"\n",
        "\n",
        "templates = (template_en, template_ru)\n",
        "exs = (ex_en, ex_ru)"
      ],
      "metadata": {
        "id": "bJYHnuCupdzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U scikit-learn"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Dej88vkc5isr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "from sklearn.metrics import f1_score\n",
        "import re\n",
        "\n",
        "def YandexLLM_predict(data, language=\"English\", model=LLM, few_shot=True, templates=templates, exs=exs):\n",
        "\n",
        "  pattern = r'\\d'\n",
        "  actual_labels = []\n",
        "  predicted_labels = []\n",
        "  curr_template = templates[0] if language==\"English\" else templates[1]\n",
        "  curr_ex = exs[0] if few_shot and language==\"English\" else exs[1] if few_shot and language==\"Russian\" else ''\n",
        "  for elem in data:\n",
        "    answer = model(curr_template.format(suf=curr_ex, statement=elem['eng_tr'] if language==\"English\" else elem['rus']))\n",
        "    try:\n",
        "      label = re.findall(pattern, answer)[0]\n",
        "      predicted_labels.append(int(label))\n",
        "      actual_labels.append(int(elem['label']))\n",
        "    except:\n",
        "      continue\n",
        "  # print(predicted_labels[:10])\n",
        "  # print(len(actual_labels), len(predicted_labels))\n",
        "  return(f1_score(actual_labels, predicted_labels, average='macro'))\n",
        "\n",
        "  #\n",
        "  # for (text, l) in random_slice:\n",
        "  #   answer = LLM(template_ru.format(text))\n",
        "    # print(answer)"
      ],
      "metadata": {
        "id": "jQuHTcDhlGlx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "with open('arabic_stance_test.json') as f:\n",
        "    arabic_stance_test = json.load(f)\n",
        "with open('ruarg_test.json') as f:\n",
        "    ruarg_test = json.load(f)\n",
        "with open('tweetstance_test.json') as f:\n",
        "    tweetstance_test = json.load(f)"
      ],
      "metadata": {
        "id": "xxHg6x5Cz8Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arb_zero_shot_eng = YandexLLM_predict(arabic_stance_test, few_shot=False)\n",
        "print(\"Arabic stance zero-shot English F1-score:\", arb_zero_shot_eng)\n",
        "ruarg_zero_shot_eng = YandexLLM_predict(ruarg_test, few_shot=False)\n",
        "print(\"RuArg zero-shot English F1-score:\", ruarg_zero_shot_eng)\n",
        "ts_zero_shot_eng = YandexLLM_predict(tweetstance_test, few_shot=False)\n",
        "print(\"English tweet stance zero-shot English F1-score:\", ts_zero_shot_eng)\n",
        "\n",
        "arb_few_shot_eng = YandexLLM_predict(arabic_stance_test)\n",
        "print(\"Arabic stance few-shot English F1-score:\", arb_few_shot_eng)\n",
        "ruarg_few_shot_eng = YandexLLM_predict(ruarg_test)\n",
        "print(\"RuArg few-shot English F1-score:\", ruarg_few_shot_eng)\n",
        "ts_few_shot_eng = YandexLLM_predict(tweetstance_test)\n",
        "print(\"English tweet stance few-shot English F1-score:\", ts_few_shot_eng)\n",
        "\n",
        "arb_zero_shot_ru = YandexLLM_predict(arabic_stance_test, language=\"Russian\", few_shot=False)\n",
        "print(\"Arabic stance zero-shot Russian F1-score:\", arb_zero_shot_ru)\n",
        "ruarg_zero_shot_ru = YandexLLM_predict(ruarg_test, language=\"Russian\", few_shot=False)\n",
        "print(\"RuArg zero-shot Russian F1-score:\", ruarg_zero_shot_ru)\n",
        "ts_zero_shot_ru = YandexLLM_predict(tweetstance_test, language=\"Russian\", few_shot=False)\n",
        "print(\"English tweet stance zero-shot Russian F1-score:\", ts_zero_shot_ru)\n",
        "\n",
        "arb_few_shot_ru = YandexLLM_predict(arabic_stance_test, language=\"Russian\")\n",
        "print(\"Arabic stance few-shot Russian F1-score:\", arb_few_shot_ru)\n",
        "ruarg_few_shot_ru = YandexLLM_predict(ruarg_test, language=\"Russian\")\n",
        "print(\"RuArg few-shot Russian F1-score:\", ruarg_few_shot_ru)\n",
        "ts_few_shot_ru = YandexLLM_predict(tweetstance_test, language=\"Russian\")\n",
        "print(\"English tweet stance few-shot Russian F1-score:\", ts_few_shot_ru)"
      ],
      "metadata": {
        "id": "ANgtDHoWzwKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Ниже код с промежуточных результатов:"
      ],
      "metadata": {
        "id": "bKegwxAHl7yE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "random_slice_1 = random.sample(list(english_tweet_stance_new.values()), 100)\n",
        "actual_labels_1 = []\n",
        "predicted_labels_1 = []\n",
        "pattern = r'-?\\d'\n",
        "for (text, l) in random_slice_1:\n",
        "  answer = LLM(template_en.format(text))\n",
        "  # print(answer)\n",
        "  try:\n",
        "    label = re.search(pattern, answer).group(0)\n",
        "    predicted_labels_1.append(int(label))\n",
        "    actual_labels_1.append(int(l))\n",
        "  except:\n",
        "    continue"
      ],
      "metadata": {
        "id": "K_tVhzDApqA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f1_score(actual_labels_1, predicted_labels_1, average='macro'))"
      ],
      "metadata": {
        "id": "8IWKqHNbqHEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_slice_2 = random.sample(list(synt_english_stance_new.values()), 100)\n",
        "actual_labels_2 = []\n",
        "predicted_labels_2 = []\n",
        "pattern = r'-?\\d'\n",
        "for (text, l) in random_slice_2:\n",
        "  answer = LLM(template_en.format(text))\n",
        "  # print(answer)\n",
        "  try:\n",
        "    label = re.search(pattern, answer).group(0)\n",
        "    predicted_labels_2.append(int(label))\n",
        "    actual_labels_2.append(int(l))\n",
        "  except:\n",
        "    continue"
      ],
      "metadata": {
        "id": "fZs7gMhFqKee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f1_score(actual_labels_2, predicted_labels_2, average='macro'))"
      ],
      "metadata": {
        "id": "LEuMOrM4qcMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('arabic_stance_aug.json', 'r') as file:\n",
        "    arabic_stance_translated_dict = json.load(file)\n",
        "\n",
        "arabic_stance_only_en = []\n",
        "for key in arabic_stance_translated_dict:\n",
        "  _, text, l = arabic_stance_translated_dict[key]\n",
        "  arabic_stance_only_en.append((text, l))"
      ],
      "metadata": {
        "id": "VnyiMP6oqeaP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_slice_3 = arabic_stance_only_en\n",
        "actual_labels_3 = []\n",
        "predicted_labels_3 = []\n",
        "pattern = r'-?\\d'\n",
        "for (text, l) in random_slice_3:\n",
        "  answer = LLM(template_en.format(text))\n",
        "  # print(answer)\n",
        "  try:\n",
        "    label = re.search(pattern, answer).group(0)\n",
        "    predicted_labels_3.append(int(label))\n",
        "    actual_labels_3.append(int(l))\n",
        "  except:\n",
        "    continue"
      ],
      "metadata": {
        "id": "8aeNq0U5tNRW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f1_score(actual_labels_3, predicted_labels_3, average='macro'))"
      ],
      "metadata": {
        "id": "nyQmvESotbgy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}