{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U langchain transformers bitsandbytes accelerate langchain-community"
      ],
      "metadata": {
        "id": "tHLFaKjrAIW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKGsywWd_pV-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from langchain import HuggingFacePipeline, PromptTemplate, LLMChain\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "qsIAI9C7pURi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token)"
      ],
      "metadata": {
        "id": "3T_v9nDLpGi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "model_name = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
        "\n",
        "model_4bit = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"cuda\",quantization_config=quantization_config,)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "9jpB7t-S_8fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_inst = pipeline(\n",
        "        \"text-generation\",\n",
        "        model=model_4bit,\n",
        "        tokenizer=tokenizer,\n",
        "        use_cache=True,\n",
        "        device_map=\"auto\",\n",
        "        max_length=2500,\n",
        "        do_sample=True,\n",
        "        top_k=5,\n",
        "        num_return_sequences=1,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        ")"
      ],
      "metadata": {
        "id": "ZXqaw2nXK9BF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline(pipeline=pipeline_inst)"
      ],
      "metadata": {
        "id": "NKQiFq8vH0Eg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "GQ9KkLp6Crwi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template_en = \"\"\"<s>[INST]You are a knowledgeable AI model who is an expert on COVID-19. Please examine the statement in the context below after the word \"STATEMENT:\". Output \"STANCE: 2\" if the author of the statement has a positive stance towards measures put in place by governments to combat COVID-19, such as lockdowns, mask mandates, and vaccination campaigns. If this statement is neutral in sentiment, output \"STANCE: 1\". Output \"STANCE: 0\" if the statement is critical of these measures. Output only \"STANCE: \" and then a number. Do NOT output anything else.{suf}\n",
        "STATEMENT: {statement}[/INST]</s>\n",
        "\"\"\"\n",
        "\n",
        "ex_en = \"\"\"\n",
        "Some examples:\n",
        "STATEMENT: [USER], doctors work in masks all their lives and everything is fine, but we will have problems with our organs from wearing them for a short time. More problems will come from complications after covid, influenza and acute respiratory viral infections.\n",
        "STANCE: 2\n",
        "STATEMENT: [USER], who can argue, the mask is not even from infection, but from the stupid bureaucrats who ordered not to be allowed into the store without it.\n",
        "STANCE: 0\n",
        "STATEMENT: [USER], the vaccine contains only dead coronavirus cells and nothing else!!!\n",
        "STANCE: 1\"\"\"\n",
        "\n",
        "template_ru = \"\"\"<s>[INST]Ты — модель ИИ, которая является экспертом по теме COVID-19. Пожалуйста, изучи утверждение в контексте ниже. Выведи \"ПОЗИЦИЯ: 2\", если автор утверждения положительно относится к мерам, принимаемым правительствами для борьбы с COVID-19, будь то карантин, требование к ношению масок и вакцинация. Если данное утверждение является нейтральным, выведи \"ПОЗИЦИЯ: 1\". Если же в утверждении содержится критическая по отношении к этом мерам позиция, выведи \"ПОЗИЦИЯ: 0\". Выводи только \"ПОЗИЦИЯ:\" и число. НЕ выводи ничего другого.{suf}\n",
        "УТВЕРЖДЕНИЕ: {statement}[/INST]</s>\n",
        "\"\"\"\n",
        "\n",
        "ex_ru = \"\"\"\n",
        "Некоторые примеры:\n",
        "УТВЕРЖДЕНИЕ: [USER], врачи всю жизнь в масках работают и все нормально, а у нас от кратковременного ношения, прямо, будут проблемы с органами  Больше проблем будет от осложнений после ковида, гриппа и ОРВ.\n",
        "ПОЗИЦИЯ: 2\n",
        "УТВЕРЖДЕНИЕ: [USER], кто спорит, маска очень даже  только не от инфекции, а от тупоголовых чинуш, которые приказали не пускать без неё в магазин.\n",
        "ПОЗИЦИЯ: 0\n",
        "УТВЕРЖДЕНИЕ: [USER], в вакцине только исключительно мертвые клетки короновируса и ничего другого там нет!!!\n",
        "ПОЗИЦИЯ: 1\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "CXi6ZwG1EVxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(statement, template, suf=''):\n",
        "  prompt = PromptTemplate(template=template, input_variables=[\"statement\", \"suf\"])\n",
        "  chain = prompt | llm | StrOutputParser()\n",
        "  response = chain.invoke({\"statement\": statement, \"suf\": suf})\n",
        "  return response.split('\\n')[-1]"
      ],
      "metadata": {
        "id": "8B8cUuPPJMtO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "filenames = ['tweetstance_test.json', 'ruarg_test.json', 'arabic_stance_test.json']\n",
        "# filenames = ['ruarg_test.json']\n",
        "# filenames = ['arabic_stance_test.json']\n",
        "# filenames = ['tweetstance_test.json', 'ruarg_test.json']"
      ],
      "metadata": {
        "id": "0e8YsF4YUtKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_res = []"
      ],
      "metadata": {
        "id": "xa2hHtH50V_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.metrics import f1_score\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "stance_prog = re.compile(r'STANCE: (-?\\d)')\n",
        "\n",
        "for filename in filenames:\n",
        "  cur_res =[]\n",
        "  print(filename)\n",
        "  with open(filename, 'r') as fin:\n",
        "    data = json.load(fin)\n",
        "  true = [int(x['label']) for x in data]\n",
        "  # English zero shot\n",
        "  en_zs = []\n",
        "  for x in tqdm(data):\n",
        "    resp = generate_response(template=template_en, statement=x['eng_tr'])\n",
        "    en_zs.append(resp)\n",
        "    # print(resp)\n",
        "    # ans = stance_prog.findall(resp)[0]\n",
        "    # en_zs.append(int(ans))\n",
        "  cur_res.append(en_zs)\n",
        "  # print(f1_score(y_true=true, y_pred=en_zs))\n",
        "  # English few shot\n",
        "  en_fs = []\n",
        "  for x in tqdm(data):\n",
        "    resp = generate_response(template=template_en, statement=x['eng_tr'], suf=ex_en)\n",
        "    en_fs.append(resp)\n",
        "    # ans = stance_prog.findall(resp)[0]\n",
        "    # en_zs.append(int(ans))\n",
        "  cur_res.append(en_fs)\n",
        "  # print(f1_score(y_true=true, y_pred=en_fs))\n",
        "  # Russian zero shot\n",
        "  ru_zs = []\n",
        "  for x in tqdm(data):\n",
        "    resp = generate_response(template=template_ru, statement=x['rus'])\n",
        "    # ans = stance_prog.findall(resp)[0]\n",
        "    # ru_zs.append(int(ans))\n",
        "    ru_zs.append(resp)\n",
        "  cur_res.append(ru_zs)\n",
        "  # print(f1_score(y_true=true, y_pred=ru_zs))\n",
        "  # Russian few shot\n",
        "  ru_fs = []\n",
        "  for x in tqdm(data):\n",
        "    resp = generate_response(template=template_ru, statement=x['rus'], suf=ex_ru)\n",
        "    # ans = stance_prog.findall(resp)[0]\n",
        "    # ru_fs.append(int(ans))\n",
        "    ru_fs.append(resp)\n",
        "  cur_res.append(ru_fs)\n",
        "  all_res.append(cur_res)\n",
        "  # print(f1_score(y_true=true, y_pred=ru_fs))"
      ],
      "metadata": {
        "id": "FN37OKuwYPYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "id": "dh_NYgWl9s5_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "exts = ['en_zs', 'en_fs', 'ru_zs', 'ru_fs']\n",
        "\n",
        "for i, x in enumerate(filenames[:len(all_res)]):\n",
        "  for j, ext in enumerate(exts):\n",
        "    csv_filename = x.replace('.json', '_' + ext + '.csv')\n",
        "    with open(csv_filename, 'w') as fout:\n",
        "      csv.writer(fout).writerows([[y] for y in all_res[i][j]])"
      ],
      "metadata": {
        "id": "fgnY1LqJ0W7n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}