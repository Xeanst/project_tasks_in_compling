{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recap: тема, задачи и гипотеза исследования\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "m1UNT9vWMVSh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тема проекта:\n",
        "> Автоматическое определение троллинга в текстах при помощи различных языковых моделей\n",
        "\n",
        "Основная гипотеза:\n",
        "\n",
        "---\n",
        "\n",
        "> **модели лучше справятся с классификацией открытого (overt) троллинга, так как он содержит более явные языковые маркеры**\n",
        "\n",
        "---\n",
        "\n",
        "Основными задачами нашего проекта являлось:\n",
        "\n",
        "*   Дополнить исходный датасет нейтральными примерами (без троллинга)\n",
        "*   Посмотреть, как различные модели справятся с выявлением троллинга в текстах в целом, сравнить результаты разных моделей\n",
        "*   Посмотреть, как модели справятся с определением типа троллинга, сравнить результаты с исследованием [Lee et al. 2022]. ??? будем ли мы такое делать в итоге\n",
        "*   Проанализировать ошибки, чтобы проверить гипотезу\n",
        "\n",
        "\n",
        "Для проведения исследования мы выбрали метод zero-shot: в обеих частях проекта классификация проводилась без дополнительного обучения. Для проекта мы выбрали две модели:\n",
        "* RoBERTa: решение задачи классификации при помощи предсказания наиболее вероятного слова на месте маски в промпте\n",
        "* Mistral: решение задачи классификации при помощи получения ответов от модели\n",
        "\n"
      ],
      "metadata": {
        "id": "fXHvgNRVM85e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дополнение исходного датасета\n",
        "\n",
        "Для решения задачи автоматического определения наличия троллинга в тексте нам пришлось дополнять исходный датасет нейтральными примерами (т.е., примерами без троллинга), поскольку исходный датасет содержал только троллинг.\n",
        "\n",
        "Мы отбирали примеры так же, как и в датасете с троллингом, состоящие из контекста -- часто, вопроса --  и ответа на этот вопрос (мы набирали примеры из вопросно-ответных датасетов, включающих в себя примеры текстов с различных форумов и в т.ч. реддита). Количество набранных в итоге примеров -- 600, но на практике мы использовали лишь 300 из них (поскольку иначе смешанный датасет получался слишком большим, и модель очень долго считала ответы)\n",
        "\n",
        "Набранные нейтральные примеры при необходимости можно увидеть [здесь](https://docs.google.com/spreadsheets/d/1inZ-oUb90I_EdEmv7_qidC9BD0DX15PZP4t0WmqeZvQ/edit?gid=1395045770#gid=1395045770)"
      ],
      "metadata": {
        "id": "08xiNEFpPDGQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mask-prompting классификация типа троллинга (без учета контекста): roberta"
      ],
      "metadata": {
        "id": "nXNK2_UWlGJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве первой модели мы использовали RoBERTa-large. Работа проводилась по следующим этапам:\n",
        "\n",
        "* классификация через mask-промптинг (для каждого текста применялся шаблон с < mask >, затем модель предсказывала наиболее вероятные токены на ее месте)\n",
        "* сбор и категоризация предсказаний\n",
        "* оценка качества на тестовой выборке"
      ],
      "metadata": {
        "id": "oSSCA7nwSK5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets sacremoses"
      ],
      "metadata": {
        "id": "QA_uBGsclGJ9",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создание датасета"
      ],
      "metadata": {
        "id": "uUrk8sxtP9Zl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "with open(\"test (2).json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df.head())"
      ],
      "metadata": {
        "id": "IGQKTdbRlGJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sacremoses import MosesDetokenizer\n",
        "\n",
        "detokenizer = MosesDetokenizer().detokenize\n",
        "texts = [detokenizer(elem.split()).lower() for elem in df['Troll']]\n",
        "labels = [elem for elem in df['TrollL']]\n",
        "for i in range(5):\n",
        "    print(texts[i], labels[i])"
      ],
      "metadata": {
        "id": "brORmE19lGJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "MODEL_NAME = \"roberta-large\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelWithLMHead.from_pretrained(MODEL_NAME).to(\"cuda\")"
      ],
      "metadata": {
        "id": "Y6Uq_rOmlGJ-",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Паттерн и классы слов"
      ],
      "metadata": {
        "id": "NuPUBgrFQv10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для начала посмотрим, какие слова будет предлагать модель на месте < mask >. Придумаем характерные предложения:"
      ],
      "metadata": {
        "id": "kJZmnAvMD3lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# сначала будет идти overt trolling, потом covert\n",
        "\n",
        "trial = [\"Imagine being this stupid and still using the internet\",\n",
        "         \"Only idiots believe in vaccines. Enjoy your 5G mind control, bitch\",\n",
        "         \"Did you learn English from a cereal box?\",\n",
        "         \"Oh wow, another useless opinion from someone who’s clearly unemployed\",\n",
        "         \"Keep crying, maybe someone will care\",\n",
        "         \"You’re so brave for sharing such a wrong opinion publicly!\",\n",
        "         \"I’d agree with you, but then we’d both be wrong\",\n",
        "         \"Wow, you really did your ‘research’ on Wikipedia, huh?\",\n",
        "         \"Your logic is… unique. Let’s leave it at that.\",\n",
        "         \"It’s adorable how confident you are despite being clueless\"]"
      ],
      "metadata": {
        "id": "F-i63q-XlGJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PATTERN = \"{0} This message has an intention of <mask>.\"\n",
        "# PATTERN = \"{0} This response <mask> people.\"\n",
        "# PATTERN = \"{0} If I've recieved this message I would be <mask>.\"\n",
        "# PATTERN = \"{0} A person who wrote this message was <mask>.\"\n",
        "# PATTERN = \"{0} А given message is an example of <mask> trolling.\"\n",
        "PATTERN = \"Analyze the following message and classify its trolling type based on these definitions: Overt trolling is direct aggression, insults, or obvious provocation. Covert trolling is hidden malice, sarcasm, or passive-aggressive language. Message: {0}. This message contains <mask>.\"\n",
        "\n",
        "def format_with_pattern(tokenizer, pattern, text):\n",
        "    augmented_text = pattern.format(text).replace(\"<mask>\", tokenizer.mask_token)\n",
        "    tokenization = tokenizer(augmented_text)[\"input_ids\"]\n",
        "    mask_index = tokenization.index(tokenizer.mask_token_id)\n",
        "    return tokenization, mask_index\n",
        "\n",
        "def score_with_model(tokenization, index, device=\"cuda\"):\n",
        "    tensor = torch.LongTensor([tokenization]).to(device)\n",
        "    with torch.no_grad():\n",
        "        model_output = model(tensor)\n",
        "    logits = model_output.logits[0]\n",
        "    log_probs = torch.log_softmax(logits[mask_index], dim=-1)\n",
        "    return log_probs"
      ],
      "metadata": {
        "id": "TFvtFnPblGJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "for text in trial:\n",
        "    print(text)\n",
        "    tokenization, mask_index = format_with_pattern(tokenizer, PATTERN, text)\n",
        "    log_probs = score_with_model(tokenization, mask_index)\n",
        "    top_probs, top_indexes = torch.topk(log_probs, k=5, dim=-1)\n",
        "    for log_prob, index in zip(top_probs, top_indexes):\n",
        "        print(tokenizer.decode([index]), np.exp(log_prob.item()))\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "lO9C07iNlGJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Даже перебрав разные промпты, не удалось найти тот, который бы выдавал разные результаты для overt/covert троллинга.\n",
        "Попробуем взять тексты из датасета, чтобы посмотреть, изменится ли что-то."
      ],
      "metadata": {
        "id": "loYGMNflEsXH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trial_2 = [\"you all are such babies about tank thursdays. not nearly as bad as everyone says.\",\n",
        "         \"It's just internalized homophobia. Support queer liberation instead of queer assimilation. Systems of colonial, heteronormative white supremacy have nothing good to offer you unless you're the kind of rich Caucasian that has private jet money.\",\n",
        "         \"You believe it would have been OK for your mom to have killed you since you were the victim of a rape?\",\n",
        "         \"get him a ps5...he'll probably marry you\",\n",
        "         \"I am sorry but this just seems petty, you and your wife have been married for several years but it seems to me you still haven't gotten over her ex.   Otherwise i don't see the point of ''guys my wife was married to Mark Carrano and she dumped him'' than it being a gotcha moment.\",\n",
        "         \"Ya'll wanted something gay like Sora didn't you? Well I for one am thrilled to have a new cool looking female fighter, don't get much of those. Arms chick didn't count cause Arms is shit, goofy ass noodle arm flailing nonsense lol.\",\n",
        "         ]"
      ],
      "metadata": {
        "id": "TFwozXD2FVqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in trial_2:\n",
        "    print(text)\n",
        "    tokenization, mask_index = format_with_pattern(tokenizer, PATTERN, text)\n",
        "    log_probs = score_with_model(tokenization, mask_index)\n",
        "    top_probs, top_indexes = torch.topk(log_probs, k=5, dim=-1)\n",
        "    for log_prob, index in zip(top_probs, top_indexes):\n",
        "        print(tokenizer.decode([index]), np.exp(log_prob.item()))\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "UERmALlTFgNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "К сожалению, результат не изменился.\n",
        "Возможно, такой метод не подходит для этой классификации."
      ],
      "metadata": {
        "id": "nPbFbTUBFwrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mask-prompting детекция троллинга (без учета контекста): roberta"
      ],
      "metadata": {
        "id": "goLzDbOylGJ_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Создание датасета"
      ],
      "metadata": {
        "id": "PYwlhLMZTGWZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для задачи детекции троллинга среди нейтральных текстов понадобится смешать собранный нами датасет с примерами троллинга:"
      ],
      "metadata": {
        "id": "jS4Cts6yGC_G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "with open(\"test (2).json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# df.to_csv(\"output.csv\", index=False)"
      ],
      "metadata": {
        "id": "aWdA3t_jlGKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_neut = pd.read_csv('neut.csv')\n",
        "contexts = [x for x in df_neut['context']]\n",
        "responses = [x for x in df_neut['response']]\n",
        "labels = [0 for x in range(len(contexts))]\n",
        "neut = [[x, responses[pos], labels[pos], 0] for pos, x in enumerate(contexts[:300])]\n",
        "print(df_neut.head())\n",
        "print()\n",
        "print(neut[:3])"
      ],
      "metadata": {
        "id": "KEMxRA9RlGKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def make_dataset(df, neut):\n",
        "  titles = [x for x in df['Title']]\n",
        "  bodies = [x for x in df['Post']]\n",
        "  contexts = [x + ' ' + bodies[pos] for pos, x in enumerate(titles)]\n",
        "  trolls = [x for x in df['Troll']]\n",
        "  troll_labels = [x for x in df['TrollL']]\n",
        "  labels = [1 for x in range(len(contexts))]\n",
        "  dataset_tr = [[x, trolls[pos], labels[pos], troll_labels[pos]] for pos, x in enumerate(contexts[:300])]\n",
        "  dataset = dataset_tr + neut\n",
        "\n",
        "  return dataset\n",
        "\n",
        "\n",
        "test = make_dataset(df, neut)\n",
        "random.seed(67)\n",
        "random.shuffle(test)\n",
        "\n",
        "print(len(test))\n",
        "for x in test[:10]:\n",
        "  print(x)\n",
        "\n",
        "print()\n",
        "test_labels = [x[2] for x in test]\n",
        "print(test_labels[:10])"
      ],
      "metadata": {
        "id": "eEUJwhLYlGKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "О - нейтральные сообщения, 1 - троллинг."
      ],
      "metadata": {
        "id": "T7TuXHuXJR16"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sacremoses import MosesDetokenizer\n",
        "\n",
        "detokenizer = MosesDetokenizer().detokenize\n",
        "texts = [detokenizer(elem[1].split()).lower() for elem in test]\n",
        "labels = [elem for elem in test_labels]\n",
        "for i in range(10):\n",
        "    print(texts[i], labels[i])"
      ],
      "metadata": {
        "id": "t0l2zZdRlGKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model и tokenizer останутся теми же."
      ],
      "metadata": {
        "id": "Z0EltGV3GlKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "# MODEL_NAME = \"roberta-large\"\n",
        "# tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "# model = AutoModelWithLMHead.from_pretrained(MODEL_NAME).to(\"cuda\")"
      ],
      "metadata": {
        "id": "wIH2qCZ5lGKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Придумаем фразы для проверки модели:"
      ],
      "metadata": {
        "id": "s48xAVqtHL48"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Паттерн и классы слов"
      ],
      "metadata": {
        "id": "YmAl4pmmVXYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# сначала будут идти 6 фраз с троллингом (3 с overt, 3 - с covert), потом 4 нейтральных фразы\n",
        "\n",
        "trial = [\"Only idiots believe in vaccines. Enjoy your 5G mind control, bitch\",\n",
        "         \"Are you fucking stupid or just mentally retarded?\",\n",
        "         \"You clearly dont care about your child if you vaccinate him. Jut so you wait he gets autism or somethin worse.\",\n",
        "         \"Oh wow, another useless opinion from someone who’s clearly unemployed\",\n",
        "         \"This is your 'research'? I've seen TikTok comments with better citations\",\n",
        "         \"Great, another park while our roads look like Swiss cheese. Priorities much?\",\n",
        "         \"I see your point about renewable energy costs. The 2023 MIT study actually shows solar prices dropped 30%\",\n",
        "         \"Just to double-check: when you say ‘remote work doesn’t work,’ are you referring to productivity or team cohesion?\",\n",
        "         \"For that GPU issue, try updating to driver version 546.33 - it fixed similar problems for others.\",\n",
        "         \"The character development in Chapter 2 is brilliant! Though the dialogue on page 5 feels a bit rushed\"]"
      ],
      "metadata": {
        "id": "QSlhIvqBlGKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATTERN = \"{0} This message has an intention of <mask>.\"\n",
        "# PATTERN = \"{0} If I've recieved this message I would be <mask>.\""
      ],
      "metadata": {
        "id": "Cq9KmT_BlGKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "for text in trial:\n",
        "    print(text)\n",
        "    tokenization, mask_index = format_with_pattern(tokenizer, PATTERN, text)\n",
        "    log_probs = score_with_model(tokenization, mask_index)\n",
        "    top_probs, top_indexes = torch.topk(log_probs, k=5, dim=-1)\n",
        "    for log_prob, index in zip(top_probs, top_indexes):\n",
        "        print(tokenizer.decode([index]), np.exp(log_prob.item()))\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "sDxuFSK7lGKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь метки различаются. Составим списки характерных слов, чтобы модель могла различать два класса.  "
      ],
      "metadata": {
        "id": "3sODnFn9G1Qz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trolling = [\"violence\", \"abuse\", \"humor\", \"harm\", \"malice\", \"cruelty\", \"abuse\", \"trolling\", \"bullying\", \"harassment\", \"mockery\", \"change\"]\n",
        "neutral = [\"truth\", \"accuracy\", \"reality\", \"clarity\", \"helping\", \"help\", \"updating\", \"improvement\", \"speaking\", \"love\"]\n",
        "\n",
        "def score_sentiment(log_probs, good_words, bad_words):\n",
        "    good_indexes = [tokenizer(\" \"+word, add_special_tokens=False)[\"input_ids\"][0] for word in good_words]\n",
        "    bad_indexes = [tokenizer(\" \"+word, add_special_tokens=False)[\"input_ids\"][0] for word in bad_words]\n",
        "    return torch.logsumexp(log_probs[good_indexes], dim=-1)-torch.logsumexp(log_probs[good_indexes+bad_indexes], dim=-1)\n",
        "\n",
        "for text in trial:\n",
        "    tokenization, mask_index = format_with_pattern(tokenizer, PATTERN, text)\n",
        "    log_probs = score_with_model(tokenization, mask_index)\n",
        "    prob = score_sentiment(log_probs, good_words=neutral, bad_words=trolling)\n",
        "    print(text, f\"{100*np.exp(prob.item()):.2f}\")"
      ],
      "metadata": {
        "id": "LazCDFyrlGKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель хорошо справилась с этими примерами (ближе к 0 - троллинг, ближе к 1 - обычные сообщения). Только третье предложение с конца разобрано неправильно."
      ],
      "metadata": {
        "id": "PnUo-e3llGKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Замер качества и метрик по классам"
      ],
      "metadata": {
        "id": "1MWvNECZThKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def score_sentiment(log_probs, good_words, bad_words):\n",
        "    good_indexes = [tokenizer(\" \"+word, add_special_tokens=False)[\"input_ids\"][0] for word in good_words]\n",
        "    bad_indexes = [tokenizer(\" \"+word, add_special_tokens=False)[\"input_ids\"][0] for word in bad_words]\n",
        "    return torch.logsumexp(log_probs[...,good_indexes], dim=-1)-torch.logsumexp(log_probs[...,good_indexes+bad_indexes], dim=-1)\n",
        "\n",
        "def score_batch_with_model(input_ids, indexes, pad_index=0, good_words=None, bad_words=None, device=\"cuda\"):\n",
        "    if good_words is None:\n",
        "        good_words = neutral\n",
        "    if bad_words is None:\n",
        "        bad_words = trolling\n",
        "    L = max(len(x) for x in input_ids)\n",
        "    input_ids = [elem + [pad_index] * (L-len(elem)) for elem in input_ids]\n",
        "    tensor = torch.LongTensor(input_ids).to(device)\n",
        "    with torch.no_grad():\n",
        "        model_output = model(tensor)\n",
        "    logits = model_output.logits[np.arange(len(input_ids)), indexes]\n",
        "    all_log_probs = torch.log_softmax(logits, dim=-1)\n",
        "    log_probs = score_sentiment(all_log_probs, good_words=good_words, bad_words=bad_words)\n",
        "    return log_probs, all_log_probs"
      ],
      "metadata": {
        "id": "Vd0BulgllGKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "input_ids, indexes = [], []\n",
        "for text in texts:\n",
        "    tokenization, mask_index = format_with_pattern(tokenizer, PATTERN, text)\n",
        "    input_ids.append(tokenization)\n",
        "    indexes.append(mask_index)\n",
        "log_probs = []\n",
        "for start in tqdm(range(0, len(input_ids), BATCH_SIZE)):\n",
        "    curr_input_ids = input_ids[start:start+BATCH_SIZE]\n",
        "    curr_indexes = indexes[start:start+BATCH_SIZE]\n",
        "    curr_log_probs, _ = score_batch_with_model(curr_input_ids, curr_indexes, pad_index=tokenizer.pad_token_id)\n",
        "    log_probs.extend(curr_log_probs)\n",
        "log_probs = np.array([x.item() for x in log_probs])"
      ],
      "metadata": {
        "id": "ZfojRKNclGKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
        "\n",
        "pred_labels = []\n",
        "for i in log_probs:\n",
        "  if  np.exp(i)>= 0.5:\n",
        "    pred_labels.append(0)\n",
        "  else:\n",
        "    pred_labels.append(1)\n",
        "\n",
        "print(pred_labels[1:10])\n",
        "\n",
        "print(f\"{100*accuracy_score(labels, pred_labels):.2f}\")"
      ],
      "metadata": {
        "id": "zzVhw0FQlGKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "target_names = ['class 0', 'class 1'] #0 - нейтральные сообщения, 1 - троллинг\n",
        "print(classification_report(labels, pred_labels, target_names=target_names))"
      ],
      "metadata": {
        "id": "ruozWHAflGKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(labels[:600], pred_labels)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (4,4)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['neutral', 'trolling'])\n",
        "disp.plot(cmap=plt.cm.YlGn)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "n4VMwFizK1Vx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_labels = []\n",
        "for i in log_probs:\n",
        "  if  np.exp(i)>= 0.7: #поменяем значение с 0.5 на 0.7, чтобы сместить границу классов (больше примеров будет попадать в разряд троллинга)\n",
        "    pred_labels.append(0)\n",
        "  else:\n",
        "    pred_labels.append(1)\n",
        "print(pred_labels[1:10])\n",
        "print(f\"{100*accuracy_score(labels, pred_labels):.2f}\")"
      ],
      "metadata": {
        "id": "_F5tQPLMlGKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['class 0', 'class 1'] #0 - нейтральные сообщения, 1 - троллинг\n",
        "print(classification_report(labels, pred_labels, target_names=target_names))"
      ],
      "metadata": {
        "id": "AsFvLMuaDjyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(labels[:600], pred_labels)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (4,4)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['neutral', 'trolling'])\n",
        "disp.plot(cmap=plt.cm.YlGn)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "r9QCrPC4LX43"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_labels = []\n",
        "for i in log_probs:\n",
        "  if  np.exp(i)>= 0.3: #поменяем значение на 0.3 чтобы больше примеров попадало в разряд нейтральных\n",
        "    pred_labels.append(0)\n",
        "  else:\n",
        "    pred_labels.append(1)\n",
        "print(pred_labels[1:10])\n",
        "print(f\"{100*accuracy_score(labels, pred_labels):.2f}\")"
      ],
      "metadata": {
        "id": "DGzEYKzQlGKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['class 0', 'class 1'] #0 - нейтральные сообщения, 1 - троллинг\n",
        "print(classification_report(labels, pred_labels, target_names=target_names))"
      ],
      "metadata": {
        "id": "ONa2OC6aDnje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(labels[:600], pred_labels)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (4,4)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['neutral', 'trolling'])\n",
        "disp.plot(cmap=plt.cm.YlGn)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "LSSHtdFMLaAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Результат немного улучшился, но это все равно не сильно лучше случайного распределения."
      ],
      "metadata": {
        "id": "tnxeXYsYlGKE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Расширение списка слов за счет добавления предложений из датасета"
      ],
      "metadata": {
        "id": "H0XlJxltUxWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Снова попробуем взять предложения из датасета, а не из головы:"
      ],
      "metadata": {
        "id": "_b_pqTh2UwWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# сначала будут идти 6 фраз с троллингом (3 с overt, 3 - с covert), потом 4 нейтральных фразы\n",
        "\n",
        "trial_2 = [\"you all are such babies about tank thursdays. not nearly as bad as everyone says.\",\n",
        "         \"It's just internalized homophobia. Support queer liberation instead of queer assimilation. Systems of colonial, heteronormative white supremacy have nothing good to offer you unless you're the kind of rich Caucasian that has private jet money.\",\n",
        "         \"You believe it would have been OK for your mom to have killed you since you were the victim of a rape?\",\n",
        "         \"get him a ps5...he'll probably marry you\",\n",
        "         \"I am sorry but this just seems petty, you and your wife have been married for several years but it seems to me you still haven't gotten over her ex.   Otherwise i don't see the point of ''guys my wife was married to Mark Carrano and she dumped him'' than it being a gotcha moment.\",\n",
        "         \"Ya'll wanted something gay like Sora didn't you? Well I for one am thrilled to have a new cool looking female fighter, don't get much of those. Arms chick didn't count cause Arms is shit, goofy ass noodle arm flailing nonsense lol.\",\n",
        "         \"delete it then reboot, at grub choose recovery mode, then choose 'xfix'\",\n",
        "         \"To get more data the radio needs to work harder, which takes more power. The radio is the second largest power consumer in your phone behind the screen, so if you're say streaming netflix you're killing your battery because you're asking the radio to do a ton of work and then using it to watch a movie.\",\n",
        "         \"Most of the jobs in the health industry. Speech pathologist, occupational therapist, respiratory therapy, etc. You only really hear about doctors, nurses, pharmacists, and physio therapists.\",\n",
        "         \"I personally have fallen in love with Shadow Fight 2 because of the variety of the weapons and the unique bosses. Also, any of the Infinity Blade games (if you’re willing to spend a few bucks to grab them).\"]"
      ],
      "metadata": {
        "id": "wfGR_narorti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATTERN = \"{0} This message has an intention of <mask>.\"\n",
        "# PATTERN = \"{0} If I've recieved this message I would be <mask>.\"\n",
        "# PATTERN = \"{0} A person who wrote this message had <mask> intent.\"\n",
        "# PATTERN = \"{0} A person who wrote this message wanted to <mask>.\""
      ],
      "metadata": {
        "id": "0x6Yh_r2sU1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text in trial_2:\n",
        "    print(text)\n",
        "    tokenization, mask_index = format_with_pattern(tokenizer, PATTERN, text)\n",
        "    log_probs = score_with_model(tokenization, mask_index)\n",
        "    top_probs, top_indexes = torch.topk(log_probs, k=5, dim=-1)\n",
        "    for log_prob, index in zip(top_probs, top_indexes):\n",
        "        print(tokenizer.decode([index]), np.exp(log_prob.item()))\n",
        "    print(\"\")"
      ],
      "metadata": {
        "id": "kBxP7yrrsXmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Дополним список слов:"
      ],
      "metadata": {
        "id": "WoZExRf5LlnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trolling = [\"violence\", \"abuse\", \"humor\", \"harm\", \"malice\", \"cruelty\", \"abuse\", \"trolling\", \"bullying\",\n",
        "            \"harassment\", \"mockery\", \"change\", \"humour\", \"genocide\", \"violence\", \"spam\", \"deception\",\n",
        "            \"revenge\", \"shock\"]\n",
        "neutral = [\"truth\", \"accuracy\", \"reality\", \"clarity\", \"helping\", \"help\", \"updating\", \"improvement\",\n",
        "           \"speaking\", \"love\", \"succeeding\", \"fixing\", \"listening\", \"urgency\", \"sorts\", \"education\",\n",
        "           \"accuracy\", \"recommendation\", \"praise\", \"sharing\"]\n",
        "\n",
        "for text in trial_2:\n",
        "    tokenization, mask_index = format_with_pattern(tokenizer, PATTERN, text)\n",
        "    log_probs = score_with_model(tokenization, mask_index)\n",
        "    prob = score_sentiment(log_probs, good_words=neutral, bad_words=trolling)\n",
        "    print(text, f\"{100*np.exp(prob.item()):.2f}\")"
      ],
      "metadata": {
        "id": "RZvLtorDLDfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель разобрала все примеры верно (если брать 50 за границу классов)."
      ],
      "metadata": {
        "id": "VA2pBRcTMbNH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Замер качества и метрик по классам"
      ],
      "metadata": {
        "id": "5YfgjVn2VDPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "input_ids, indexes = [], []\n",
        "for text in texts:\n",
        "    tokenization, mask_index = format_with_pattern(tokenizer, PATTERN, text)\n",
        "    input_ids.append(tokenization)\n",
        "    indexes.append(mask_index)\n",
        "log_probs = []\n",
        "for start in tqdm(range(0, len(input_ids), BATCH_SIZE)):\n",
        "    curr_input_ids = input_ids[start:start+BATCH_SIZE]\n",
        "    curr_indexes = indexes[start:start+BATCH_SIZE]\n",
        "    curr_log_probs, _ = score_batch_with_model(curr_input_ids, curr_indexes, pad_index=tokenizer.pad_token_id)\n",
        "    log_probs.extend(curr_log_probs)\n",
        "log_probs = np.array([x.item() for x in log_probs])"
      ],
      "metadata": {
        "id": "d_FqLtcsM3oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_labels = []\n",
        "for i in log_probs:\n",
        "  if  np.exp(i)>= 0.5:\n",
        "    pred_labels.append(0)\n",
        "  else:\n",
        "    pred_labels.append(1)\n",
        "\n",
        "print(pred_labels[1:10])\n",
        "\n",
        "print(f\"{100*accuracy_score(labels, pred_labels):.2f}\")"
      ],
      "metadata": {
        "id": "zEq9rS3DNM82"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "target_names = ['class 0', 'class 1'] #0 - нейтральные сообщения, 1 - троллинг\n",
        "print(classification_report(labels, pred_labels, target_names=target_names))"
      ],
      "metadata": {
        "id": "YZH-vW0lNU-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(labels[:600], pred_labels)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (4,4)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['neutral', 'trolling'])\n",
        "disp.plot(cmap=plt.cm.YlGn)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1b2gkdeJLfR3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь нет смысла двигать границу классов. Результат хоть и улучшился, но все еще плохой."
      ],
      "metadata": {
        "id": "3a5JgccDNv3y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вывод\n",
        "Для классификации overt/covert троллинга и в принципе его детекции без учета контекста не подходит метод mask-промптинга. Результат выходит чуть лучше случайного распределения. В теории, можно было бы подобрать больше промптов и выделить больше слов для категоризации, но вряд ли результат выйдет достаточно качественным."
      ],
      "metadata": {
        "id": "hjrd9Mv4N9YO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-shot детекция троллинга: mistral"
      ],
      "metadata": {
        "id": "8gf6BcF4OKFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве другой модели мы решили взять Mistral. Работа проводилась по следующим этапам:\n",
        "* получение ответов от модели (запрашиваемый формат ответа: 1/0 - наличие vs. отсутствие троллинга) с помощью промпта\n",
        "* оценка качества на сформированной тестовой выборке\n",
        "* анализ ошибочных ответов, чтобы подтвердить/опровергнуть первоначальную гипотезу (см. выше)\n",
        "* эксперименты по подбору промпта с целью улучшить качество классификации\n",
        "* сравнение результатов с другими моделями и методами."
      ],
      "metadata": {
        "id": "l8NDk1k_ONsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --quiet -U mistralai"
      ],
      "metadata": {
        "id": "8SodO0lmfc2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open (\"key.txt\", \"r\") as fin:\n",
        "#   api_key = fin.readline()"
      ],
      "metadata": {
        "id": "9_hkXWuRqIBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from mistralai import Mistral\n",
        "\n",
        "def run_mistral(user_message, api_key, model=\"mistral-large-latest\"):\n",
        "    client = Mistral(api_key=api_key)\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        "    chat_response = client.chat.complete(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        # stop=[\".\"]\n",
        "    )\n",
        "    return chat_response.choices[0].message.content"
      ],
      "metadata": {
        "id": "2oPsyo-mfBTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Подбор промпта и тестовые прогоны"
      ],
      "metadata": {
        "id": "fUyzBRoKs6Ak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задаем первый промпт -- просим модель определить, есть ли в тексте троллинг и ответить в указанном формате"
      ],
      "metadata": {
        "id": "rjrX6ck9QFC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATTERN = \"Identify if there is any trolling in the text, given after the word 'RESPONSE'. Base your decision on the context, given after the word 'CONTEXT'. CONTEXT: {0}, RESPONSE: {1}. Do not explain your decision, give only a number as an aswer, 1 if there is trolling in the text and 0 if there is not. \""
      ],
      "metadata": {
        "id": "Sr81_RT2s6tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    [\"Why no achievements on PC? Does anyone else wish there was achievements on PC? Feels like there's not really anything to work for in this game outside of getting your tryhard on.\",\n",
        "    \"Have you tried playing for fun?\"],\n",
        "    [\"How would you prevent climate change? How would you prevent a climate change and potential extinction of humanity in a libertarian world?  (if you don't believe in climate change just pretend it's real)\",\n",
        "    \"In a libertarian world, climate change would be addressed through property rights, market-based solutions like carbon pricing, technological innovation, and voluntary cooperation.\"],\n",
        "    [\"What are some good questions to ask my interviewer? I have an interview tomorrow. What questions would my interviewer like to hear?\",\n",
        "     \"Save your time and stress and get another job honestly..they will stress you out. The only benefits you will like are spotify and Lyra...Food is not great and free university after working 2 years.\"]\n",
        "]"
      ],
      "metadata": {
        "id": "Bnpr-6tPrNpc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = PATTERN.format(texts[0][0], texts[0][1])\n",
        "prompt_2 = PATTERN.format(texts[1][0], texts[1][1])\n",
        "\n",
        "print(prompt_1)"
      ],
      "metadata": {
        "id": "rFhPX113tlHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверяем, что модель выдает то, что от нее просят"
      ],
      "metadata": {
        "id": "XdM-o3qyEZSV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = run_mistral(prompt_1, api_key=api_key)\n",
        "response_2 = run_mistral(prompt_2, api_key=api_key)\n",
        "print(response)\n",
        "print(response_2)"
      ],
      "metadata": {
        "id": "444T4bM2uJo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Создание датасета"
      ],
      "metadata": {
        "id": "sqYne4kVH0Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем файлы с троллингом в датафрейм"
      ],
      "metadata": {
        "id": "BSGeyewXQSwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "with open(\"test (2).json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# df.to_csv(\"output.csv\", index=False)"
      ],
      "metadata": {
        "id": "GNQbdCnSH3hB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем нейтральный датасет в датафрейм (пока в отдельный)"
      ],
      "metadata": {
        "id": "r-1mKJ99QXyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_neut = pd.read_csv('neut.csv')\n",
        "contexts = [x for x in df_neut['context']]\n",
        "responses = [x for x in df_neut['response']]\n",
        "labels = [0 for x in range(len(contexts))]\n",
        "neut = [[x, responses[pos], labels[pos], 0] for pos, x in enumerate(contexts[:300])]\n",
        "print(df_neut.head())\n",
        "print()\n",
        "print(neut[:3])"
      ],
      "metadata": {
        "id": "4W45l8sHH454"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объединяем нейтральный и троллинговый датафреймы, чтобы получить тестовую выборку, и перемешиваем в рандомном порядке, получаем итоговый тестовый датасет размеров в 600 примеров"
      ],
      "metadata": {
        "id": "GqYmA5T7Qgns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "# подмешиваю нейтральные примеры в тест + шаффлю чтобы сделать датасет\n",
        "\n",
        "def make_dataset(df, neut):\n",
        "  titles = [x for x in df['Title']]\n",
        "  bodies = [x for x in df['Post']]\n",
        "  contexts = [x + ' ' + bodies[pos] for pos, x in enumerate(titles)]\n",
        "  trolls = [x for x in df['Troll']]\n",
        "  troll_labels = [x for x in df['TrollL']]\n",
        "  labels = [1 for x in range(len(contexts))]\n",
        "  dataset_tr = [[x, trolls[pos], labels[pos], troll_labels[pos]] for pos, x in enumerate(contexts[:300])]\n",
        "  dataset = dataset_tr + neut\n",
        "\n",
        "  return dataset\n",
        "\n",
        "\n",
        "test = make_dataset(df, neut)\n",
        "random.seed(67)\n",
        "random.shuffle(test)\n",
        "\n",
        "print(len(test))\n",
        "for x in test[:10]:\n",
        "  print(x)\n",
        "\n",
        "print()\n",
        "test_labels = [x[2] for x in test]\n",
        "print(test_labels[:10])"
      ],
      "metadata": {
        "id": "Zu5jQsJ9IDE7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "в датасет помимо текстов также включены:\n",
        "\n",
        "x[2] (лейбл на 1-м месте после текстов) - метка наличия/отсутствия троллинга\n",
        "\n",
        "x[3] (лейбл на 2-м месте после текстов) - метка типа троллинга (0 для нейтральных предложений). Нужна, чтобы потом посмотреть, что хуже определяется как троллинг, overt или covert"
      ],
      "metadata": {
        "id": "vOa0h2R3v21T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "У мистрали есть лимит на количество запросов в минуту, поэтому тестировать приходится с использованием нескольких ключей, чтобы все успевало восстановиться и программа не вылетала"
      ],
      "metadata": {
        "id": "HnfOH_moRNWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# здесь я создаю словарь из ключей потому что в функции которая чередует ключи они берутся из словаря\n",
        "\n",
        "api_keys = dict()\n",
        "with open('keys.txt', 'r', encoding='utf-8') as f:\n",
        "  for line in f:\n",
        "    key, value = line.strip().split('+')\n",
        "    if key not in api_keys:\n",
        "      api_keys[key] = ''\n",
        "    api_keys[key] = value"
      ],
      "metadata": {
        "id": "vSkIbti5QOel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "curr_global_key = \"api_key1\"\n",
        "\n",
        "def get_model_response(message, api_keys, max_retries=15):\n",
        "    global curr_global_key\n",
        "    keys_list = list(api_keys.keys())\n",
        "    for retry in range(max_retries):\n",
        "        try:\n",
        "            # print(f\"Using API key: {curr_global_key}\")\n",
        "            time.sleep(1)\n",
        "            response = run_mistral(message, api_keys[curr_global_key])\n",
        "            # если запрос успешен, переключаемся на следующий ключ со следующим запросом\n",
        "            curr_global_key = keys_list[(keys_list.index(curr_global_key) + 1) % len(keys_list)]\n",
        "            return response\n",
        "        except Exception as e:\n",
        "            # если нет, то пробуем этот запрос с другим ключом\n",
        "            if 'Requests rate limit exceeded' in str(e) or 'Status 429' in str(e):\n",
        "                # print(f\"Rate limit hit for {curr_global_key}, trying with next key after 1s...\")\n",
        "                time.sleep(1)\n",
        "                curr_global_key = keys_list[(keys_list.index(curr_global_key) + 1) % len(keys_list)]\n",
        "                continue\n",
        "            else:\n",
        "                raise e  # если ошибка не связана с лимитом, выбрасываем дальше\n",
        "    raise Exception(\"Max retries reached\")"
      ],
      "metadata": {
        "id": "r0hDZgg1ORtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Определение троллинга"
      ],
      "metadata": {
        "id": "XyXa9of-Eyyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Тестируем на датасете из 600 примеров пристегните ремни"
      ],
      "metadata": {
        "id": "JFDJqxQzFnAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "answers = []\n",
        "\n",
        "\n",
        "for x in tqdm(test):\n",
        "  time.sleep(1)\n",
        "  prompt = PATTERN.format(x[0], x[1])\n",
        "  response = get_model_response(prompt, api_keys=api_keys)\n",
        "  answers.append(response)\n",
        "\n",
        "print(answers[:10])\n",
        "print(test_labels[:10])"
      ],
      "metadata": {
        "id": "ViaIyTCxUmxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "P.S.: здесь собственно возникает ответ на вопрос, почему примеров 600, а не больше -- потому, что 600 примеров считаются по полчаса, иногда дольше, а ждать по часу+ на каждой итерации эксперимента совсем не хотелось 😭"
      ],
      "metadata": {
        "id": "EgHx7oVARtGo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ответы модель дает в виде строк, перегоняем их в целые числа, чтобы сравнить с правильными"
      ],
      "metadata": {
        "id": "eDvNnXsQScpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(answers[:10])\n",
        "\n",
        "for pos, x in enumerate(answers):\n",
        "  answers[pos] = int(x)\n",
        "\n",
        "print(answers[:10])\n",
        "print(test_labels[:10])"
      ],
      "metadata": {
        "id": "oSBngmE2CxQi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Измерение качества"
      ],
      "metadata": {
        "id": "swqatNkYN7g2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "print(f\"{100*accuracy_score(test_labels, answers):.2f}\")"
      ],
      "metadata": {
        "id": "EQc0kAnY_Bws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видно, с выявлением троллинга модель справляется довольно хорошо (и гораздо лучше, чем ROBERTA при попытке определения троллинга на основе fill-mask метода)\n",
        "\n",
        "Посмотрим на метрики по классам:"
      ],
      "metadata": {
        "id": "iwn6Jn84GWlt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "target_names = ['class neut', 'class troll']\n",
        "print(classification_report(test_labels, answers, target_names=target_names))"
      ],
      "metadata": {
        "id": "ojtZVk7ND5x8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Анализ ошибочных ответов"
      ],
      "metadata": {
        "id": "doigP8Up2c8B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напоминание: наша гипотеза состояла в следующем:\n",
        "\n",
        "> С выявлением закрытого (covert) троллинга модель будет справляться хуже, чем с определением открытого.\n",
        "\n",
        "Посчитаем процентное содержание предложений без троллинга, с открытым и с закрытым троллингом в ошибочных ответах модели, чтобы посмотреть, подтвердится ли гипотеза\n"
      ],
      "metadata": {
        "id": "Z0UYCFeT4Kh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type_tr = []\n",
        "for pos, x in enumerate(answers):\n",
        "  if x != test_labels[pos]: # если ответ не правильный\n",
        "    type_tr.append(test[pos][3]) # добавляем в список \"ошибок\" лейбл типа троллинга для примера,\n",
        "                                 # на который дан неправильный ответ\n",
        "\n",
        "# print(len(type_tr))\n",
        "# print(type_tr[:5])\n",
        "no_troll = type_tr.count(0)\n",
        "overt_troll = type_tr.count(1)\n",
        "covert_troll = type_tr.count(2)\n",
        "\n",
        "res = {'Тип предложения': ['без троллинга', 'с открытым троллингом', 'с закрытым троллингом'],\n",
        "       'Процент предложений данного типа в ошибочных ответах': [no_troll/len(type_tr)*100, overt_troll/len(type_tr)*100, covert_troll/len(type_tr)*100]}\n",
        "\n",
        "df_res = pd.DataFrame(res)\n",
        "df_res"
      ],
      "metadata": {
        "id": "3L83YICI0zp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = ['No trolling','Overt','Covert']\n",
        "values = [no_troll/len(type_tr)*100, overt_troll/len(type_tr)*100, covert_troll/len(type_tr)*100]\n",
        "colors = ['khaki','goldenrod','olive']\n",
        "\n",
        "plt.figure(figsize=(3,4))\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.pie(values,labels=labels,colors=colors)\n",
        "plt.title('Распределение предложений в ошибочных ответах', fontsize=12, fontfamily='serif')\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AjgzmgcySrXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видно, гипотеза **подтвердилась**: среди ошибочных ответов действительно большинство примеров с закрытым типом троллинга"
      ],
      "metadata": {
        "id": "Wzyahuez5C2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Попытка улучшить ситуацию с закрытым троллингом"
      ],
      "metadata": {
        "id": "dyqvAXJ6qKG-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Попробуем немного уточнить промпт и посмотреть, улучшится ли качество и уменьшится ли количество предложений с закрытым троллингом в ошибочных ответах"
      ],
      "metadata": {
        "id": "QGaYeg0TqQ2L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Промпты, которые мы пробовали:\n",
        "1. *Identify if there is any trolling in the text, given after the word 'RESPONSE'. Trolling in the text may be explicit, which is direct insults or agression, or implicit, which is hidden malice or passive-agressive language. Base your decision on the context, given after the word 'CONTEXT'. CONTEXT: {0}, RESPONSE: {1}. Do not explain your decision, give only a number as an aswer, 1 if there is trolling in the text and 0 if there is not.* -- **не помогло**, хотя качество выросло (нейтрального и оверт класса в ошибках стало меньше, но при этом процент закрытого троллинга только увеличился)\n",
        "2. *Classify the message given after the word 'RESPONSE' as either '1' (trolling) or '0' (not trolling), base your decision on context, given after the word 'CONTEXT'. Trolling (1) includes any intentional provocation: direct insults, shocking content (taboo topics), harmful disinformation, emotional manipulation, excessive criticism and discussion derailment (Digress). Not Trolling (0) is a neutral or constructive communication. CONTEXT: {0}, RESPONSE: {1}. Give only a number (0 or 1) as an answer* -- **совсем не помогло.**\n",
        "3. *Identify if there is any trolling in the text, given after the word 'RESPONSE'. Note that trolling in the text can be implicit, which is hidden malice or passive-agressive language. Base your decision on the context, given after the word 'CONTEXT'. CONTEXT: {0}, RESPONSE: {1}. Do not explain your decision, give only a number as an aswer, 1 if there is trolling in the text and 0 if there is not* -- **помогло**"
      ],
      "metadata": {
        "id": "WJPq510LuLGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATTERN_1 = \"Identify if there is any trolling in the text, given after the word 'RESPONSE'. Note that trolling in the text can be implicit, which is hidden malice or passive-agressive language. Base your decision on the context, given after the word 'CONTEXT'. CONTEXT: {0}, RESPONSE: {1}. Do not explain your decision, give only a number as an aswer, 1 if there is trolling in the text and 0 if there is not.\""
      ],
      "metadata": {
        "id": "bwTJBPCcvNwx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "answers = []\n",
        "\n",
        "\n",
        "for x in tqdm(test):\n",
        "  time.sleep(1)\n",
        "  prompt = PATTERN_1.format(x[0], x[1])\n",
        "  response = get_model_response(prompt, api_keys=api_keys)\n",
        "  answers.append(response)\n",
        "\n",
        "print(answers[:10])\n",
        "print(test_labels[:10])"
      ],
      "metadata": {
        "id": "UfCK-biKv0Mr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(answers[:10])\n",
        "\n",
        "for pos, x in enumerate(answers):\n",
        "  answers[pos] = int(x)\n",
        "\n",
        "print(answers[:10])\n",
        "print(test_labels[:10])"
      ],
      "metadata": {
        "id": "FnE0TvC60wnz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{100*accuracy_score(test_labels, answers):.2f}\")"
      ],
      "metadata": {
        "id": "tiyMpcXn8sTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_names = ['class neut', 'class troll']\n",
        "print(classification_report(test_labels, answers, target_names=target_names))"
      ],
      "metadata": {
        "id": "_0q-0k2S8zyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видим, качество повысилось на несколько процентов (81 vs 84). Посмотрим на распределение предложений в ошибочных ответах"
      ],
      "metadata": {
        "id": "QjzkQ94oTl_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type_tr = []\n",
        "for pos, x in enumerate(answers):\n",
        "  if x != test_labels[pos]: # если ответ не правильный\n",
        "    type_tr.append(test[pos][3]) # добавляем в список \"ошибок\" лейбл типа троллинга для примера,\n",
        "                                 # на который дан неправильный ответ\n",
        "\n",
        "print(len(type_tr))\n",
        "# print(type_tr[:5])\n",
        "no_troll = type_tr.count(0)\n",
        "overt_troll = type_tr.count(1)\n",
        "covert_troll = type_tr.count(2)\n",
        "\n",
        "res = {'Тип предложения': ['без троллинга', 'с открытым троллингом', 'с закрытым троллингом'],\n",
        "       'Процент предложений данного типа в ошибочных ответах': [no_troll/len(type_tr)*100, overt_troll/len(type_tr)*100, covert_troll/len(type_tr)*100]}\n",
        "\n",
        "df_res = pd.DataFrame(res)\n",
        "df_res"
      ],
      "metadata": {
        "id": "VYqde2Lvv9r9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['No trolling','Overt','Covert']\n",
        "values = [no_troll/len(type_tr)*100, overt_troll/len(type_tr)*100, covert_troll/len(type_tr)*100]\n",
        "colors = ['khaki','goldenrod','olive']\n",
        "\n",
        "plt.figure(figsize=(3,4))\n",
        "plt.rcParams['font.family'] = 'serif'\n",
        "plt.pie(values,labels=labels,colors=colors)\n",
        "plt.title('Распределение предложений в ошибочных ответах', fontsize=12, fontfamily='serif')\n",
        "plt.axis('equal')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QTMnxQMS9jJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Как видно, **качество улучшилось и процент скрытого троллинга в ошибках снизился** (на 20%). При этом, впрочем, модель по-прежнему лучше всего справляется с классификацией открытого троллинга: его в ошибках меньше всего.\n"
      ],
      "metadata": {
        "id": "cXIO553G9JFU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Zero-shot классификация типа троллинга (overt/covert): mistral"
      ],
      "metadata": {
        "id": "wUhMO0BOUUkd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Теперь посмотрим, как Мистраль будет справляться с определением типа троллинга в тексте"
      ],
      "metadata": {
        "id": "btqx4CONUL4B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Создание датасета"
      ],
      "metadata": {
        "id": "s4qIi1BmOqoi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "with open(\"test (2).json\", \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# df.to_csv(\"output.csv\", index=False)"
      ],
      "metadata": {
        "id": "WYAGgr5xWF2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном случае датасет создаем только из примеров с троллингом и меток типа троллинга.\n",
        "\n",
        "❗**Важно**: сама классификация троллинга тоже проводилась на датасете размером в **600** примеров! В ячейке значение 100 осталось после экспериментов с промптами из следующего раздела (они проводились на меньшем объеме, чтобы не ждать ответов слишком долго, и на полном датасете мы их не тестировали, потому что, забегая вперед, ничего не помогло)."
      ],
      "metadata": {
        "id": "jqxkhgmsUTo8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# новая функция для лепки датасета\n",
        "\n",
        "def make_dataset(df):\n",
        "  titles = [x for x in df['Title']]\n",
        "  bodies = [x for x in df['Post']]\n",
        "  contexts = [x + ' ' + bodies[pos] for pos, x in enumerate(titles)]\n",
        "  trolls = [x for x in df['Troll']]\n",
        "  labels = [x for x in df['TrollL']]\n",
        "  dataset = [[x, trolls[pos]] for pos, x in enumerate(contexts[:100])]\n",
        "\n",
        "  return dataset, labels\n",
        "\n",
        "test, test_labels = make_dataset(df)\n",
        "\n",
        "print(len(test))\n",
        "for x in test[:5]:\n",
        "  print(x)\n",
        "\n",
        "print(test_labels[:5])"
      ],
      "metadata": {
        "id": "GFDUu-ylXPOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Подбор промпта\n",
        "\n",
        "Промпты, которые мы тестировали:\n",
        "\n",
        "\n",
        "1. Identify the type of trolling -- overt or covert -- in the text, given after the word 'RESPONSE'. Base your decision on the context, given after the word 'CONTEXT'. CONTEXT: {0}, RESPONSE: {1}. Do not explain your decision, give only a number as an answer, 1 if the trolling in the text is overt and 2 if it is covert. -- **64%** на 600 примерах\n",
        "2. Identify the type of trolling in the text, given after the word 'RESPONSE'. Choose from two classes -- overt or covert trolling. Overt trolling might include more explicit insults or rudeness, whereas covert trolling is more hidden. Base your decision on the context, given after the word 'CONTEXT'. CONTEXT: {0}, RESPONSE: {1}. Do not explain your decision, give only a number as an answer, 1 if the trolling in the text is overt and 2 if it is covert. -- **68%** на 600 примерах"
      ],
      "metadata": {
        "id": "Jwg333g_mNPX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATTERN = \"Identify the type of trolling in the text, given after the word 'RESPONSE'. Choose from two classes -- overt or covert trolling. Overt trolling might include more explicit insults or rudeness, whereas covert trolling is more hidden. Base your decision on the context, given after the word 'CONTEXT'. CONTEXT: {0}, RESPONSE: {1}. Do NOT explain your decision, give only a number as an answer, 1 if the trolling in the text is overt and 2 if it is covert. \""
      ],
      "metadata": {
        "id": "WK08LwoVZoOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "texts = [\n",
        "    [\"Planning on leaving an envelope with some cash for our mail carrier in our mailbox today. With a note that it's for them. Is that the best way to do it?\", 'Why the hell would you give em money? They get paid from tax payers since they are government screw em.'],\n",
        "['Tips on arm hypertrophy? I’m 21M 5’7” 145lbs and I have skinny arms. Originally I focused on strength, but I’m trying to get some hypertrophy and it doesn’t seem to be working.        I can do 3x5 50lbs weighted pull-ups and dips, but I still feel like I have stick arms. My chest and back have definitely improved, but not arms.        What are some good exercises and tips for arm hypertrophy? Thanks!', 'The simplest was to get bigger arms fast is high-rep, relatively low weight work.   Try doing sets of 50 bicep curls, with a light weight- so that you arms should be burning like hell at the end of the 50. And do a good number of those sets (like 8). These are also very good for developing forearms.  Triceps add a lot to the size of the arms. The most effective, high rep exercise for triceps is sphinx push ups. Try doing 6 sets of 50 of those.'],\n",
        "['Tip for everyone who is trying to shift: Do not shift when you’re in a bad/sad mood. I’m talking from personal experience when I say that when you’re angry or sad the shifting is way harder, just try to shift in happy moods and when you’re sad or angry you might be tired and it’s your mind telling you to take a break', 'Another tip: you can’t fucking shift realities'],\n",
        "['My boyfriend made me turn around to look at my butt, then said I have “craters” all over the place. He went on to suggest I start doing squats before bed. This really hurt my feelings and made me feel disgusting. How would you guys react in this situation?', 'i don’t think he went about it the right way, but i think having preference and knowing what you find attractive and unattractive is okay. i don’t think he’s a piece of shit for wanting a SO who is in shape.'],\n",
        "['Second pregnancy. When breast feeding, I go from some tiny triple A boobs up to a 32J. I\\'m in the in-between stage. Is there anything that would fit now and later too? I\\'m specifically looking for \"sexy lingerie\" so that very much limits my options.', 'That’s what the calculator said? Holy shit. That must have hurt! I haven’t heard of J cups being sold. Especially not in smaller band sizes. You might have to find a custom shop near you.']\n",
        "\n",
        "]"
      ],
      "metadata": {
        "id": "S7wGCTLDbF9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_1 = PATTERN.format(texts[0][0], texts[0][1])\n",
        "prompt_2 = PATTERN.format(texts[1][0], texts[1][1])\n",
        "\n",
        "print(prompt_1)"
      ],
      "metadata": {
        "id": "pxiGeirDbuZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "убеждаемся, что модель отвечает, как просят"
      ],
      "metadata": {
        "id": "CSuobq_IVmW7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = run_mistral(prompt_1, api_key=api_keys['api_key2'])\n",
        "response_2 = run_mistral(prompt_2, api_key=api_keys['api_key2'])\n",
        "print(response)\n",
        "print(response_2)"
      ],
      "metadata": {
        "id": "qIG50xOHcVpk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "модель выдает что просят но неправильно. сейчас проверим, насколько"
      ],
      "metadata": {
        "id": "DPMeCwXGchH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Классификация троллинга"
      ],
      "metadata": {
        "id": "dnPIzrIdNqBq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "answers = []\n",
        "\n",
        "i = 0\n",
        "for x in tqdm(test):\n",
        "  # i += 1\n",
        "  # print(i, end=' ')\n",
        "  time.sleep(1)\n",
        "  prompt = PATTERN.format(x[0], x[1])\n",
        "  response = get_model_response(prompt, api_keys=api_keys)\n",
        "  answers.append(response)\n",
        "\n",
        "print(answers[:10])\n",
        "print(test_labels[:10])"
      ],
      "metadata": {
        "id": "HaZQn4Kbc3fZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "перегоняем ответы в инты"
      ],
      "metadata": {
        "id": "vAKy3uNdV38F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(answers)\n",
        "for pos, x in enumerate(answers):\n",
        "  # print(x)\n",
        "  if len(str(x)) == 1: # там был случай где модель ответила текстом его пришлось отфильтровать (больше не повторялось вроде)\n",
        "    answers[pos] = int(x)\n",
        "  else:\n",
        "    answers[pos] = 2\n",
        "    # print(answers[pos])\n",
        "\n",
        "print(answers[:10])\n",
        "print(test_labels[:10])"
      ],
      "metadata": {
        "id": "V8PHcja_e86K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Измерение качества"
      ],
      "metadata": {
        "id": "IMo8otcfsnlV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "print(f\"{100*accuracy_score(test_labels[:600], answers):.2f}\")"
      ],
      "metadata": {
        "id": "e5I2dXKFfAgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "После доп. разъяснений в промпте качество немного повысилось"
      ],
      "metadata": {
        "id": "TqKdZyBgsOmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "target_names = ['class overt', 'class covert']\n",
        "print(classification_report(test_labels[:600], answers, target_names=target_names))"
      ],
      "metadata": {
        "id": "POAxeigeoUXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Анализ ошибочных ответов"
      ],
      "metadata": {
        "id": "pSW0ld9Ilp8I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видим, что имеет место заметное отличие качества по классам. Для наглядности выведем матрицу ошибок и посмотрим на распределение классификации"
      ],
      "metadata": {
        "id": "q-GobHhRm2Ll"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(test_labels[:600], answers)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (4,4)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['overt', 'covert'])\n",
        "disp.plot(cmap=plt.cm.YlGn)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7XIk55GZkCsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Что интересно, в данном случае наша первоначальная гипотеза **не подтверждается**: чаще ошибочно классифицируется открытый троллинг -- возможно, это влияние определений типов троллинга, данных в промпте (далее попробуем их уточнить)"
      ],
      "metadata": {
        "id": "Zdb9sI4ImQBR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Попытка улучшить качество"
      ],
      "metadata": {
        "id": "4qzMkiSjswt7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Приведем промпты, которые мы протестировали на 100 примерах (чтобы эксперименты занимали немного меньше времени -- 100 примеров достаточно, чтобы отследить динамику, и, в случае улучшения, прогнать \"удачный\" промпт по полному датасету):\n",
        "\n",
        "1. *Classify the response given after the word 'RESPONSE' as: 1 (Overt trolling) for Aggression/throwing an ill-disposed or prohibited topic that is avoided for political or religious reasons/providing disinformation with the intent to harm others or 2 (Covert trolling) for creating a sensitive discussion/excessive criticism/making a discussion to be derailed into irrelevant or toxic subjects. Base your decision on context, given after the word 'CONTEXT'. CONTEXT: {0}, RESPONSE: {1}. Do NOT explain your reasoning, answer only with 1 or 2* -- **не помогло**\n",
        "\n",
        "\n",
        "2. *Identify the type of trolling in the text, given after the word 'RESPONSE'. Choose from two classes -- overt or covert trolling. Note that overt trolling is more explicit, including insults, swearing or taboo topics, whereas covert trolling is more implicit, including passive aggression or irrelevant information. Base your decision on the context, given after the word 'CONTEXT'. CONTEXT: {0}, RESPONSE: {1}. Do NOT explain your decision, give only a number as an answer, 1 if the trolling in the text is overt and 2 if it is covert.* -- **не помогло**\n",
        "\n",
        "3. *Classify the response as: 1 (Overt trolling) for Aggression/throwing an ill-disposed or prohibited topic that is avoided for political or religious reasons/providing disinformation with the intent to harm others or 2 (Covert trolling) for creating a sensitive discussion/excessive criticism/making a discussion to be derailed into irrelevant or toxic subjects. CONTEXT: {0}, RESPONSE: {1}. Answer only with 1 or 2* -- **не помогло**\n",
        "\n",
        "4. *Classify the response as overt (1) or covert (2) trolling based on these rules: Overt = Aggress (direct insults), Shock (taboo topics), Endanger (harmful disinformation). Covert = Antipathize (emotional provocation), Hypocriticize (excessive criticism), Digress (off-topic derailing). CONTEXT: {0}, RESPONSE: {1}. Answer only 1 or 2* -- **не помогло**\n",
        "\n",
        "**Изначальный промпт:** *Identify the type of trolling in the text, given after the word 'RESPONSE'. Choose from two classes -- overt or covert trolling. Overt trolling might include more explicit insults or rudeness, whereas covert trolling is more hidden. Base your decision on the context, given after the word 'CONTEXT'. CONTEXT: {0}, RESPONSE: {1}. Do NOT explain your decision, give only a number as an answer, 1 if the trolling in the text is overt and 2 if it is covert.* -- **работает лучше всего**"
      ],
      "metadata": {
        "id": "LlJezYQts0tK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATTERN = \"Identify the type of trolling in the text, given after the word 'RESPONSE'. Choose from two classes -- overt or covert trolling. Note that overt trolling is more explicit, including insults, swearing or taboo topics, whereas covert trolling is more implicit, including passive aggression or irrelevant information. Base your decision on the context, given after the word 'CONTEXT'. CONTEXT: {0}, RESPONSE: {1}. Do NOT explain your decision, give only a number as an answer, 1 if the trolling in the text is overt and 2 if it is covert.\""
      ],
      "metadata": {
        "id": "GvbDKyKeulWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "answers = []\n",
        "\n",
        "i = 0\n",
        "for x in tqdm(test):\n",
        "  # i += 1\n",
        "  # print(i, end=' ')\n",
        "  time.sleep(1)\n",
        "  prompt = PATTERN.format(x[0], x[1])\n",
        "  response = get_model_response(prompt, api_keys=api_keys)\n",
        "  answers.append(response)\n",
        "\n",
        "print(answers[:10])\n",
        "print(test_labels[:10])"
      ],
      "metadata": {
        "id": "b5sSB-DTvSEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in answers:\n",
        "  print(x)"
      ],
      "metadata": {
        "id": "ENEBfwJP271B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for pos, x in enumerate(answers):\n",
        "  # print(x)\n",
        "  if len(str(x)) == 1: # там был случай где он ответил текстом его пришлось отфильтровать\n",
        "    answers[pos] = int(x)\n",
        "  else:\n",
        "    answers[pos] = 2\n",
        "    # print(answers[pos])\n",
        "\n",
        "print(answers[:10])\n",
        "print(test_labels[:10])"
      ],
      "metadata": {
        "id": "TE0ItTx7wsr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "target_names = ['class overt', 'class covert']\n",
        "print(classification_report(test_labels[:100], answers, target_names=target_names))"
      ],
      "metadata": {
        "id": "k_FBdrEEvZUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(test_labels[:100], answers)\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (4,4)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['overt', 'covert'])\n",
        "disp.plot(cmap=plt.cm.YlGn)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zpU75Z9cvdel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "К сожалению, улучшить классификацию открытого троллинга с помощью разъяснений в промпте не удалось: просмотрев несколько матриц ошибок, мы увидели, что процентное соотношение ошибок остается примерно одинаковым: в классе overt модель ошибается примерно в 50% случаев, в классе covert -- примерно в 11-12%"
      ],
      "metadata": {
        "id": "neHCfklvXayG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Выводы"
      ],
      "metadata": {
        "id": "lbcEai5fX8zz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подведем итоги экспериментов с Мистралью:\n",
        "* с определением наличия/отсутствия троллинга в тексте Мистраль справляется довольно хорошо без дополнительного обучения -- максимальная точность, которой нам удалось достичь -- 84%\n",
        "* с классификацией типа троллинга модель справляется чуть хуже -- максимальная полученная точность -- 68%\n",
        "* в случае с определением наличия/отсутствия троллинга в тексте, наша гипотеза подтвердилась -- модель лучше распознает открытый троллинг и его в ошибочных ответах меньше всего\n",
        "* однако в случае с классификацией типа троллинга гипотеза не подтвердилась: модель чаще ошибается в классификации открытого троллинга, а не закрытого. Такой исход, впрочем, кажется логичным -- в случае с закрытым троллингом в тексте нет явных маркеров негатива, а потому ошибочно отнести его к открытому классу троллинга сложнее, чем наоборот.\n",
        "\n"
      ],
      "metadata": {
        "id": "VCfr50l-YAlg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Таблица 1. Метрики по экспериментам\n",
        "![таблица.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "kMlXTKIIdcBA"
      }
    }
  ]
}