{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VM7CUZPlklv"
      },
      "source": [
        "Извлечение мнений из новостных текстов\n",
        "\n",
        "[Репозиторий на GitHub ](https://github.com/dialogue-evaluation/RuOpinionNE-2024)\n",
        "\n",
        "[Страница на CodaLab](https://codalab.lisn.upsaclay.fr/competitions/20244)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GLGMauEOlklz"
      },
      "source": [
        "## Данные"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl11afrVlklz"
      },
      "source": [
        "### Загрузка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMQM8-fllklz"
      },
      "source": [
        "Каждый объект датасета представляет собой json-строку. Напишем функцию для загрузки данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pgyBrzpFlkl0"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import requests\n",
        "\n",
        "def load_json(path, url):\n",
        "\n",
        "  r = requests.get(url, allow_redirects=True)\n",
        "  with open(path, 'wb') as st:\n",
        "    st.write(r.content)\n",
        "\n",
        "  with open(path, 'r', encoding = 'utf8') as file:\n",
        "    data = list()\n",
        "    for line in file:\n",
        "        data_entry = json.loads(line)\n",
        "        data.append(data_entry)\n",
        "  return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtJ_oVCTlkl1"
      },
      "source": [
        "Загрузим данные обучающей, валидационной и тестовой выборки. Все части, кроме тестовой, содержат разметку мнений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "snjvJnyplkl1"
      },
      "outputs": [],
      "source": [
        "path = \"train.jsonl\"\n",
        "url = 'https://raw.githubusercontent.com/dialogue-evaluation/RuOpinionNE-2024/master/train.jsonl'\n",
        "train_data = load_json(path, url)\n",
        "print(f\"Количество предложений обучающей выборки: {len(train_data)}\\n\")\n",
        "train_data[16]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x2rBV5Uklkl1"
      },
      "outputs": [],
      "source": [
        "path = \"validation.jsonl\"\n",
        "url = 'https://raw.githubusercontent.com/dialogue-evaluation/RuOpinionNE-2024/master/validation_labeled.jsonl'\n",
        "validation_data = load_json(path, url)\n",
        "print(f\"Количество предложений валидационной выборки: {len(validation_data)}\\n\")\n",
        "validation_data[400]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PceXFPx8lkl2"
      },
      "outputs": [],
      "source": [
        "path = \"test.jsonl\"\n",
        "url = 'https://raw.githubusercontent.com/dialogue-evaluation/RuOpinionNE-2024/master/test.jsonl'\n",
        "test_data = load_json(path, url)\n",
        "print(f\"Количество предложений тестовой выборки: {len(test_data)}\\n\")\n",
        "test_data[763]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXZrgqnhlkl2"
      },
      "source": [
        "### Анализ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuQ7Kq4Llkl2"
      },
      "source": [
        "Проанализиуем обучающую выборку.\n",
        "\n",
        "Определим минимальную, максимальную и среднюю длину текста. Отобразим распределение на графике."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1lx1XSMlkl2"
      },
      "outputs": [],
      "source": [
        "lens = [len(x['text'].split()) for x in train_data]\n",
        "\n",
        "max_l, min_l, mean_l = max(lens), min(lens), sum(lens)/len(lens)\n",
        "\n",
        "print(f'Минимальная длина текста: {min_l}')\n",
        "print(f'Максимальная длина текста: {max_l}')\n",
        "print(f'Средняя длина текста: {mean_l:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5noJoHRlkl2"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "len_counts = Counter(lens)\n",
        "plt.figure(figsize = (6,3))\n",
        "plt.bar(len_counts.keys(), len_counts.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQF0EX0Llkl2"
      },
      "source": [
        "Выведем самый длинный текст."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vJaD1BXlkl3"
      },
      "outputs": [],
      "source": [
        "for elem in train_data:\n",
        "    if len(elem['text'].split()) == max_l:\n",
        "        print(elem['sent_id'])\n",
        "        print(elem['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QclUgpuPlkl3"
      },
      "source": [
        "Определим количество текстов, состоящих из более чем одного предложения:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwvYSKqYlkl3"
      },
      "outputs": [],
      "source": [
        "count = 0\n",
        "for elem in train_data:\n",
        "    text = elem['text']\n",
        "    if '\\n' in text or '.' in text[:-1]:\n",
        "        count+=1\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRmkfME-lkl3"
      },
      "source": [
        "Для дальнейшего анализа преобразуем обучающую выборку в датафрейм, где 1 мнение = 1 строка."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNi3o_AElkl3"
      },
      "outputs": [],
      "source": [
        "opinions = []\n",
        "for elem in train_data:\n",
        "    for op in elem['opinions']:\n",
        "        # источник и интервал\n",
        "        if len(op['Source'][0]) > 1:\n",
        "            source_text = op['Source'][0]\n",
        "            source_span = op['Source'][1]\n",
        "        else:\n",
        "            source_text = op['Source'][0][0]\n",
        "            source_span = op['Source'][1][0]\n",
        "        # объект и интервал\n",
        "        if len(op['Target'][0]) > 1:\n",
        "            target_text = op['Target'][0]\n",
        "            target_span = op['Target'][1]\n",
        "        else:\n",
        "            target_text = op['Target'][0][0]\n",
        "            target_span = op['Target'][1][0]\n",
        "        # выражение и интервал\n",
        "        if len(op['Polar_expression'][0]) > 1:\n",
        "            exp_text = op['Polar_expression'][0]\n",
        "            exp_span = op['Polar_expression'][1]\n",
        "        else:\n",
        "            exp_text = op['Polar_expression'][0][0]\n",
        "            exp_span = op['Polar_expression'][1][0]\n",
        "        opinions.append([elem['sent_id'], elem['text'], source_text, target_text, exp_text,\n",
        "                       op['Polarity'], source_span, target_span, exp_span])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kjS1MFC6lkl3"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "cols = ['sent_id', 'text', 'Source', 'Target', 'Polar_expression', 'Polarity', 'Source_span', 'Target_span', 'Polar_expression_span']\n",
        "df = pd.DataFrame(opinions, columns = cols)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNAxxNaTlkl3"
      },
      "source": [
        "Оценим распределение классов тональности."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6julPSOlkl3"
      },
      "outputs": [],
      "source": [
        "print(df['Polarity'].value_counts())\n",
        "\n",
        "plt.figure(figsize = (6,3))\n",
        "df['Polarity'].value_counts().plot.bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7ZVausklkl3"
      },
      "source": [
        "Определим число текстов с множественными мнениями и отобразим распределение на графике."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2REAEo8lkl4"
      },
      "outputs": [],
      "source": [
        "textcount = Counter(df['text'].value_counts())\n",
        "textcount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qH31nicBlkl4"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize = (6,3))\n",
        "plt.bar(textcount.keys(), textcount.values())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8wvhSmVlkl4"
      },
      "source": [
        "Посчитаем максимальную и среднюю длину для источника, объекта и выражения. Выведем примеры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzX4jdUclkl4"
      },
      "outputs": [],
      "source": [
        "sources = []\n",
        "for item in df['Source']:\n",
        "    if isinstance(item, str):\n",
        "        sources.append(item)\n",
        "    else:\n",
        "        sources+=item\n",
        "max_s = max([len(x.split()) for x in sources])\n",
        "mean_s = sum([len(x.split()) for x in sources])/len(sources)\n",
        "print(f'Максимальная длина источника: {max_s}')\n",
        "print(f'Средняя длина источника: {mean_s:.3f}')\n",
        "\n",
        "print(f'Самый длиный источник:')\n",
        "for item in df['Source']:\n",
        "    if isinstance(item, str) and len(item.split()) == max_s:\n",
        "        print(f'\"{item}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwbNell0lkl4"
      },
      "outputs": [],
      "source": [
        "targets = []\n",
        "for item in df['Target']:\n",
        "    if isinstance(item, str):\n",
        "        targets.append(item)\n",
        "    else:\n",
        "        targets+=item\n",
        "max_t = max([len(x.split()) for x in targets])\n",
        "mean_t = sum([len(x.split()) for x in targets])/len(targets)\n",
        "print(f'Максимальная длина объекта: {max_t}')\n",
        "print(f'Средняя длина объекта: {mean_t:.3f}')\n",
        "\n",
        "for item in df['Target']:\n",
        "    if isinstance(item, str) and len(item.split()) == max_t:\n",
        "        print(f'Самый длиный объект:\\n\"{item}\"')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-9r7NtQ5lkl4"
      },
      "outputs": [],
      "source": [
        "expressions = list()\n",
        "for item in df['Polar_expression']:\n",
        "    if isinstance(item, str):\n",
        "        expressions.append(item)\n",
        "    else:\n",
        "        expressions+=item\n",
        "max_e = max([len(x.split()) for x in expressions])\n",
        "mean_e = sum([len(x.split()) for x in expressions])/len(expressions)\n",
        "print(f'Максимальная длина выражения: {max_e}')\n",
        "print(f'Средняя длина выражения: {mean_e:.3f}')\n",
        "\n",
        "for item in df['Polar_expression']:\n",
        "    if isinstance(item, str) and len(item.split()) == max_e:\n",
        "        print(f'Самое длиное выражение:\\n\"{item}\"')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x6DfhoNhlkl4"
      },
      "source": [
        "Определим самые частые источники."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuergaT4lkl4"
      },
      "outputs": [],
      "source": [
        "df['Source'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf5J6nnolkl4"
      },
      "source": [
        "Посчитаем количество разрывных и множественных источников, объектов и выражений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OD_Kj0Zllkl4"
      },
      "outputs": [],
      "source": [
        "s, t, e = 0, 0, 0\n",
        "for i, row in df.iterrows():\n",
        "    if isinstance(row['Source'], list):\n",
        "        s+=1\n",
        "    if isinstance(row['Target'], list):\n",
        "        t+=1\n",
        "    if isinstance(row['Polar_expression'], list):\n",
        "        e+=1\n",
        "\n",
        "print(f'Множественный/ фрагментированный источник: {s}')\n",
        "print(f'Множественный/ фрагментированный объект: {t}')\n",
        "print(f'Множественное/ фрагментированное выражение: {e}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYzPIXZ9lkl5"
      },
      "source": [
        "Выведем примеры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyrxrPh_lkl5"
      },
      "outputs": [],
      "source": [
        "for i, row in df.iterrows():\n",
        "    if isinstance(row['Polar_expression'], list):\n",
        "        print(row['Polar_expression'], row['Polar_expression_span'], sep = '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT4--Q56lkl5"
      },
      "source": [
        "## Модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgz83Msnlkl5"
      },
      "source": [
        "Применим модель [Qwen2.5 72B instruct](https://huggingface.co/Qwen/Qwen2.5-72B-Instruct) в режиме few-shot."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jNrvtMdGlkl5"
      },
      "source": [
        "### InferenceClient"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rrpEmNdlkl5"
      },
      "source": [
        " Воспользуемся моделью через Hugging Face API.\n",
        "\n",
        "1. Регистрируемся на [Hugging Face](https://huggingface.co/).\n",
        "2. Создаем токен в настройках аккаунта: Settings -> [Access Tokens](https://huggingface.co/settings/tokens). Важно: выбираем тип токена `read`.\n",
        "3. Записываем токен в переменную TOKEN\n",
        "\n",
        "Не храните токен на GitHub! Если вы хотите распространить ваш код, предварительно удалите токен из кода."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JL7LG8bTlkl9"
      },
      "outputs": [],
      "source": [
        "token = 'hf_00000' # токен начинается с hf_...\n",
        "model_name = \"Qwen/Qwen2.5-72B-Instruct\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emjh-XWtlkl9"
      },
      "source": [
        "3. Импортируем [InferenceClient](https://huggingface.co/docs/huggingface_hub/v0.16.2/en/package_reference/inference_client#huggingface_hub.InferenceClient) — инструмент для получения запросов от модели.\n",
        "4. Указываем в клиенте название модели и токен, которые мы прописали заранее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jT2wdAt-lkl9"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "client = InferenceClient(model_name, token=token)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_zgh6bNlkl9"
      },
      "source": [
        "Создаем промт. Можно задать следующие параметры:\n",
        "\n",
        "* messages — системная роль и промпт для LLM\n",
        "* max_tokens — максимальная длина вывода (в токенах)\n",
        "* temperature — температура (рандомность выдачи)\n",
        "* top_p — также задает рандомность, а именно количество вариантов вывода модели на каждом шаге генерации выдачи\n",
        "\n",
        "Что записывается в messages:\n",
        "\n",
        "* системная роль: основной промпт модели, например, ты помощник преподавателя или генерируй код на Python\n",
        "* текущий промпт: можно получать его через input, переменную или аргумент функции и т.д.\n",
        "\n",
        "Рассмотрим пример промта, который можно было бы использовать при создании виртуального ассистента."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Jvpu8mhlkl9"
      },
      "outputs": [],
      "source": [
        "topic = input('Введите тему запроса: ') # здесь мы просим пользователя ввести перменную\n",
        "\n",
        "output = client.chat.completions.create( # метод из HuggingFace Cient для осуществления запросов к LLM\n",
        "          messages=[\n",
        "              {\"role\": \"system\", # маркер системной роли\n",
        "                \"content\": \"Ты ассистент обучающегося в университете. Объясняй концепты. Используй формат маркированных списков.\"\n",
        "              },\n",
        "              {\"role\": \"user\", # маркер текущего промпта пользователя\n",
        "              \"content\": f\"Объясни основы {topic} простыми словами\"},\n",
        "          ],\n",
        "          max_tokens=1000, # мы задали максимальную длину ответа — 1000 токенов, это значение можно увеличить или уменьшить\n",
        "          temperature=0.2, # temperature можно поменять, например, на 0.6 или 0.7 — понаблюдайте, окажет ли это влияние на результат\n",
        "          top_p=0.9 # это значение можно задавать от 0.1 до 0.9 — также можете понаблюдать за изменениями\n",
        "          ).choices[0].get('message')['content'] # этот хвостик нам нужен, чтобы вывести только ответ модели без метаданных — попробуйте удалить его и вывести ответ с метаданными\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9n_q7kKclkl9"
      },
      "source": [
        "### Применение к данным"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TksjXAF-lkl9"
      },
      "source": [
        "Опишем промт для задачи извлечения мнений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0UfXT6Flkl9"
      },
      "outputs": [],
      "source": [
        "prompt = 'Твоя задача состоит в том, чтобы проанализировать текст и извлечь из него выражения мнений, \\\n",
        "представленные в виде кортежа мнений, состоящих из 4 основных составляющих:\\n\\\n",
        "1. Источник мнения: автор, именованная сущность текста (подстрока исходного текста), либо \"NULL\". Key = Source;\\n\\\n",
        "2. Объект мнения: именованная сущность в тексте (подстрока исходного текста). Key = Target;\\n\\\n",
        "3. Тональность: положительная/негативная (\"POS\"/ \"NEG\"). Допустимы только значения \"POS\" и \"NEG\", значение \"NULL\" недопустимо. Key = Polarity;\\n\\\n",
        "4. Языковое выражение: аргумент, на основании которого принята результирующая тональность \\\n",
        "(одна или несколько подстрок исходного текста). Key = Polar_expression;\\n\\\n",
        "Значение источника, объекта и тональности должны быть заключены в кавычки. \\\n",
        "Если источник мнения отсутствует, то Source = \"NULL\". Если источником мнения является автор, то Source = \"AUTHOR\". Источник мнения не может быть выражен местоимением. \\\n",
        "В прочих случаях поле Source должно полностью совпадать с подстрокой исходного текста. Поля Target, Polar_expression всегда полностью совпадают с подстроками текста и стоять в том же падеже.\\n\\\n",
        "Не добавляй никаких пояснений. Ответ необходимо представить в виде json списка, каждый элемент которого является кортежем мнений. Само слово json не нужно выводить. \\\n",
        "Каждый кортеж мнений это словарь, состоящий из четырех значений: Source, Target, Polarity, Polar_expression. \\\n",
        "Для извлечённых Source, Target, Polarity, Polar_expression должно быть справедливо утверждение: \\\n",
        "На основании выражения Polar_expression можно сказать, что Source имеет Polarity отношение к Target..\\n\\\n",
        "Ниже представлены примеры выполнения задачи:\\n\\\n",
        "***Текст***\\n\\\n",
        "Премьер-министр Молдовы осудил террориста за бесчеловечные и жестокие действия.\\n\\\n",
        "Source: \"Премьер-министр Молдовы\", Target: \"террориста\", Polarity: \"NEG\", Polar_expression: \"бесчеловечные и жестокие действия\".\\n\\\n",
        "***Текст***\\n\\\n",
        "Знаменитая актриса продемонстрировала человечность и простоту, достойную уважения публики.\\n\\\n",
        "***Ответ***\\n\\\n",
        "Source: \"AUTHOR\", Target: \"актриса\", Polarity: \"POS\", Polar_expression: \"продемонстрировала человечность и простоту, достойную уважения публики\".\\n\\\n",
        "Проанализируй таким же образом следующий текст.\\n\\\n",
        "***Текст***'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GWJGgTalkl9"
      },
      "source": [
        "Напишем функцию, которая будет принимать предложения из датасета, записывать его в промт и подавать на вход модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70a6w2_Clkl-"
      },
      "outputs": [],
      "source": [
        "def inference(sentence):\n",
        "  output = client.chat.completions.create(\n",
        "          messages=[\n",
        "              {\"role\": \"user\",\n",
        "              \"content\": f\"{prompt}\\n{sentence}\"},\n",
        "          ],\n",
        "          stream=False,\n",
        "          temperature=0.5,\n",
        "          top_p=0.9\n",
        "          ).choices[0].get('message')['content']\n",
        "  return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ScQ1kYalkl-"
      },
      "source": [
        "Применим функцию к одному из предложений."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6JWllQC3lkl-"
      },
      "outputs": [],
      "source": [
        "sent_id = 0\n",
        "text = train_data[sent_id][\"text\"]\n",
        "print(f'Prompt:\\n{prompt}\\n{text}\\n')\n",
        "output = inference(train_data[sent_id][\"text\"])\n",
        "print(f'Predicted tuple: {type(output)}\\n{output}\\n')\n",
        "print(f'Gold tuple: {type(train_data[sent_id][\"opinions\"])}\\n{train_data[sent_id][\"opinions\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RqcVx9Jlkl-"
      },
      "source": [
        "LLM не возвращает интервалы для источника, объекта и выражения. Также отличается формат истинной цепочки мнений и предсказания. Следовательно, необходима некоторая дополнительная обработка ответов модели.\n",
        "\n",
        "Для примера применим функцию к первым 100 предложениям обучающей выборки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzvAjmmxlkl-"
      },
      "outputs": [],
      "source": [
        "from tqdm.auto import tqdm\n",
        "\n",
        "progress_bar = tqdm(range(100))\n",
        "train_output = []\n",
        "\n",
        "for sample in train_data[:100]:\n",
        "  sample_output = inference(sample[\"text\"])\n",
        "  train_output.append(sample_output)\n",
        "  progress_bar.update(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DAyVIaSlkl-"
      },
      "source": [
        "Определим функцию для нахождения интервалов и функцию для преобразования ответа модели в формат json-строки с нужными ключами \"`sent_id`\", \"`text`\" и \"`opinions`\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVm2_-axlkl-"
      },
      "outputs": [],
      "source": [
        "def get_interval(text, phrase):\n",
        "    if phrase == 'AUTHOR':\n",
        "        return 'NULL'\n",
        "    elif phrase == 'NULL':\n",
        "        return '0:0'\n",
        "    else:\n",
        "        start_index = text.find(phrase)\n",
        "        end_index = start_index + len(phrase)\n",
        "        return f\"{start_index}:{end_index}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gNoHAxylkl-"
      },
      "outputs": [],
      "source": [
        "def string2json(sample, output):\n",
        "\n",
        "    # Определяем идентификатор\n",
        "    sent_id = sample[\"sent_id\"]\n",
        "    # Определяем предложение\n",
        "    text = sample[\"text\"]\n",
        "\n",
        "    if output == '[]':\n",
        "        predicted_json = {\n",
        "            \"sent_id\": sent_id,\n",
        "            \"text\": text,\n",
        "            \"opinions\": []\n",
        "            }\n",
        "\n",
        "    else:\n",
        "        # Преобразуем строку в Python-объект (список)\n",
        "        opinions_list = json.loads(output)\n",
        "        if opinions_list[0]['Polarity']=='NULL':\n",
        "          predicted_json = {\n",
        "            \"sent_id\": sent_id,\n",
        "            \"text\": text,\n",
        "            \"opinions\": []\n",
        "            }\n",
        "        else:\n",
        "          # Создаем новый JSON-объект\n",
        "          predicted_json = {\n",
        "              \"sent_id\": sent_id,\n",
        "              \"text\": text,\n",
        "              \"opinions\": [{\"Source\": [[opinions_list[0][\"Source\"]], [get_interval(text, opinions_list[0][\"Source\"])]],\n",
        "                            \"Target\": [[opinions_list[0][\"Target\"]], [get_interval(text, opinions_list[0][\"Target\"])]],\n",
        "                            \"Polar_expression\": [[opinions_list[0][\"Polar_expression\"]], [get_interval(text, opinions_list[0][\"Polar_expression\"])]],\n",
        "                            \"Polarity\": opinions_list[0][\"Polarity\"]}]\n",
        "              }\n",
        "    return predicted_json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMm_f4rXlkl_"
      },
      "source": [
        "Применяем обработку ко всем ответам модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jB3lIBMxlkl_"
      },
      "outputs": [],
      "source": [
        "train_json_output = []\n",
        "for i in range(len(train_output)):\n",
        "  print(i, string2json(train_data[i], train_output[i]))\n",
        "  train_json_output.append(string2json(train_data[i], train_output[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThLCyBAWlkl_"
      },
      "outputs": [],
      "source": [
        "train_json_output[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ID0nQcH5lkl_"
      },
      "outputs": [],
      "source": [
        "train_data[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nz1BHvhFlkl_"
      },
      "source": [
        "Для оценки качества нужно посчитать метрику $Sentiment\\;Tuple\\;F_1$.\n",
        "\n",
        "Импортируем код, предлагаемый организаторами соревнования."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijGehzQZlkl_"
      },
      "outputs": [],
      "source": [
        "!wget -q https://raw.githubusercontent.com/dialogue-evaluation/RuOpinionNE-2024/master/codalab/evaluation.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5_PLJd6lkl_"
      },
      "outputs": [],
      "source": [
        "import evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EowTlKgplkl_"
      },
      "outputs": [],
      "source": [
        "evaluation.do_eval_core(train_data[:100], train_json_output)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}