{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-0zUFuHEqCK"
      },
      "source": [
        "В современном мире машинного обучения тема **объяснимости и интерпретируемости** моделей становится неотъемлемой частью развития искусственного интеллекта.\n",
        "\n",
        "Когда алгоритмы машинного обучения используются для принятия решений, особенно в чувствительных областях, таких как медицина или право, а также в научных применениях, важно понимать, почему модель делает тот или иной вывод.\n",
        "\n",
        "Мы рассмотрим концепции и методы, касающиеся способов представления и объяснения выводов, полученных от моделей машинного обучения.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zY4jnv1CEqCK"
      },
      "source": [
        "# Мотивация использования Explainability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_YCTQOmEqCK"
      },
      "source": [
        "Модели машинного обучения представляют собой черный ящик."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtZFLOHOEqCL"
      },
      "source": [
        "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L14/out/input_blackbox_output.png\" alt=\"alttext\" width=\"400\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-JrDmHdEqCL"
      },
      "source": [
        "Иногда это  становится препятствием для внедрения моделей.\n",
        "\n",
        "Есть как минимум три причины, по которым нас может интересовать объяснение предсказаний модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ezo26TJqEqCL"
      },
      "source": [
        "**1. Доверие к предсказаниям**\n",
        "\n",
        "Нельзя остановить ядерную электростанцию или назначить пациенту опасное лечение лишь на основании предсказания «черного ящика».\n",
        "Даже маловероятная ошибка в таких случаях будет иметь тяжелые последствия. Поэтому человек, принимающий решение, должен понимать, на основе каких признаков или симптомов сделано предсказание."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xssDqTcEqCL"
      },
      "source": [
        "**2. Обнаружение некорректных зависимостей**\n",
        "\n",
        "Модель может использовать совсем не те признаки, которые соответствуют реальным объектам. То есть вместо реальных свойств объекта ориентироваться на случайно обнаруженные зависимости, не связанные с реальными данными (фон, водяной знак и т. п.).\n",
        "\n",
        "Яркий пример мы можем увидеть в статье [\"Why Should I Trust You?\" Explaining the Predictions of Any Classifier](https://arxiv.org/abs/1602.04938), авторы которой обучили классификатор волков и хаски на изображениях, отобранных так, чтобы на всех фотографиях волков на фоне был снег, а на фотографиях хаски — нет. На рисунке ниже мы можем увидеть, на что обращает внимание при предсказаниях полученная в результате такого обучения модель."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t9BuA7qyEqCL"
      },
      "source": [
        "<center><img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.1/L14/2_bad_models_prediction.png\" alt=\"alttext\" width=\"400\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qNn8MmsGEqCL"
      },
      "source": [
        "**3. Публикации в научных журналах**\n",
        "\n",
        "Вероятность публикации статьи значительно повышается, если автор смог объяснить происхождение результатов своего исследования."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLGjRDAaEqCL"
      },
      "source": [
        "<font size=\"5\"> Explainability & Interpretability </font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdL2i0plEqCL"
      },
      "source": [
        "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L14/out/explainability_vs_interpretability.png\" alt=\"alttext\" width=\"1000\"/></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM2NBKaNEqCL"
      },
      "source": [
        "В англоязычной литературе можно встретить два термина, связанных с темой доверия к ML-моделям: Explainability и Interpretability. Терминология в этой области еще не устоялась, и в разных источниках эти термины определяют по-разному. Можно выделить следующие характерные различия:\n",
        "\n",
        "* **Explainability** — методики, позволяющие объяснить механизм функционирования модели. Например, для линейной регрессии это анализ коэффициентов при параметрах.\n",
        "\n",
        "* **Interpretability** — анализ того, как изменение входов модели влияет на ее выходы. Например, закрашивая часть пикселей изображения, можно выяснить, какие из них повлияют на предсказания (пример с хаски и волками).\n",
        "\n",
        "Мы рассмотрим оба типа методов.\n",
        "\n",
        "[Machine Learning Explainability vs Interpretability: Two concepts that could help restore trust in AI](https://www.kdnuggets.com/2018/12/machine-learning-explainability-interpretability-ai.html)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ODh4lV4EqCL"
      },
      "source": [
        "# Объяснимость моделей классического ML"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fkg7nO68EqCL"
      },
      "source": [
        "Некоторые алгоритмы машинного обучения обладают свойством объяснимости сами по себе. Объяснить, почему модель выдала то или иное предсказание, возможно непосредственно исходя из понимания принципа работы модели.\n",
        "\n",
        "Чтобы подчеркнуть, что, в отличие от \"черных ящиков\", внутреннее устройство таких моделей прозрачно и понятно, их называют \"белыми\" или \"прозрачными\" ящиками (glass box).\n",
        "\n",
        "В частности, к таким алгоритмам относятся **линейные модели** и **модели, основанные на деревьях решений**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U7oT6qZEqCM"
      },
      "source": [
        "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L14/out/glass_box.png\" alt=\"alttext\" width=\"400\"/></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44oxURiwEqCM"
      },
      "source": [
        "## Оценка важности признаков для линейных моделей\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJStmQTYK9CS"
      },
      "source": [
        "Выход линейной модели является линейной комбинацией входных признаков, к которой также добавляется смещение:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "splUSBX5K9CT"
      },
      "source": [
        "$$ \\large\n",
        "\\begin{eqnarray*}\n",
        "y & = & w_1 x_1+ w_2 x_2 + ... + w_n x_n + b\\\\\n",
        "& = & \\sum_{i=1}^n x_i w_i + b \\\\\n",
        "& = & \\left(\\vec{x}, \\vec{w}\\right) + b\n",
        "\\end{eqnarray*}\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1N_Cq1ORK9CT"
      },
      "source": [
        "Данную формулу можно графически представить следующим образом:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pM1ugC22K9CT"
      },
      "source": [
        "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L05/out/one_neuron_linear_model.png\" width=\"450\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRmTeITFEqCM"
      },
      "source": [
        "В случае с **линейными моделями** легко определить, какие признаки модель считает важными. Если модель присваивает какому-то признаку **большой вес**, то этот признак сильнее влияет на **предсказание**.\n",
        "\n",
        "При этом стоит отметить, что **признаки должны быть сравнимы**, то есть должны находиться в сравнимых диапазонах и быть выражены в одних единицах измерения (или быть безразмерными).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pr19lcl1EqCM"
      },
      "source": [
        "### Пример для табличных данных (Boston Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUVkWpGGEqCM"
      },
      "source": [
        "Для примера скачаем **датасет жилья Бостона** ([The Boston Housing Dataset](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html)), в котором проанализируем зависимость цены на жилье от параметров жилья и района, в котором оно находится."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AocVko7zEqCM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load dataset\n",
        "boston_dataset = pd.read_csv(\n",
        "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/boston_dataset.csv\",\n",
        "    index_col=0,\n",
        ")\n",
        "x_data = boston_dataset.iloc[:, :-1]\n",
        "y_data = boston_dataset[\"target\"].values\n",
        "\n",
        "boston_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVX5sqrhEqCM"
      },
      "source": [
        "Посмотрим на статистики признаков:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DpJX3WCtEqCM"
      },
      "outputs": [],
      "source": [
        "boston_dataset.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaS4zH00EqCM"
      },
      "source": [
        "Из описательных статистик по признакам видно, что признаки несравнимы. Поэтому коэффициенты линейной модели, обученной на таких данных, будут не только нести в себе важность, но и масштабировать значения, чтобы перевести их в размерность целевой переменной. Этот факт будет мешать интерпретировать значения весов перед признаками как степень их влияния на предсказание целевой переменной.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZEZPqTtKEqCM"
      },
      "source": [
        "Обучим модель на **стандартизованных данных**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aej6YrZyEqCM"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "ss = StandardScaler()\n",
        "x_data_scaled = ss.fit_transform(x_data)\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(x_data_scaled, y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i69R6D6KEqCN"
      },
      "source": [
        "Выведем **коэффициенты** признаков, отсортированные по абсолютному значению:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQBo0RW7EqCN"
      },
      "outputs": [],
      "source": [
        "linear_model_coefs = model.coef_\n",
        "feature_names = x_data.columns\n",
        "\n",
        "linear_importance = pd.DataFrame(\n",
        "    {\"name\": feature_names, \"coef\": linear_model_coefs}\n",
        ").sort_values(\"coef\", key=abs, ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NV7aCeQOEqCN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "linear_importance[\"sign\"] = linear_importance[\"coef\"].apply(\n",
        "    lambda x: \"neg\" if x < 0 else \"pos\"\n",
        ")\n",
        "palette = {\"neg\": \"#1e88e5\", \"pos\": \"#ff0d57\"}\n",
        "\n",
        "plt.figure(figsize=(5, 5))\n",
        "plt.title(\"Linear model coefficients\")\n",
        "ax = sns.barplot(\n",
        "    data=linear_importance,\n",
        "    y=\"name\",\n",
        "    x=\"coef\",\n",
        "    hue=\"sign\",\n",
        "    palette=palette,\n",
        "    legend=False,\n",
        "    orient=\"h\",\n",
        ")\n",
        "for i in ax.containers:\n",
        "    ax.bar_label(i, fmt=\"%.2f\", label_type=\"center\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8aJPHo3EqCN"
      },
      "source": [
        "Добавим абсолютные значения для сравнения с другими оценками важности."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lF_Ii9jSEqCN"
      },
      "outputs": [],
      "source": [
        "linear_importance[\"abs(coef)\"] = linear_importance[\"coef\"].abs()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Di3hkZREqCN"
      },
      "source": [
        "## Оценка важности признаков для деревьев решений"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-MV2VZuEqCN"
      },
      "source": [
        "В случае с **деревьями** всё далеко не так очевидно: дерево не знает такой концепции, как **\"вес признака\"**.\n",
        "\n",
        "Универсального критерия значимости для деревьев у нас нет, и, в зависимости от задачи и от того, как эти признаки устроены, ответы могут быть разными."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXpc9e8pEqCN"
      },
      "source": [
        "Один из способов оценки качества признаков для дерева решений следует из принципа построения дерева. При выборе признака и порога для разбиения выборки в узле дерева используется метрика $\\text{Gini}$:\n",
        "\n",
        "$$\\large \\text{Gini} = 1 - \\sum_ip_i^2,$$\n",
        "\n",
        "где $p_i$ — вероятность того, что объект, попавший в данный  лист, относится к $i$-му классу. Чем меньше $\\text{Gini}$ в листьях, тем лучше узел, от которого \"растут\" листья, разделяет классы.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kerMSKKtFe_-"
      },
      "source": [
        "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.3/L03/out/compute_gini_for_binary_features.png\" width=\"900\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для того, чтобы охарактеризовать, насколько данный узел хорошо разделяет выборку, $\\text{Gini}$ листьев данного узла суммируются с весами, равными доле объектов, попавших в каждый из листев (выражение в скобках в формуле ниже). Далее данный показатель вычитается из $\\text{Gini}$ узла разбиения. Таким образом формируется показатель $\\text{impurity decrease}$, который характеризует, как хорошо данное разбиение \"очищает\" выборки (то есть делает подвыборки в листьях более однородными по целевой переменной)."
      ],
      "metadata": {
        "id": "FLddK0FCe27-"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn4PfK-hEqCN"
      },
      "source": [
        "$$\\large \\text{Impurity decrease} = \\text{Gini}_0 - \\left(\\dfrac{n_1}{n_1+n_2}\\text{Gini}_1 + \\dfrac{n_2}{n_1+n_2}\\text{Gini}_2\\right),$$\n",
        "\n",
        "где $n_1, n_2$ — число объектов в листьях, $ \\text{Gini}_0$ — чистота исходного узла."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp7_5sp5Fe__"
      },
      "source": [
        "**Боль в груди:**\n",
        "\n",
        " $\\text{Impurity decrease} = 0.498 - (\\dfrac{138}{138+159})\\cdot 0.364 - (\\dfrac{159}{138+159})\\cdot 0.336 = 0.149$\n",
        "\n",
        "**Хорошо циркулирует кровь:**\n",
        "\n",
        " $\\text{Impurity decrease} = 0.498 - (\\dfrac{164}{164+133})\\cdot 0.349 - (\\dfrac{133}{164+133})\\cdot 0.373 = 0.138$\n",
        "\n",
        "**Есть атеросклероз:**  \n",
        "\n",
        "$\\text{Impurity decrease} = 0.498 - (\\dfrac{123}{123+174})\\cdot 0.377 - (\\dfrac{174}{123+174})\\cdot 0.383 = 0.117$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ToiGAos0Fe__"
      },
      "source": [
        "Наибольший $\\text{impurity decrease}$ в признаке \"боль в груди\". Значит, мы возьмем \"боль в груди\" как признак, на основании которого продолжим строить дерево.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OShei9iGFe__"
      },
      "source": [
        "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.3/L03/out/compute_gini_for_another_features.png\" width=\"600\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0E2HOUZEqCN"
      },
      "source": [
        "Именно $\\text{impurity decrease}$ используется для расчета атрибута [️️`feature_importances_`](https://scikit-learn.org/stable/auto_examples/ensemble/plot_forest_importances.html) в Sklearn. Для случайного леса (и других ансамблей) просто выдается среднее по деревьям.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sqFcZNfYEqCN"
      },
      "source": [
        "У данного метода есть **недостаток:** он может завышать качество признаков с большим количеством возможных значений.\n",
        "\n",
        "Даже если признак не информативен, но у него много значений, на нем можно выбрать большое количество порогов, по которым можно разбить данные, что приведет к переобучению."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05iVt25VFfAA"
      },
      "source": [
        "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.3/L03/out/decision_tree_for_real_numbers.png\" width=\"1000\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Бинарные и категориальные признаки с небольшим числом категорий потенциально могут получать заниженное качество по сравнению с вещественными, даже если те дают худшее разбиение."
      ],
      "metadata": {
        "id": "-gQg97zwfr0n"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5blYZCMwEqCN"
      },
      "source": [
        "### Пример для табличных данных (Boston Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9F5X0hwuEqCN"
      },
      "source": [
        "Посмотрим на важность признаков, основанную на **impurity decrease**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGKPh2CjEqCO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rng = np.random.RandomState(42)\n",
        "model = RandomForestRegressor(random_state=rng)\n",
        "model.fit(x_data, y_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lFKgMXiEqCO"
      },
      "outputs": [],
      "source": [
        "rf_model_importances = model.feature_importances_\n",
        "\n",
        "gini_importance = pd.DataFrame(\n",
        "    {\n",
        "        \"name\": feature_names,\n",
        "        \"feature importances\": rf_model_importances,\n",
        "    }\n",
        ").sort_values(\"feature importances\", ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-9mBMuuEqCO"
      },
      "outputs": [],
      "source": [
        "def importances_diagram(data, x, y, title, fmt=\"%.2f\"):\n",
        "    plt.title(title)\n",
        "    ax = sns.barplot(\n",
        "        data=data,\n",
        "        y=y,\n",
        "        x=x,\n",
        "        color=sns.xkcd_rgb[\"azure\"],\n",
        "        orient=\"h\",\n",
        "    )\n",
        "    for i in ax.containers:\n",
        "        ax.bar_label(i, fmt=fmt, label_type=\"edge\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adY4M5rVEqCO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(13, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "importances_diagram(\n",
        "    data=linear_importance,\n",
        "    x=\"abs(coef)\",\n",
        "    y=\"name\",\n",
        "    title=\"Linear model importances\",\n",
        ")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "importances_diagram(\n",
        "    data=gini_importance,\n",
        "    x=\"feature importances\",\n",
        "    y=\"name\",\n",
        "    title=\"Random forest importances\",\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MjwaQrGNEqCO"
      },
      "source": [
        "Можно видеть, что важность признаков для одних и тех же данных зависит от модели. При этом признаки `RM` — количество комнат в доме, и `LSTAT` — процент людей с низким социальным статусом (без среднего образования, безработных), важны для обеих моделей, что достаточно логично."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4uiZh03mEqCO"
      },
      "outputs": [],
      "source": [
        "num_unique = x_data.agg(lambda x: len(np.unique(x)))\n",
        "num_unique.name = \"num unique\"\n",
        "num_unique = pd.DataFrame(num_unique)\n",
        "num_unique[\"name\"] = num_unique.index\n",
        "gini_importance = gini_importance.merge(num_unique, how=\"inner\", on=\"name\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на соотношение между диаграммами количества уникальных значений у признаков и важностей признаков."
      ],
      "metadata": {
        "id": "MNv93-N8Cf23"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "my2BMPsiEqCO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(13, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "importances_diagram(\n",
        "    data=gini_importance,\n",
        "    x=\"num unique\",\n",
        "    y=\"name\",\n",
        "    title=\"Number of unique values in features\",\n",
        "    fmt=\"%d\",\n",
        ")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "importances_diagram(\n",
        "    data=gini_importance,\n",
        "    x=\"feature importances\",\n",
        "    y=\"name\",\n",
        "    title=\"Random forest importances\",\n",
        ")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o45ghTqhEqCO"
      },
      "source": [
        "Интересно отметить, что признаки `LSTAT`, `RM`, `DIS` и `CRIM`, оказавшиеся наиболее важными для Random Forest, имеют большое количество уникальных значений. В то же время признаки `AGE` и `B` также имеют большое количество уникальных значений, хотя их важность для модели случайного леса не высока."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JMJNK3AyEqCO"
      },
      "source": [
        "# Методы, изучающие отклик модели на изменение входных данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV_8KHtbEqCO"
      },
      "source": [
        "В этом разделе мы рассмотрим методы, изучающие отклик модели на изменение входных данных. Они также называются **Model-Agnostic Methods** и находятся ближе всего к концепции “черного ящика”. Эти методы изучают связь между входами и выходами модели и пытаются ее объяснить."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVZS8slrEqCO"
      },
      "source": [
        "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L14/out/black_box_interpretability.png\" alt=\"alttext\" width=\"500\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMyvNc3qEqCP"
      },
      "source": [
        "## ICE (Individual Conditional Expectation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9pGXVySEqCP"
      },
      "source": [
        "Одним из самых простых и интуитивно понятных методов является метод Individual Conditional Expectation (ICE). Он заключается в следующем:\n",
        "1. Обучаем и **фиксируем модель**.\n",
        "2. Выбираем **один объект**.\n",
        "3. Выбираем **один признак** этого объекта, который мы будем **менять в некотором диапазоне**, все остальные признаки фиксируем.\n",
        "4. Меняем этот признак и смотрим, как меняется **предсказание модели**.\n",
        "5. Строим кривую зависимости **предсказанного значения** от **изменяемого признака** для модели.\n",
        "\n",
        "Если применить метод ICE на множестве объектов, а затем усреднить результаты, то получится метод, который называется Partial Dependence (PD).\n",
        "\n",
        "Посмотрим, как этот метод работает на примере модели Random Forest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC0e3z-tEqCP"
      },
      "source": [
        "### Пример для табличных данных (Boston Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwIrWPnpEqCP"
      },
      "source": [
        "Загрузим и предобработаем  данные:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAS8aG2qEqCP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load dataset\n",
        "boston_dataset = pd.read_csv(\n",
        "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/boston_dataset.csv\",\n",
        "    index_col=0,\n",
        ")\n",
        "x_data = boston_dataset.iloc[:, :-1]\n",
        "y_data = boston_dataset[\"target\"].values\n",
        "\n",
        "boston_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I8GucS7hEqCP"
      },
      "source": [
        "Обучим модель:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxBP3-viEqCP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rng = np.random.RandomState(42)\n",
        "model = RandomForestRegressor(random_state=rng)\n",
        "model.fit(x_data, y_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m-cGD3HOEqCP"
      },
      "source": [
        "Нам интересно посмотреть на два признака, которые были наиболее важны для предсказания: **`RM`** — среднее количество комнат в жилье, **`LSTAT`** — процент людей с низким социальным статусом, и на один признак, который для  **Random Forest** не важен: **`AGE`** — возраст постройки.\n",
        "\n",
        "В Sklearn реализован класс `PartialDependenceDisplay` [[doc]🛠️](https://scikit-learn.org/stable/modules/generated/sklearn.inspection.PartialDependenceDisplay.html), который реализует методы ICE и PD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cIyP7qK0EqCP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.inspection import PartialDependenceDisplay\n",
        "\n",
        "_, ax = plt.subplots(ncols=3, figsize=(15, 5), sharey=True, constrained_layout=True)\n",
        "\n",
        "features_info = {\n",
        "    \"features\": [\"RM\", \"LSTAT\", \"AGE\"],  # features to inspect\n",
        "    \"kind\": \"both\",  # plot both individual lines (ICE) and average line (PD)\n",
        "}\n",
        "\n",
        "common_params = {\n",
        "    \"subsample\": 50,  # how many samples to draw\n",
        "    \"n_jobs\": 2,  # for parallelizing\n",
        "    \"grid_resolution\": 20,  # how many steps of feature changing on x-axis\n",
        "    \"random_state\": 0,  # seed for random sampling\n",
        "}\n",
        "\n",
        "x_data = pd.DataFrame(x_data, columns=x_data.columns)\n",
        "\n",
        "display = PartialDependenceDisplay.from_estimator(\n",
        "    model,\n",
        "    x_data,\n",
        "    **features_info,\n",
        "    ax=ax,\n",
        "    **common_params,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMNoe_hHEqCP"
      },
      "source": [
        "Синие линии — это ICE для отдельных объектов. По оси $x$ — изменяемые признаки для этих объектов, по оси $y$ — изменение целевого значения. Оранжевым цветом нарисовано среднее по объектам (PD).\n",
        "\n",
        "Видно, что увеличение количества комнат в большинстве случаев положительно влияет на цену жилья, увеличение процента людей с низким социальным статусом — отрицательно, а возраст постройки не важен.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AIyxat5KEqCP"
      },
      "source": [
        "## LIME (Local Interpretable Model-agnostic Explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irKqvi8fEqCP"
      },
      "source": [
        "### Принцип работы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10N3fabCEqCP"
      },
      "source": [
        "Нам бы хотелось оценивать все признаки одновременно для любой модели. Для этого можно попробовать **заменить \"черный ящик\"** (black-box) **\"прозрачным\"** (glass-box).\n",
        "\n",
        "Ключевая идея [**LIME**](https://arxiv.org/abs/1602.04938) — **локальная аппроксимация сложно-интерпретируемой** (black-box) модели при помощи **легко-интерпретируемой** (glass-box)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM_X9-RcEqCP"
      },
      "source": [
        "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L14/out/lime_idea.png\" width=\"400\"></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wd4u5F_YEqCQ"
      },
      "source": [
        "Давайте разбирать идею по частям:\n",
        "1. **Локальная аппроксимация** — значит, что мы берем **один объект** и **модифицируем** его (изменяем признаки), чтобы получить небольшой датасет, локализованный вокруг исходного объекта.\n",
        "2. **Сложно интерпретируемая модель** — модель, для которой мы проводим оценку (наш \"черный ящик\"). Ее мы используем для того, чтобы получить **предсказания** для датасета, построенного на основе одного объекта.\n",
        "3. Таким образом, мы получаем **датасет**, включающий **признаки** и **предсказания** “черного ящика”. На этом датасете **учим** “прозрачный ящик” — **легко-интерпретируемую модель**, для которой мы умеем определять важность признаков. Например, линейную модель или дерево решений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGT9aT5xEqCQ"
      },
      "source": [
        "Идею **LIME** можно проиллюстрировать следующим образом:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0nVYn7AOEqCQ"
      },
      "source": [
        "<center><img src =\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L14/out/lime_example.png\" width=\"1000\"></center>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHz5c8LEEqCQ"
      },
      "source": [
        "По **осям** отложены значения **двух непрерывных признаков**. Изначально мы имеем сложно интерпретируюмую модель, которая разделяет пространство признаков на две области со сложной границей.\n",
        "\n",
        "**Шаг 1.** Выбираем один объект, для которого мы хотим получить локальное объяснение (на иллюстрации это $\\large x^*$).\n",
        "\n",
        "**Шаг 2.** Семплируем вокруг интересущего нас объекта новые объекты (черные точки).\n",
        "\n",
        "**Шаг 3.** Используем исходную модель для разметки семплированных точек — получаем новый датасет, представляющий локальную область вокруг интересующего нас объекта.\n",
        "\n",
        "**Шаг 4.** Взвешиваем объекты из локального датасета с учетом их расстояния до интересующего нас объекта.\n",
        "\n",
        "**Шаг 5.** Обучаем на полученном локальном датасете линейную модель с учетом весов для новых объектов. В локальной области интересующего нас объекта линейная модель ведет себя схоже с исходной сложной моделью. Используем важность признаков простой линейной модели как оценку важностей признаков для сложной модели в локальной области интересующего нас объекта.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO41qP9REqCQ"
      },
      "source": [
        "### Как получить набор объектов вблизи искомого?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGtjVhf6EqCQ"
      },
      "source": [
        "* В **текстах** можно **удалить слово**.\n",
        "* Для **изображений** можно **делить картинку на области** (суперпиксели) и поочередно закрашивать их одним и тем же цветом (средним).\n",
        "* Для **табличных данных**:\n",
        " * для **бинарных** переменных в низкоразмерном пространстве достаточно просто менять значение переменной на противоположное (**0 на 1** и **1 на 0**),\n",
        " * для **вещественных переменных** были предложены различные варианты. Например, к ним можно прибавлять **Гауссов шум** или **дискретизировать** (например, по квантилям)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoDH3nd4EqCQ"
      },
      "source": [
        "### Ограничения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfTmcGcxEqCQ"
      },
      "source": [
        "Описанный подход позволяет интерпретировать поведение модели **только в некоторой области** вблизи интересующего нас объекта.\n",
        "\n",
        "На практике этого может быть достаточно. **Работает быстро**, так как не требует перебора всех комбинаций признаков."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvxATEZPL142"
      },
      "source": [
        "### Пример для табличных данных (Boston Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfe_zOZtL15S"
      },
      "source": [
        "Загрузим и предобработаем  данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3siyGa0L15T"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# load dataset\n",
        "boston_dataset = pd.read_csv(\n",
        "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/boston_dataset.csv\",\n",
        "    index_col=0,\n",
        ")\n",
        "x_data = boston_dataset.iloc[:, :-1].values\n",
        "y_data = boston_dataset[\"target\"].values\n",
        "\n",
        "boston_dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pthXmqguL15U"
      },
      "source": [
        "Обучим модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsG2jpUyL15V"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "rng = np.random.RandomState(42)\n",
        "model = RandomForestRegressor(random_state=rng)\n",
        "model.fit(x_data, y_data)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q lime"
      ],
      "metadata": {
        "id": "qnPEFWG_t0PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Применим Lime"
      ],
      "metadata": {
        "id": "avfCTfDUIBpA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lime.lime_tabular import LimeTabularExplainer\n",
        "\n",
        "\n",
        "explainer = LimeTabularExplainer(training_data=x_data,\n",
        "                                 training_labels=y_data,\n",
        "                                 mode=\"regression\",\n",
        "                                 feature_names = boston_dataset.columns.tolist())"
      ],
      "metadata": {
        "id": "o_tLpJ-XJEsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "explanation = explainer.explain_instance(x_data[42, :],\n",
        "                                         predict_fn=model.predict)\n",
        "\n",
        "explanation.show_in_notebook(show_table=True)"
      ],
      "metadata": {
        "id": "c3ZXqQJhJEzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yd-FiWtf4NNw"
      },
      "source": [
        "### Пример NLP (классификация статей)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pg-MZB5A4NNw"
      },
      "source": [
        "<center><img src=\"https://edunet.kea.su/repo/EduNet-web_dependencies/dev-2.3/L14/christian_or_atheist.png\" alt=\"alttext\" width=\"900\"/></center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2WQlcuw4NNw"
      },
      "source": [
        "Используем датасет [fetch_20newsgroups](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html).\n",
        "\n",
        "Данные [«The 20 Newsgroups»](http://qwone.com/~jason/20Newsgroups/) — это коллекция примерно из **20&nbsp;000 новостных документов**, разделенная (приблизительно) равномерно между **20 различными категориями**.\n",
        "\n",
        "Коллекция «The 20 Newsgroups» стала популярным набором данных для экспериментов с техниками машинного обучения для текстовых приложений, таких как классификация и кластеризация.\n",
        "\n",
        "В данном примере мы будем использовать [Multinomial Naive Bayes](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html) для классификации и TF-IDF для представления текстов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyHFT4Lo4NNx"
      },
      "outputs": [],
      "source": [
        "import sklearn\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "newsgroups_train = fetch_20newsgroups(subset=\"train\")\n",
        "newsgroups_test = fetch_20newsgroups(subset=\"test\")\n",
        "# making class names shorter\n",
        "class_names = [\n",
        "    x.split(\".\")[-1] if \"misc\" not in x else \".\".join(x.split(\".\")[-2:])\n",
        "    for x in newsgroups_train.target_names\n",
        "]\n",
        "class_names[3] = \"pc.hardware\"\n",
        "class_names[4] = \"mac.hardware\"\n",
        "\n",
        "for i, class_name in enumerate(class_names):\n",
        "    print(f\"{i:<3d}{class_name}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9rYsqH64NNx"
      },
      "source": [
        "Мы берем **два класса**, которые трудно различить, потому что в них много схожих слов: **христианство и атеизм**.\n",
        "\n",
        "Обучая модель, мы получаем **точность на тестовых данных 83,5%**, что является удивительно высоким показателем. Если бы точность была нашим единственным мерилом доверия, мы бы точно доверились этому классификатору."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gDV05U74NNx"
      },
      "outputs": [],
      "source": [
        "import sklearn.metrics\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Again, let's use the tfidf vectorizer, commonly used for text.\n",
        "vectorizer = sklearn.feature_extraction.text.TfidfVectorizer(lowercase=False)\n",
        "train_vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
        "test_vectors = vectorizer.transform(newsgroups_test.data)\n",
        "\n",
        "# Train the model\n",
        "model_nb = MultinomialNB(alpha=0.01)\n",
        "model_nb.fit(train_vectors, newsgroups_train.target)\n",
        "\n",
        "# Calculate F1_score\n",
        "pred = model_nb.predict(test_vectors)\n",
        "\n",
        "f1_metric = sklearn.metrics.f1_score(newsgroups_test.target, pred, average=\"weighted\")\n",
        "\n",
        "print(f\"f1-score on test: {f1_metric:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3ROYOoR4NNx"
      },
      "source": [
        "Мы видим, что этот классификатор имеет очень высокий F1 score. [Руководство Sklearn для 20 newsgroups](https://scikit-learn.org/stable/modules/naive_bayes.html#multinomial-naive-bayes) указывает, что **Multinomial Naive Bayes переобучается** на этом наборе данных, изучая нерелевантные взаимосвязи, такие как заголовки."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dbyyJv3A4NNx"
      },
      "source": [
        "Теперь мы используем **LIME** для объяснения отдельных предсказаний.\n",
        "\n",
        "Как видно из кода, текст подается на вход модели не в сыром виде, а после предобработки объектом `vectorizer`.\n",
        "\n",
        "Сперва нам потребуется создать обертку — пайплайн, который объединяет `vectorizer` и модель:\n",
        "\n",
        "[`sklearn.pipeline.make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00yVYn3d4NNx"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "model_with_preprocessing = make_pipeline(vectorizer, model_nb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lutq9yWK4NNx"
      },
      "source": [
        "[`LimeTextExplainer`](https://lime-ml.readthedocs.io/en/latest/lime.html#lime.lime_text.LimeTextExplainer) имеет метод `explain_instance` с такими аргументами:\n",
        "\n",
        "\n",
        "```python\n",
        "explain_instance(\n",
        "    text_instance,\n",
        "    classifier_fn,\n",
        "    labels=(1, ),\n",
        "    top_labels=None,\n",
        "    num_features=10,\n",
        "    num_samples=5000,\n",
        "    distance_metric=\"cosine\",\n",
        "    model_regressor=None)\n",
        "```\n",
        "\n",
        "**`classifier_fn`** *— функция для классификации, которая получает список из `d` строк и выдает `(d, k)` numpy-массив с предсказанными вероятностями для `k` классов.*\n",
        "\n",
        "В нашем случае такой функцией будет `model_with_preprocessing.predict_proba`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OojyUH54NNx"
      },
      "source": [
        "Давайте посмотрим на LIME-объяснение для произвольного экземпляра в тестовом наборе.\n",
        "\n",
        "В случае многоклассовой классификации мы должны определить, для каких меток хотим получить объяснения, с помощью параметра `labels`. **Сгенерируем пояснения** для меток 0 и 15:\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zIBiQvg4NNy"
      },
      "outputs": [],
      "source": [
        "!pip install -q lime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmQHouyk4NNy"
      },
      "outputs": [],
      "source": [
        "import lime\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=class_names, random_state=42)\n",
        "idx = 1340\n",
        "explanation = explainer.explain_instance(\n",
        "    newsgroups_test.data[idx],\n",
        "    model_with_preprocessing.predict_proba,\n",
        "    num_features=10,\n",
        "    labels=[0, 15],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy3dau724NNy"
      },
      "source": [
        "Возвращается специальный объект класса [`Explanation`](https://lime-ml.readthedocs.io/en/latest/lime.html?highlight=Explanation#lime.explanation.Explanation):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V2kfozm4NNy"
      },
      "outputs": [],
      "source": [
        "print(explanation.as_list(label=0))\n",
        "print(explanation.as_list(label=15))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o0acxezN4NNy"
      },
      "source": [
        "Обратите внимание, что положительный и отрицательный знаки относятся к конкретной метке, так что слова, отрицательные по отношению к классу 0, могут быть положительными по отношению к классу 15, и наоборот."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7paWBIc94NNy"
      },
      "source": [
        "Теперь давайте посмотрим на **визуализацию объяснений**.\n",
        "Обратите внимание на то, что для каждого класса слова в правой части строки являются «положительными», а слова в левой части — «отрицательными» для объясняемого класса.\n",
        "\n",
        "Также видно, что в классификаторе используются как **осмысленные слова** (такие как «Theism», «Genocide» и т. д.), так и **неосмысленные** (название университета «Rice», домен «owlnet»)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DgVF-3ZT4NNy"
      },
      "outputs": [],
      "source": [
        "explanation.show_in_notebook(text=newsgroups_test.data[idx], labels=(0,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QwdWCjd4NNy"
      },
      "outputs": [],
      "source": [
        "explanation.show_in_notebook(text=newsgroups_test.data[idx], labels=(15,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kS_abUCJ4NNy"
      },
      "source": [
        "На этом примере можно увидеть, что в заголовке или кавычках может быть и полезный сигнал, который будет помогать обобщению (например,  в строке «Тема»).\n",
        "\n",
        "А есть и **слова, которые нельзя обобщать** (например, адреса электронной почты и названия учреждений)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1I3EpC4aEqCU"
      },
      "source": [
        "## SHAP (SHapley Additive exPlanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYxl71XfEqCU"
      },
      "source": [
        "###Принцип работы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdO-gAr9EqCU"
      },
      "source": [
        "<center><img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L14/out/shap_scheme.png\" alt=\"alttext\" width=\"600\"/></center>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_IFfRN8VEqCU"
      },
      "source": [
        "Цель [**SHAP** 📚[book]](https://christophm.github.io/interpretable-ml-book/shap.html) — объяснить предсказание объекта $x$ путем **вычисления вклада каждого признака** в предсказание. Для этого вычисляются SHAP-значения, основанные на **значениях Шепли** из **теории игр**.\n",
        "\n",
        "**SHAP** рассматривает объясняемую **модель как игру**, а **признаки** объектов — как **коалицию игроков**. **SHAP-значения** говорят нам, как **справедливо распределить \"выигрыш\" между игроками** — это вклад, который каждый признак вносит в предсказание модели.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0itqcjWCEqCU"
      },
      "source": [
        "### Свойства чисел Шепли"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcbmKpQwEqCU"
      },
      "source": [
        "Числа Шепли, разработанные Ллойдом Шепли в 1953 году, являются важным понятием в теории кооперативных игр. Они справедливо распределяют общий выигрыш коалиции игроков, учитывая индивидуальные вклады каждого участника. Числа Шепли определяют вклад каждого игрока, анализируя все возможные коалиции и вычисляя средний предельный вклад каждого игрока."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmPUnWEMEqCU"
      },
      "source": [
        "Числа Шепли обладают рядом свойств, которые делают их эффективными и справедливыми. Перечислим некоторые из них:\n",
        "\n",
        "1. **Эффективность**: сумма чисел Шепли всех игроков равна общему выигрышу коалиции. Это означает, что весь выигрыш распределяется без остатка.\n",
        "\n",
        "2. **Нулевая игра**: игрок, не вносящий дополнительного вклада ни в одну коалицию, получает нулевое вознаграждение. Это означает, что ненужные или неактивные участники не получают долю выигрыша.\n",
        "\n",
        "3. **Симметрия**: если два игрока вносят одинаковый вклад во все возможные коалиции, они получают одинаковое вознаграждение. Это свойство обеспечивает справедливое распределение в случае равного вклада."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqdEMQO-EqCU"
      },
      "source": [
        "### Теоретико-игровой пример"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emaUwvCGEqCU"
      },
      "source": [
        "Рассмотрим на примере, как оценивается вклад игроков в общий выигрыш с помощью чисел Шепли.\n",
        "\n",
        "Пусть у нас есть уличная музыкальная группа из трех участников: барабанщика, гитариста и солиста. Они выступают на улице и собирают деньги в шляпу. Музыканты хотят оценить, **какой вклад в заработок привносит каждый участник группы**.\n",
        "\n",
        "Для этого можно устроить эксперимент: несколько вечеров подряд группа будет выступать для публики **в разных комбинациях состава участников** (на иллюстрации все комбинации изображены в виде вершин графа и пронумерованы, ребра графа обозначают добавление участника в состав):\n",
        "* пустое множество участников (пустая шляпа на улице, вершина $1$),\n",
        "* все участники по одному (вершины $2$–$4$),\n",
        "* все участники по двое (вершины $5$–$7$),\n",
        "* полный состав из трех музыкантов (вершина $8$)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOK3g39wEqCU"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L14/out/shap_features_graph.png\" alt=\"alttext\" width=\"550\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_5U-5qLEqCU"
      },
      "source": [
        "Для простоты представим, что каждый вечер тот или иной состав группы\n",
        "оценивается одной и той же публикой. Оценкой является заработок за вечер. Музыканты поиграли по такой схеме все восемь вечеров и зафиксировали заработок за каждый вечер."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-79RTHaEqCU"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L14/out/shap_predictions_graph.png\" alt=\"alttext\" width=\"550\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXSCcn-hEqCU"
      },
      "source": [
        "Теперь в каждой вершине графа находится оценка того или иного состава группы публикой.\n",
        "\n",
        "Зная оценки всех возможных комбинаций состава этой группы, мы можем посчитать вклад каждого участника в итоговый заработок.\n",
        "\n",
        "Вклад участника в заработок вычисляется на основании так называемых **дополнительных вкладов** *(marginal contribution, MC)*.\n",
        "\n",
        "**Дополнительный вклад игрока** — это **разница** между заработком состава, **включающим данного игрока**, и заработком состава **без данного игрока**.\n",
        "\n",
        "В данном случае можно рассчитать дополнительный вклад для игрока как разницу оценок вершин, соединенных ребром в графе."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEEdZU6yEqCU"
      },
      "source": [
        "Например, дополнительный вклад барабанщика по сравнению с пустой группой\n",
        "$\\{∅\\}$ рассчитывается следующим образом (см. вершины $2$ и $1$):\n",
        "\n",
        "\n",
        "$$ \\large \\text{MC}_{🥁,\\{∅\\}}= \\text{Earning}_{\\{🥁\\}}\\ - \\text{Earning}_{\\{∅\\}}=  4\\ 000 - 0 = 4\\ 000$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n91o5n1hEqCU"
      },
      "source": [
        "А дополнительный вклад барабанщика при добавлении его в пару к солисту будет равен (см. вершины $6$ и $4$):\n",
        "\n",
        "$$ \\large \\text{MC}_{🥁,\\{🎤\\}}= \\text{Earning}_{\\{🥁🎤\\}}\\ \\ - \\text{Earning}_{\\{🎤\\}}\\ =  8\\ 500 - 10\\ 000 = -\\ 1\\ 500$$\n",
        "\n",
        "Отрицательный дополнительный вклад возможен и означает, что добавление учасника в группу снижает заработок (может быть, барабанщик играет невпопад и без него солист получает больше, чем с ним)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFOdDyNXEqCU"
      },
      "source": [
        "Для того, чтобы **оценить итоговый вклад барабанщика** в оценку всей группы публикой, нужно учесть его **дополнительные вклады** во все комбинации, **где он участвовал** (в графе выделены соответствующие вершины):"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPnTqrxeEqCU"
      },
      "source": [
        "<center>\n",
        "<img src=\"https://edunet.kea.su/repo/EduNet-content/dev-2.1/L14/out/shap_estimation_important_features.png\" alt=\"alttext\" width=\"550\"/>\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPkwH7ZGEqCV"
      },
      "source": [
        "SHAP-значение для барабанщика в этой группе является общим вкладом игрока в заработок и вычисляется как **взвешенная сумма его дополнительных вкладов**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QUwgY-9xEqCV"
      },
      "source": [
        "$$ \\large \\text{SHAP}_{🥁}=w_1\\cdot \\text{MC}_{🥁,\\{\\emptyset\\}}+w_2\\cdot \\text{MC}_{🥁,\\{🎸\\}}+w_3\\cdot \\text{MC}_{🥁,\\{🎤\\}}+w_4\\cdot \\text{MC}_{🥁,\\{🎸🎤\\}} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7uPyd4WEqCV"
      },
      "source": [
        "Веса определяются согласно правилу: сумма весов дополнительных вкладов для каждого уровня графа должна быть равной 1.\n",
        "\n",
        "Таким образом, нетрудно рассчитать веса дополнительных вкладов барабанщика:\n",
        "* первый уровень содержит $3$ ребра, каждое из которых будет иметь вес $\\dfrac{1}{3}$\n",
        "* второй уровень содержит $6$ ребер, каждое из которых будет иметь вес $\\dfrac{1}{6}$\n",
        "* третий уровень содержит $3$ ребра, каждое из которых будет иметь вес $\\dfrac{1}{3}$\n",
        "\n",
        "Таким образом: $\\displaystyle w_1=w_4=\\frac{1}{3}, \\; w_2=w_3=\\frac{1}{6}$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44g1rS5LEqCV"
      },
      "source": [
        "**В этой аналогии:**\n",
        "* конкретный музыкальный коллектив — это один объект выборки,\n",
        "* музыканты — это признаки,\n",
        "* публика — это модель,\n",
        "* заработок группы (оценка группы публикой) — предсказание модели (оценка объекта моделью).\n",
        "\n",
        "Однако эта аналогия в случае моделей машинного обучения требует дополнительного пояснения. В примере с музыкальной группой мы использовали одну модель (публику) для оценки разных комбинаций признаков (разных составов группы).\n",
        "\n",
        "Отсутствие какого-то игрока в группе означает отсуствие признака в признаковом описании объекта. Большинство моделей ML не могут работать с пропущенными значениями (то есть с признаковыми описаниями различной длины). Поэтому для получения оценок придется всякий раз **обучать модель заново на новом подмножестве признаков** (сохраняя гиперпараметры модели и набор обучающих объектов).\n",
        "\n",
        "Для получения предсказания модели для пустого множества признаков может быть использовано, например, среднее значение целевой переменной по обучающей выборке.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sckkSolEEqCV"
      },
      "source": [
        "### Kernel SHAP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1QN7ZHaEqCV"
      },
      "source": [
        "У описанного выше метода есть недостаток: нам нужно обучить огромное количество моделей. Для всего десяти признаков это $2^{10} = 1024$ модели.\n",
        "\n",
        "На помощь нам приходит статья [A Unified Approach to Interpreting Model Predictions](https://arxiv.org/pdf/1705.07874.pdf). В ней введено понятие **аддитивного метода атрибуции признаков**, в котором в качестве \"стеклянного ящика\" используется функция бинарных переменных (есть признак/нет признака):\n",
        "\n",
        "$$\\large g(z') = \\phi_0 +\\sum_{i=1}^M\\phi_i z_i',$$\n",
        "\n",
        "где $z'\\in\\{0,1\\}^M$ — вектор из $0$ и $1$ длины $M$: $0$ — отсутствие признака, $1$ — наличие признака, $M$ — количество упрощенных признаков (например, суперпикселей для изображения), $\\phi_i$ — вклад (важность) $i$-го упрощенного признака."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvY13XBGEqCV"
      },
      "source": [
        "Для адекватного описания работы модели данный метод должен удовлетворять трем свойствам. Эти свойства позволяют методу SHAP обеспечивать интерпретируемость и справедливость оценки важностей признаков для моделей машинного обучения, подобно тому, как числа Шепли обеспечивают справедливое распределение выигрыша в теории игр.\n",
        "\n",
        "1. **Local Accuracy** (локальная точность, аналог свойства \"Эффективность\" для чисел Шепли) — результат модели объяснения $g(x’)$ должен совпадать с результатом оригинальной модели $f(x)$ (вклад всех признаков суммируется в значение предсказания модели):\n",
        "\n",
        "$$\\large f(x)=g(x')=\\phi_0 +\\sum_{i=1}^M\\phi_i x_i',$$\n",
        "\n",
        "где:\n",
        "* $x' = \\{x_1', x_2', ...,x_M'\\}$ — упрощенные признаки объекта (например, суперпиксели для изображения),\n",
        "*  $x$ — оригинальный набор признаков объекта (например, значения RGB пикселей изображения),\n",
        "* упрощенный набор признаков переводится в оригинальный с помощью функции $h_x(x)$:\n",
        "\n",
        "$$\\large x=h_x(x')$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92LsoodNEqCV"
      },
      "source": [
        "2. **Missingness (отсутствие влияния отсутствующих признаков, аналог свойства \"Нулевая игра\" для чисел Шепли)** — если признак отсутствует ($x_i = \\text{None}$ означает, что упрощенный признак $x_i' = 0$), он вносит нулевой вклад:\n",
        "\n",
        "$$\\large x_i' = 0 \\Rightarrow \\phi_i = 0$$\n",
        "\n",
        "Это свойство означает, что признаки, не влияющие на предсказание модели, имеют нулевые значения SHAP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vj14wO9PEqCV"
      },
      "source": [
        "3. **Consistency (согласованность)** — если для двух моделей $f'$ и $f$ устранение $i$-го признака изменяет предсказание первой модели больше, чем второй, то и SHAP-значение $\\phi_i$ для этого признака должно быть больше для первой модели. Формально это свойство выражается таким образом:\n",
        "\n",
        "> Пусть $f_x(z')=f(h_x(z'))$ и $z' \\text{\\\\} i$ обозначает установку $z_i'=0$. Для двух любых моделей $f$ и $f'$, **если**\n",
        "\n",
        "> $$\\large f'_x(z') - f'_x(z'\\text{\\\\}i) \\geq f_x(z') - f_x(z'\\text{\\\\}i)$$\n",
        "\n",
        "> для всех входов $z'\\in\\{0,1\\}^M$, **тогда** $\\large \\phi_i(f', x) \\geq \\phi_i(f, x)$.\n",
        "\n",
        "Это свойство обеспечивает интуитивную согласованность между разными моделями: если $i$-й признак важнее для первой модели, чем для второй, то и его SHAP-значение должно быть больше для первой модели, чем для второй."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZWugVffEqCV"
      },
      "source": [
        "Такой метод расчета называется Kernel SHAP. Он позволяет не обучать огромное количество моделей и реализовать вычисление значений Шепли за конечное время. Именно так считаются значения Шепли в библиотеке SHAP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ax6NYcFEqCV"
      },
      "source": [
        "### Пример для табличных данных (Boston Dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5__RFkxcEqCV"
      },
      "source": [
        "Установим пакет SHAP:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V62rfcrlEqCV"
      },
      "outputs": [],
      "source": [
        "!pip install -q shap"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmyX-OfpEqCV"
      },
      "source": [
        "Для примера скачаем датасет жилья Бостона (`boston_dataset.csv`), в котором проанализируем зависимость цены на жилье от параметров жилья и района, в котором оно находится."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P82C0PHJEqCV"
      },
      "source": [
        "Разобьем данные на обучающие и тестовые и обучим Random Forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ljxZB7mEqCW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "\n",
        "# load dataset\n",
        "boston_dataset = pd.read_csv(\n",
        "    \"https://edunet.kea.su/repo/EduNet-web_dependencies/datasets/boston_dataset.csv\",\n",
        "    index_col=0,\n",
        ")\n",
        "x_data = boston_dataset.iloc[:, :-1]\n",
        "y_data = boston_dataset[\"target\"]\n",
        "\n",
        "# Split the data into train and test data\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    x_data, y_data, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Build the model with the random forest regression algorithm\n",
        "rng = np.random.RandomState(42)\n",
        "model = RandomForestRegressor(n_jobs=-1, max_depth=4, random_state=rng)\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIHZILbYEqCW"
      },
      "source": [
        "Применим SHAP."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPh3l2lnEqCW"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# explain the model's predictions using SHAP\n",
        "# (same syntax works for LightGBM, CatBoost, scikit-learn and spark models)\n",
        "explainer = shap.TreeExplainer(model)\n",
        "explanations = explainer(x_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOPwTyZUEqCW"
      },
      "source": [
        "Вызов `explainer` возвращает объект класса `Explanation`, который хранит:\n",
        "- данные, для которых получены SHAP-объяснения, в атрибуте `.data`,\n",
        "- массив SHAP-значений для каждого признака каждого объекта в атрибуте `.values`,\n",
        "- массив базовых значений для каждого объекта в атрибуте `.base_values`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pUwJX1WEqCW"
      },
      "outputs": [],
      "source": [
        "print(f\"Type of the explanations object: {type(explanations)}\")\n",
        "\n",
        "print(f\"Shape of x_test:                       {x_test.shape}\")\n",
        "print(f\"Shape of the explanations data:        {explanations.data.shape}\")\n",
        "print(f\"Shape of the explanations SHAP values: {explanations.values.shape}\")\n",
        "print(f\"Shape of the explanations base values: {explanations.base_values.shape}\\n\")\n",
        "\n",
        "print(\n",
        "    f\"Is explanations.data equal x_test: {(explanations.data == x_test.values).all()}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUu8pkK4EqCW"
      },
      "source": [
        "**Force plot**\n",
        "\n",
        "Хороший способ визуализировать вклад каждого признака в конкретный прогноз — использовать так называемый \"график сил\" (force plot).\n",
        "\n",
        "В приведенном ниже примере показан график сил для первого объекта в тестовом наборе данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MNUxL_CEqCW"
      },
      "outputs": [],
      "source": [
        "# load JS visualization code to notebook\n",
        "shap.initjs()\n",
        "# visualize the first prediction’s explanation\n",
        "shap.plots.force(explanations[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQq2qvwrEqCW"
      },
      "source": [
        "* $f(x)$ — это прогноз модели по анализируемому объекту недвижимости. А \"base value\" — это средний прогноз по всему набору тестовых данных. Или, другими словами, это значение, которое можно было бы спрогнозировать, если бы мы не знали никаких характеристик текущего примера.\n",
        "\n",
        "* Признаки, которые способствуют увеличению цены, показаны красным, а те, которые уменьшают, — синим.\n",
        "\n",
        "* Длина стрелки — “сила” влияния. Численное значение (оно не совпадает с длиной) — важность признака. Из нашего анализа мы помним, что увеличение `RM` положительно влияет на предсказание, но для данного объекта значение `RM` влияет на цену отрицательно и, возможно, это повод дополнительно исследовать данный объект."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJrmL0S1EqCW"
      },
      "source": [
        "**Waterfall plot**\n",
        "\n",
        "Другой способ визуализации SHAP-объяснения для конкретного примера — так называемый \"график-водопад\" (waterfall plot). Фактически это график сил, где стрелки, обозначающие сдвиг предсказания от базового значения за счет SHAP-значений, расположены одна под другой, начиная с самой длинной сверху."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ezxNRv4EqCW"
      },
      "outputs": [],
      "source": [
        "# visualize the first prediction's explanation using waterfall\n",
        "\n",
        "shap.plots.waterfall(explanations[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EoJj-SzZEqCW"
      },
      "source": [
        "Этот график объясняет движущие силы конкретного прогноза: влияние каждого отдельного признака (наименее значимые признаки объединяются в одну группу) представлено стрелками, которые перемещают предсказание влево и вправо, начиная с базового значения (внизу картинки).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9sbz94GIEqCX"
      },
      "source": [
        "Указанный выше пример приведен только для одного объекта.\n",
        "\n",
        "Если мы возьмем много объяснений в виде графика сил, повернем их на 90 градусов, а затем сложим их по горизонтали, мы сможем увидеть объяснения для всего набора данных (в блокноте этот график является интерактивным):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzi-H7OaEqCX"
      },
      "outputs": [],
      "source": [
        "# load JS visualization code to notebook\n",
        "shap.initjs()\n",
        "# visualize the training set predictions\n",
        "shap.force_plot(explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEwEy27IEqCX"
      },
      "source": [
        "* По оси $x$ — объекты, по оси $y$ — вклад признаков в предсказание для каждого объекта. Важно заметить, что объекты упорядочены по схожести, которая считается по расстоянию между объектами.\n",
        "* Можно использовать выпадающее меню, чтобы посмотреть, как будет выглядеть график без упорядочивания или при упорядочивании по конкретному признаку.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjc4NLFSEqCX"
      },
      "source": [
        "**Bar plot**\n",
        "\n",
        "Сводный график `shap.plots.bar` даст нам график важности признаков.\n",
        "\n",
        "Признаки с высокой предсказательной способностью показаны вверху, а с низкой предсказательной силой — внизу."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld4ki4D-EqCX"
      },
      "outputs": [],
      "source": [
        "shap.plots.bar(explanations)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fmo5QrCcEqCX"
      },
      "source": [
        "Обратите внимание, что, согласно SHAP, наименьшей предсказательной способностью обладают признаки **`CHAS`, `ZN`, `RAD`** и **`INDUS`**.\n",
        "\n",
        "Здесь мы только что рассмотрели алгоритм `TreeExplainer` для интерпретации модели.\n",
        "\n",
        "Вы можете изучить остальные алгоритмы: `DeepExplainer`, `KernelExplainer`, `LinearExplainer` и `GradientExplainer`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdPMpAG_EqCX"
      },
      "source": [
        "### Пример NLP (перевод с английского на русский)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xv5sc6RQEqCX"
      },
      "source": [
        "С помощью SHAP можно строить интерпертации предсказаний более сложных, в том числе нейросетевых, моделей.\n",
        "\n",
        "Рассмотрим пример интерпретации модели для предварительно обученной модели машинного перевода\n",
        "[Machine Translation Explanations 🐾[git]](https://github.com/slundberg/shap/blob/master/notebooks/text_examples/translation/Machine%20Translation%20Explanations.ipynb). Для перевода будем использовать предобученную [модель-трансформер 🎓[arxiv]](https://arxiv.org/abs/1810.04805)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7AXrBfVEqCX"
      },
      "source": [
        "Используем одну из моделей [Hugging Face 🐾[git]](https://github.com/huggingface/transformers).\n",
        "\n",
        "Модель: [Language Technology in Helsinki ✏️[blog]](https://blogs.helsinki.fi/language-technology/)\n",
        "\n",
        "[[doc] 🛠️ Language Technology Research Group at the University of Helsinki](https://huggingface.co/Helsinki-NLP)\n",
        "\n",
        "[[doc] 🛠️ Helsinki-NLP/opus-mt-en-ru](https://huggingface.co/Helsinki-NLP/opus-mt-en-ru)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXr9POlsEqCX"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers[sentencepiece]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHkalVBxEqCX"
      },
      "source": [
        "Загружаем модель.\n",
        "\n",
        "Для этого используется класс `AutoModelForSeq2SeqLM`, на вход которому передается имя модели, а возвращает он объект соответствующего класса."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z11ukKmbEqCX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from IPython.display import clear_output\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "lang = \"en\"\n",
        "target_lang = \"ru\"\n",
        "model_name = f\"Helsinki-NLP/opus-mt-{lang}-{target_lang}\"\n",
        "\n",
        "# Download the model and the tokenizer\n",
        "# can also try translation with different pre-trained models\n",
        "\n",
        "# It's a Factory pattern\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "model.to(device)\n",
        "clear_output()\n",
        "print(type(model))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGllMyuKEqCX"
      },
      "source": [
        "В данном случае нам вернулся объект типа `MarianMT` [🛠️[doc]](https://huggingface.co/transformers/model_doc/marian.html).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae-jRxchEqCX"
      },
      "source": [
        "Теперь создадим [токенайзер 🛠️[doc]](https://huggingface.co/transformers/main_classes/tokenizer.html).\n",
        "\n",
        "Как мы уже обсуждали, токенайзер преобразовывает слова и знаки препинания из исходного текста в токены, которые можно подать на вход модели. В данном случае возвращаются id. При этом не всегда одно слово преобразовывается в один токен, иногда слово разбивается по слогам на несколько токенов.\n",
        "\n",
        "Токенайзер создается с помощью класса `AutoTokenizer` по имени модели."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCM82THFEqCX"
      },
      "outputs": [],
      "source": [
        "!pip install -q sacremoses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byW1PWg7EqCX"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "clear_output()\n",
        "\n",
        "print(type(tokenizer))\n",
        "\n",
        "input = tokenizer(\"Hello world!\", return_tensors=\"pt\")\n",
        "print(input)\n",
        "\n",
        "translated = model.generate(\n",
        "    **tokenizer(\"Hello world!\", return_tensors=\"pt\").to(device), max_new_tokens=512\n",
        ")\n",
        "# ** -  is dictionary unpack operator\n",
        "# https://pavel-karateev.gitbook.io/intermediate-python/sintaksis/args_and_kwargs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdNuESKCEqCY"
      },
      "source": [
        "Теперь переведем целую фразу и проанализируем, как выход модели связан со входом.\n",
        "\n",
        "Для этого создадим объект `shap.Explainer` [🛠️[doc]](https://shap.readthedocs.io/en/latest/generated/shap.Explainer.html), который в данном случае инициализируется экземпляром модели и экземпляром токенайзера.\n",
        "\n",
        "\n",
        "\n",
        "> *В действительности вторым параметром конструктора `shap.Explainer` не обязательно должен быть токенайзер. `shap.Explainer` принимает объект, поддерживающий интерфейс `masker`:*\n",
        "\n",
        "> ```masked_args = masker(*model_args, mask=mask)```\n",
        "\n",
        "> *Он используется для исключения части аргументов, и токенайзеры поддерживают этот интерфейс (`shap.TokenMasker`). Благодаря такому подходу SHAP может работать с различными моделями как с \"черным ящиком\".*\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Вместо того, чтобы запускать саму модель, мы запускаем `Explainer` (неявно вызывая его метод `__call__`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP-_siu5EqCY"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "\n",
        "# Define the input sentences we want to translate\n",
        "data = [\"SHAP is a method to explain machine learning models predictions.\"]\n",
        "\n",
        "# We build an explainer by passing the model we want to explain and\n",
        "# the tokenizer we want to use to break up the input strings\n",
        "explainer = shap.Explainer(model, tokenizer, max_new_tokens=512)\n",
        "\n",
        "# Explainers are callable, just like models\n",
        "explanation = explainer(data)\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLsouooSEqCY"
      },
      "source": [
        "На выходе получаем объект класса `shap.Explanation` [🛠️[doc]](https://shap.readthedocs.io/en/latest/generated/shap.Explanation.html#shap-explanation), который содержит значения Шепли для каждого токена."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L3EpFRuXEqCY"
      },
      "outputs": [],
      "source": [
        "print(\"Data\", explanation.data)\n",
        "print(\"SHAP values shape\", explanation.shape)  # 1, in, out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-rELAz2EqCY"
      },
      "source": [
        "Теперь, используя интерактивную визуализацию `shap.plots.text` [🛠️[doc]](https://shap.readthedocs.io/en/latest/example_notebooks/api_examples/plots/text.html), можно отобразить результат объяснения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l65TzEUNEqCY"
      },
      "outputs": [],
      "source": [
        "shap.initjs()\n",
        "shap.plots.text(explanation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THFw_vrAEqCY"
      },
      "source": [
        "Данная языковая модель предсказывает эмбеддинги — вектора, которые преобразуются в токены. При этом SHAP для оценки важности использует сжатые представления эмбеддингов. В данном случае наибольший интерес представляет не раскраска `outputs` (абсолютное значение сжатого представления эмбеддинга на выходе), а подсветка `inputs`, которая появляется, когда мы нажимаем на выходной токен. Она показывает, какие входные токены влияют на выходной.\n",
        "\n",
        "Анализ важностей через SHAP в данном примере похож на анализ карт внимания в трансформерах: можно проследить, какие входные токены наиболее важны для конкретного выходного токена. При этом SHAP дает более наглядную визуализацию, напрямую связывая выход и вход модели. Анализ карт внимания затруднителен в больших моделях, состоящих из многих слоев: сложно проследить полный путь трансформации входных токенов в выходные, так как важности \"размываются\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoDfsfJz2Xcl"
      },
      "source": [
        "# Заключение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njhfX2Wu2Xcl"
      },
      "source": [
        "Мы рассмотрели основные методы, которые используются для оценки важности признаков для моделей классического ML. Линейные модели и модели, основанные на деревьях, могут быть объяснены нативно исходя из принципов их построения и работы. В иных случаях могут быть полезны методы, которые пытаются интерпретировать предсказания модели основываясь на изменении входных данных. Среди таких мы рассмотрели LIME и SHAP.\n",
        "\n",
        "Пренебрежение объяснением того, почему модель дала тот или иной результат, ведет к недоверию по отношению не только к самой модели, но и к конкретным прогнозам, и, следовательно, является существенным препятствием для внедрения вашей модели или публикации статьи в научном журнале.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}