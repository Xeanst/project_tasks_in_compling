## Проектные задачи компьютерной лингвистики

Цель курса – обеспечить системное представление о современных методах обработки текстовых данных с использованием машинного обучения и нейронных сетей, а также сформировать практические навыки их применения. Программа разделена на теоретическую и проектную части, что позволяет студентам не только освоить ключевые концепции, но и применить их в процессе научно-исследовательской работы.

Курс является обязательным для студентов 4 курса бакалавриата кафедры теоретической и прикладной лингвистики МГУ им. М. В. Ломоносова. 

<!DOCTYPE html>
<html>
    <table>
        <tr>
    <th>Тема</th>
    <th>Содержание</th>
    <th>Материалы</th>
  </tr>
        <tr>
            <td colspan="3" >А. Теоретическая часть</td>
        </tr>
        <tr>
            <td>1. Введение в обработку текстовых данных</td>
            <td>
                <li>Предобработка текста: токенизация, приведение к нижнему регистру, удаление стоп-слов, нормализация (стемминг и лемматизация).</li>
                <li>Методы векторизации текстов: мешок слов, TF-IDF.</li>
                <li>Алгоритмы классификации: наивный байесовский классификатор, логистическая регрессия, дерево решений, наивный байесовский классификатор, случайный лес.</li>
                <li>Меры качества классификации.</li>
                <li>Пример классификации новостных текстов по тематикам.</li>
            </td>
            <td><a href="https://colab.research.google.com/drive/1iWF2hisv50MZ7AKi585tPldjEYmeAxay?usp=sharing">Colab-блокнот</a></td>
        </tr>
        <tr>
            <td>2. Векторные представления слов</td>
            <td>
                <li>Модель word2vec: алгоритмы skip-gram и CBOW.</li>
                <li>Оптимизация negative sampling.</li>
                <li>FastText: векторы для символьных n-грамм.</li>
                <li>Самостоятельная реализация в pytorch.</li>
                <li>Использование предобученных моделей.</li>
            </td>
            <td><a href="https://colab.research.google.com/drive/1fx7U398lcwIoPGp1vn2e5_vjLnu5lQjf?usp=sharing">Colab-блокнот</a></td>
        </tr>
        <tr>
            <td>3. Языковое моделирование</td>
            <td>
                <li>Вероятность слов и предложений на основе корпуса.</li>
                <li>N-граммные модели. Сглаживание Лапласа.</li>
                <li>Генерация текста. Перплексия.</li>
                <li>Генерация текста статьи с помощью n-граммных моделей.</li>
                <li>Нейросетевые языковые модели.</li>
                <li>Архитектура рекуррентных нейронных сетей.</li>
                <li>Типы задач: один к одному, один ко многим, многие к одному, многие ко многим.</li>
                <li>Сеть долгой краткосрочной памяти.</li>
                <li>Применение LSTM для посимвольной генерации.</li>
                </td>
            <td class="link-column"><a href="https://colab.research.google.com/drive/10XFszxpbWVREx1vAVleixIddZ_R0NlqR?usp=sharing">Colab-блокнот</a></td>
        </tr>
        <tr>
            <td>4. Механизм внимания</td>
            <td>
                <li>Постановка задачи sequence2sequence (seq2seq) на примере машинного перевода.</li>
                <li>Архитектура энкодер-декодер.</li>
                <li>Недостатки стандартной модели.</li>
                <li>Пример реализации машинного перевода.</li>
                <li>Визуализация весов внимания.</li>
                <li>Оценка качества машинного перевода.</li>
                </td>
            <td><a href="https://colab.research.google.com/drive/1-hg_qXMwZXcPiks5mPuSXsPdNccbyZZN?usp=sharing">Colab-блокнот</a></td>
        </tr>
        <tr>
            <td>5. Архитектура Трансформер</td>
            <td>
                <li>Механизм внутреннего внимания.</li>
                <li>Множественное внимание.</li>
                <li>Кодирование позиции.</li>
                <li>Нормализация слоя. Сквозная связь.</li>
                <li>Оптимизация и регуляризация.</li>
                <li>Примеры на искусственных и на реальных данных.</li>
                <li>Развитие архитектуры Трансформер.</li>
                <li>Модели BART, T5.</li>
            </td>
            <td><a href="https://colab.research.google.com/drive/1KUSuJkKaww5QXhNUMoN3MYZqdKhxqILE?usp=sharing">Colab-блокнот</a></td>
        </tr>
        <tr>
            <td>6. Модели на основе энкодера Трансформера</td>
            <td>
                <li>Использование предобученных векторов ELMo.</li>
                <li>Модель BERT на основе энкодера трансформера.</li>
                <li>Маскированное языковое моделирование.</li>
                <li>Предсказание следующего предложения.</li>
                <li>Библиотека Transformers.</li>
                <li>Токенизация на подслова.</li>
                <li>Тонкая настройка для определения логического следования.</li>
                </td>
            <td><a href="https://colab.research.google.com/drive/1sGSHCxC3H_plgpRalfRiHI9x7qrRBV65?usp=sharing">Colab-блокнот</a></td>
        </tr>
        <tr>
            <td>7. Модели на основе декодера Трансформера</td>
            <td>
                <li>Модель GPT и открытые модели.</li>
                <li>Методы генерации текста: жадный поиск, поиск по лучу, сэмплирование с температурой.</li>
                <li>Затравочное программирование.</li>
                <li>Обучение с подкреплением с обратной связью от человека.</li>
                <li>Проблемы дообучения больших моделей.</li>
                <li>Методы эффективной тонкой настройки.</li>
                <li>Пример тонкой настройки с помощью LoRA.</li>
            </td>
            <td><a href="https://colab.research.google.com/drive/1ceGd9wwzhJf9srL50NSr-SV0Ys-DWmC0?usp=sharing">Colab-блокнот</a></td>
        </tr>
        <tr>
            <td colspan="3">Б. Проектная часть</td>
        </tr>
        <tr>
            <td>8. Анализ тональности к именованным сущностям в новостных текстах</td>
            <td>
                <li>Особенности новостных текстов с точки зрения анализа тональности.</li>
                <li>Соревнование RuSentNE-2023: постановка задачи, анализ датасета, метрики.</li>
                <li>Воспроизведение бейзлайна: тонкая настройка модели RuBERT base conversational для классификации пары предложений:
                    <ul>
                      <li>1) Вопрос «Как относятся к X?» где Х — сущность в дательном падеже;</li>
                      <li>2) Текст предложения.</li>
                    </ul></li>
            </td>
            <td>
                <a href="https://drive.google.com/file/d/125-u2a68TYi2LBqoT6X0iw2Jflwa-kpO/view?usp=sharing">Презентация</a><br>
                <a href="https://colab.research.google.com/drive/1X5pew_-CNX63eP8ueNnnURRngzVSpY6K?usp=sharing">Colab-блокнот</a>
            </td>
        </tr>
        <tr>
            <td>9. Извлечение мнений из новостных текстов</td>
            <td>
                <li>Предшествующие исследования:
                    <ul>
                        <li>графовый подход,</li>
                        <li>разметка последовательности.</li>
                    </ul>
                </li>
                <li>Соревнование RuOpinionNE-2024:
                    <ul>
                        <li>постановка задачи,</li>
                        <li>анализ датасета,</li>
                        <li>метрики.</li>
                    </ul>
                    </li>
                <li>Воспроизведение бейзлайна: применение модели Qwen2.5 72B instruct в режиме few-shot.</li>
            </td>
            <td>
                <a href="https://drive.google.com/file/d/1RuSHU472CwvWeDoZ9cqVluVS5Vfl-DUS/view?usp=sharing">Презентация</a><br>
                <a href="https://colab.research.google.com/drive/13LIYbe95t-fKL7QMvuU71k8LRVNLXY5q?usp=sharing">Colab-блокнот</a>
            </td>
        </tr>
        <tr>
            <td>10. Анализ аргументации</td>
            <td>Аргумент как утверждение, содержащее позицию и довод. Соревнование RuArg-2022: постановка задачи, анализ датасета, метрики. Воспроизведение бейзлайна: тонкая настройка отдельной модели Sentence RuBERT по каждой теме: «маски», «карантин», «вакцины».</td>
            <td>
                <a href="https://drive.google.com/file/d/1tG6GeZ-hE09CDgYuvNY5cQ0-_uPe_lQp/view?usp=sharing">Презентация</a><br>
                <a href="https://colab.research.google.com/drive/1J4-LHvIhoXXSRoy8z_A7pRv9AyZDy2Jp?usp=sharing">Colab-блокнот</a>
            </td>
        </tr>
        <tr>
            <td>11. Представление тем проектных работ</td>
            <td>Выступления студентов. Постановка цели и задач проектной работы. Обзор существующих методов и подходов. Определение репрезентативности данных, их дисбаланс, выбросы и пропуски в данных. Выбор и обоснование целевых метрик. Выбор моделей для планируемых экспериментов. Обсуждение с преподавателем и другими студентами.</td>
            <td><a href="https://drive.google.com/drive/folders/1Yl-eMVuxB1YgnelhMWXAkCHzJt57XR2j?usp=sharing">Презентации</a></td>
        </tr>
        <tr>
            <td>12. Методы подбора инструкций для больших языковых моделей</td>
            <td>Платформы для доступа к LLM по API: Yandex Cloud, Sber, Mistral AI, Together AI, Hugging Face, GroqCloud. Преимущества и недостатки: скорость работы, стоимость, ограничения. Методы подбора инструкций (prompt engineering) для работы с LLM. Генерация ответа в режиме zero-shot и few-shot. Наиболее продвинутые техники: цепочка размышлений (Chain-of-Thoughts), самосогласованность (self-consistency), установка роли (role prompting).</td>
            <td><a href="https://colab.research.google.com/drive/12twkTbImoJrwDDAVL18_JjNqRiLbt0oK?usp=sharing">Colab-блокнот</a></td>
        </tr>
        <tr>
            <td>13. Объяснимость моделей машинного обучения</td>
            <td>Важность понимания решений моделей. Деление моделей на прозрачные и непрозрачные с точки зрения интерпретируемости. Объяснимость моделей классического ML: линейных моделей, деревьев решений. Методы объяснения, независимые от модели (model-agnostic): ICE, LIME, SHAP. Практическая реализация для различных задач.</td>
            <td><a href="https://colab.research.google.com/drive/1d-td9O3yvNz360y4cLUIiXIaNK0KSuDq?usp=sharing">Colab-блокнот</a></td>
        </tr>
        <tr>
            <td>14. Итоговая защита проектов</td>
            <td>Представление результатов выполненных проектов. Описание опробованных гиперпараметров модели и проведенных экспериментов по улучшению качества. Сопоставление итогов проекта с предыдущими работами в этой области. Практическая применимость результатов. Рецензирование работ друг друга. Ответы на вопросы.</td>
            <td><a href="https://drive.google.com/drive/folders/1vzof0gS5E98sag30Z_23e4wIPGaNKJUY?usp=sharing">Проекты</a></td>
        </tr>
</table>
</html>
